---
http_interactions:
- request:
    method: get
    uri: https://0xfe.blogspot.com/feeds/posts/default
    body:
      encoding: US-ASCII
      string: ''
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - "*/*"
      User-Agent:
      - Ruby
  response:
    status:
      code: 200
      message: OK
    headers:
      Cross-Origin-Opener-Policy-Report-Only:
      - same-origin; report-to=coop_reporting
      Report-To:
      - '{"group":"blogger-renderd","max_age":2592000,"endpoints":[{"url":"https://csp.withgoogle.com/csp/report-to/httpsserver2/blogger-renderd"}]}'
      Content-Security-Policy-Report-Only:
      - script-src 'none';form-action 'none';frame-src 'none'; report-uri https://csp.withgoogle.com/csp/httpsserver2/blogger-renderd
      Cross-Origin-Resource-Policy:
      - cross-origin
      Server:
      - blogger-renderd
      X-Content-Type-Options:
      - nosniff
      X-Xss-Protection:
      - '0'
      Content-Length:
      - '242401'
      X-Frame-Options:
      - SAMEORIGIN
      Date:
      - Tue, 29 Jul 2025 09:55:38 GMT
      Expires:
      - Tue, 29 Jul 2025 09:55:39 GMT
      Cache-Control:
      - public, must-revalidate, proxy-revalidate, max-age=1
      Last-Modified:
      - Mon, 09 Jun 2025 12:31:35 GMT
      Etag:
      - W/"25062ffaf404d65f81e2ad9745e540e9e672dadd034afd042f1aeba8f35ccb2b"
      Content-Type:
      - application/atom+xml; charset=UTF-8
      Age:
      - '0'
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
    body:
      encoding: ASCII-8BIT
      string: "<?xml version='1.0' encoding='UTF-8'?><?xml-stylesheet href=\"http://www.blogger.com/styles/atom.css\"
        type=\"text/css\"?><feed xmlns='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/'
        xmlns:blogger='http://schemas.google.com/blogger/2008' xmlns:georss='http://www.georss.org/georss'
        xmlns:gd=\"http://schemas.google.com/g/2005\" xmlns:thr='http://purl.org/syndication/thread/1.0'><id>tag:blogger.com,1999:blog-19544619</id><updated>2025-06-09T08:31:35.340-04:00</updated><category
        term=\"vexflow\"/><category term=\"haskell\"/><category term=\"vim\"/><category
        term=\"webaudio\"/><title type='text'>0xFE - 11111110b - 0376</title><subtitle
        type='html'></subtitle><link rel='http://schemas.google.com/g/2005#feed' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/posts/default'/><link rel='self' type='application/atom+xml'
        href='https://www.blogger.com/feeds/19544619/posts/default'/><link rel='alternate'
        type='text/html' href='https://0xfe.blogspot.com/'/><link rel='hub' href='http://pubsubhubbub.appspot.com/'/><link
        rel='next' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default?start-index=26&amp;max-results=25'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><generator
        version='7.00' uri='http://www.blogger.com'>Blogger</generator><openSearch:totalResults>63</openSearch:totalResults><openSearch:startIndex>1</openSearch:startIndex><openSearch:itemsPerPage>25</openSearch:itemsPerPage><entry><id>tag:blogger.com,1999:blog-19544619.post-1927090407427133388</id><published>2023-12-22T13:33:00.000-05:00</published><updated>2023-12-22T13:33:16.974-05:00</updated><title
        type='text'>The Firewall Guy</title><content type='html'>&lt;p&gt;About 20
        years ago, I worked as an independent consultant at a major telecom. I wrote
        a program that did some stuff, and couldn&#39;t get it to communicate on the
        network.&lt;/p&gt;&lt;p&gt;Developers there didn&#39;t get root on a machine,
        and there was limited access to tooling, so I reached out to the sysadmin.
        A day later he came back to me and said, &quot;everything here&#39;s good,
        check with the firewall guy.&quot;&lt;/p&gt;&lt;p&gt;The firewall guy. It
        took me a day to track down the firewall guy.&lt;/p&gt;&lt;p&gt;&quot;Umm...
        Mr. Firewall guy, can you help me out with this problem?&quot;&lt;/p&gt;&lt;p&gt;Firewall
        guy was kinda grumpy. He begrudgingly collected some information, begrudgingly
        looked at stuff. &quot;Firewall&#39;s fine. Talk to the network guy.&quot;&lt;/p&gt;&lt;p&gt;Two
        days later, I found the network guy, who was nicer: &quot;Network&#39;s good.
        Talk to the firewall guy.&quot;&lt;/p&gt;&lt;p&gt;&quot;I did a couple of
        days ago. Firewall guy says everything&#39;s fine.&quot;&lt;/p&gt;&lt;p&gt;&quot;Okay,
        then you&#39;re probably resolving to the wrong addresses. Talk to the DNS
        guy.&quot;&lt;/p&gt;&lt;p&gt;It took me many days to find the DNS guy. DNS
        guy left six months ago. Firewall guy was now also DNS guy.&lt;/p&gt;&lt;p&gt;I
        did not like Firewall guy, but I didn&#39;t have a choice: &quot;So Mr. Firewall
        guy, Network guy says it might be a DNS issue.&quot;&lt;/p&gt;&lt;p&gt;&quot;You
        again. It definitely not a Firewall or DNS problem.&quot;&lt;/p&gt;&lt;p&gt;At
        this point I was kinda stuck. I was accountable for delivering something that
        works, but had no agency to actually deliver the thing.&lt;/p&gt;&lt;p&gt;As
        I was thinking about what to do next, Firewall guy called me on my desk phone:
        &quot;try your thing again.&quot; I tried my thing again. &quot;Thanks very
        much, that worked! What was wrong?&quot;&lt;/p&gt;&lt;p&gt;&quot;It&#39;s
        complicated. &amp;lt;hangs up&amp;gt;&quot; I took a peek and saw the DNS
        entries didn&#39;t change. It was probably the firewall.&lt;/p&gt;&lt;p&gt;It
        took me about two days to build the thing, and eight days to navigate their
        bureaucracy. I billed them for ten days of my time, and apologized for taking
        so long.&lt;/p&gt;&lt;p&gt;The manager replied back right away: &quot;Oh that
        was quick! No need to apologize. Our regular consulting firm estimated 2 people
        3 months. Can you come by next week for your next project?&quot;&lt;/p&gt;</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/1927090407427133388/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2023/12/the-firewall-guy.html#comment-form'
        title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1927090407427133388'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1927090407427133388'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2023/12/the-firewall-guy.html'
        title='The Firewall Guy'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-1309421684262886131</id><published>2020-03-02T14:14:00.000-05:00</published><updated>2020-03-02T14:27:52.942-05:00</updated><title
        type='text'>Generating Spectrograms with Neural Networks</title><content type='html'>&lt;div
        dir=&quot;ltr&quot; style=&quot;text-align: left;&quot; trbidi=&quot;on&quot;&gt;\nIn
        a previous experiments, I used &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Spectrogram&quot;&gt;spectrograms&lt;/a&gt;&lt;/i&gt;&amp;nbsp;instead
        of raw audio as inputs to neural networks, while training them to recognize
        pitches, intervals, and chords.&lt;br /&gt;\n&lt;br /&gt;\nI found that feeding
        the networks raw audio data got nowhere. Training was extremely slow, and
        losses seemed to be bounded at unacceptably high values. After switching to
        spectrograms, the networks started learning almost immediately -- it was quite
        remarkable!&lt;br /&gt;\n&lt;br /&gt;\nThis post is about &lt;i&gt;&lt;b&gt;generating&lt;/b&gt;&lt;/i&gt;
        spectrograms with neural networks.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhDM2rOgj22MvXc9tLVrlD3jey8LAzjuXVUJljzhyPgaqEOluN1Fmtta9Iubv_X3rmQHWTv6y236myxVY_Hv-XBEeb3zkSPVbTYSxoW3Gk18XsOf-o9e9nEUzKDmwLaj4K6McaXEg/s1600/Screen+Shot+2020-03-02+at+11.17.26+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;684&quot; data-original-width=&quot;1316&quot;
        height=&quot;332&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhDM2rOgj22MvXc9tLVrlD3jey8LAzjuXVUJljzhyPgaqEOluN1Fmtta9Iubv_X3rmQHWTv6y236myxVY_Hv-XBEeb3zkSPVbTYSxoW3Gk18XsOf-o9e9nEUzKDmwLaj4K6McaXEg/s640/Screen+Shot+2020-03-02+at+11.17.26+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;These
        spectrograms were generated by a Neural Network&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nOn Spectrograms&lt;/h3&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\nSpectrograms are 2-dimensional visual representations of
        slices of audio (or really, any signal.) On the &lt;i&gt;x-axis&lt;/i&gt;
        of a spectrogram is time, and on the &lt;i&gt;y-axis&lt;/i&gt; is frequency.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot;
        cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left:
        auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEggIrcRsL735uyROVhGVIftc7Yg8a_RMVsl50-0JS39fjJM50Oe8bemSs_009R_DDH-MYpc_8J3-T0V51mTAS5-ae785UKd4li91y_VWNg3BzNL8sZAv_3y_fXYB4uEp6esiYdJNg/s1600/Screen+Shot+2020-02-22+at+9.15.03+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;526&quot; data-original-width=&quot;820&quot;
        height=&quot;256&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEggIrcRsL735uyROVhGVIftc7Yg8a_RMVsl50-0JS39fjJM50Oe8bemSs_009R_DDH-MYpc_8J3-T0V51mTAS5-ae785UKd4li91y_VWNg3BzNL8sZAv_3y_fXYB4uEp6esiYdJNg/s400/Screen+Shot+2020-02-22+at+9.15.03+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;A Violin
        playing A4 (440hz)&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nBecause the data is correlated well along both dimensions, spectrograms
        lend themselves well to both human analysis and convolutional neural networks.&lt;br
        /&gt;\n&lt;br /&gt;\nSo, I wondered, why can&#39;t the networks learn the
        spectrograms themselves? Under the covers, spectrograms are built with &lt;a
        href=&quot;https://en.wikipedia.org/wiki/Short-time_Fourier_transform&quot;&gt;STFTs&lt;/a&gt;,
        which are entirely linear operations on data -- you slide a window over the
        data at some stride length, then perform a discrete Fourier transform to get
        the frequency components of the window.&lt;br /&gt;\n&lt;br /&gt;\nSince the
        transformation is entirely linear, all you need is one network layer, no activations,
        no biases. This should theoretically collapse down to a simple regression
        problem. Right? Let&#39;s find out.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nGenerating Training Data&lt;/h3&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\nWe start by synthesizing some training data. To keep things
        simple, let&#39;s assume that we want to generate spectrograms of 25ms of
        audio sampled at 8khz, which is 2000 samples. Round up (in binary) to 2048
        to make things GPU friendly.&lt;br /&gt;\n&lt;br /&gt;\nThe underlying &lt;a
        href=&quot;https://en.wikipedia.org/wiki/Short-time_Fourier_transform&quot;&gt;STFT&lt;/a&gt;
        will use a &lt;a href=&quot;https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows&quot;&gt;hanning
        window&lt;/a&gt; of size 256, &lt;a href=&quot;https://en.wikipedia.org/wiki/Fast_Fourier_transform&quot;&gt;FFT&lt;/a&gt;
        size of 256, and a stride length of 250, producing &lt;b&gt;33x129&lt;/b&gt;
        images. That&#39;s 33 frequency-domain slices (along the time axis) capped
        at &lt;a href=&quot;https://en.wikipedia.org/wiki/Nyquist_frequency&quot;&gt;128hz&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/08204e72217ce29f06ac4c1ba7dd4d39.js&quot;&gt;&lt;/script&gt;\n\nNote
        that the spectrograms return complex values. We want to make sure the networks
        can learn to completely reconstruct both the magnitude and phase portions
        of the signal. Also note that we&#39;re going to teach our network how to
        compute hanning windows.&lt;br /&gt;\n&lt;br /&gt;\nHere&#39;s the code to
        generate the training data -- we calculate &lt;i&gt;batch_size&lt;/i&gt; (15,000)
        examples, each with 2048 samples and assign them to &lt;i&gt;xs&lt;/i&gt;.
        We then calculate their spectrograms and assign them to &lt;i&gt;ys&lt;/i&gt;
        (the targets.)&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/0da873c4ee32ff1bbb5d22b9f0b49817.js&quot;&gt;&lt;/script&gt;\n\nNote
        that we separate the real and imaginary components of the spectrogram and
        simply stack one atop the other. We also don&#39;t scale or normalize the
        data in any way. &lt;b&gt;Let the network figure all that out! :-)&lt;/b&gt;&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nBuilding
        the Model&lt;/h3&gt;\n&lt;br /&gt;\nNow the fun part. We build a single-layer
        network with &lt;i&gt;2048&lt;/i&gt; inputs for the audio slice, and &lt;i&gt;&lt;b&gt;row
        * col&lt;/b&gt;&lt;/i&gt; outputs for the image (&lt;b&gt;&lt;i&gt;times two&lt;/i&gt;&lt;/b&gt;
        to hold the real and imaginary components of the outputs.) Since the outputs
        are strictly a linear function of the inputs, we don&#39;t need a bias term
        or activation functions.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/bd8db7b878cbef048543e58d850bab67.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\nAgain, this is really just linear regression. &lt;i&gt;With, oh, about
        &lt;b&gt;17 million variables!&lt;/b&gt;&lt;/i&gt;&lt;br /&gt;\n&lt;br /&gt;\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3_UJQowtAxQB2JF104bcDRY-rslxaO7XVXZWMD-vwkZ1aOrwi2NgneYOrACxPa_V8VtmtlZ-tTbsZH1amO8D_gubfAZJ-5K0KAMOuiNCv-Ze-O8WgPjOhDTCBpPbkMznMSat8zw/s1600/Screen+Shot+2020-03-01+at+8.36.20+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;320&quot; data-original-width=&quot;1140&quot;
        height=&quot;176&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3_UJQowtAxQB2JF104bcDRY-rslxaO7XVXZWMD-vwkZ1aOrwi2NgneYOrACxPa_V8VtmtlZ-tTbsZH1amO8D_gubfAZJ-5K0KAMOuiNCv-Ze-O8WgPjOhDTCBpPbkMznMSat8zw/s640/Screen+Shot+2020-03-01+at+8.36.20+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\nThis model
        trains very fast. In 4 epochs (about 80 seconds), the loss drops to 3.0e-08,
        which is sufficient for our experiments, and in 10 epochs (about 7 minutes),
        we can drop it all the way to 2.0e-15.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhlCy70eiXOmrryOkFXTIj7wXf3u2krxBTDuG-L_1fquE6l-J9sRGFomBL0dG7-H691XH22nPuQrwt9Fklage-dbLNfxMnllhj2S-w9b2is7ipDtNE5MNuuTLSdSSkfOzTi8mxfTQ/s1600/Screen+Shot+2020-03-02+at+11.34.06+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;686&quot; data-original-width=&quot;1390&quot;
        height=&quot;313&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhlCy70eiXOmrryOkFXTIj7wXf3u2krxBTDuG-L_1fquE6l-J9sRGFomBL0dG7-H691XH22nPuQrwt9Fklage-dbLNfxMnllhj2S-w9b2is7ipDtNE5MNuuTLSdSSkfOzTi8mxfTQ/s640/Screen+Shot+2020-03-02+at+11.34.06+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nThe Real Test&lt;/h3&gt;\n&lt;br /&gt;\nOur model is ready.
        Let&#39;s see how well this does on unseen data. We generate a slice of audio
        playing four tones, and compare scipy&#39;s spectrogram function with our
        neural network.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/231d285b53f15b0ace08f93934100e6c.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-ASUhhLR9dlj1s5OCAKk0f341ND0VOaDihlVFDCxqF6nYBaQ0kUZA8DdplPiOCe0g7wlQU28KEk75bXY_7cbiK1zz6KHszHnhrit5AWwqaloynohIeJWKBR8Cg6RybvNIvYXF-w/s1600/Screen+Shot+2020-03-01+at+12.28.19+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;384&quot; data-original-width=&quot;1444&quot;
        height=&quot;170&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-ASUhhLR9dlj1s5OCAKk0f341ND0VOaDihlVFDCxqF6nYBaQ0kUZA8DdplPiOCe0g7wlQU28KEk75bXY_7cbiK1zz6KHszHnhrit5AWwqaloynohIeJWKBR8Cg6RybvNIvYXF-w/s640/Screen+Shot+2020-03-01+at+12.28.19+PM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Left:
        SciPy, Right: Neural Network&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nWow, that&#39;s actually pretty good, however when we look at a log-scaled
        version, you can see noise in the network-generated one.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/77110315b05d55bad70d9a20dcc2594e.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVkxUewAMYUH4TCma7eMbiYgKrY9dVsgrRaE_4yYizNhSg8sAStsvmBkuPtpakQBwpj_YP2jf6Z7PUsULu37T4nlDA8K1B-yArvWpHbjLoJkA5VXS0uvHvU0hWoGGRjPmenOoegA/s1600/Screen+Shot+2020-03-01+at+12.28.29+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;398&quot; data-original-width=&quot;1434&quot;
        height=&quot;176&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVkxUewAMYUH4TCma7eMbiYgKrY9dVsgrRaE_4yYizNhSg8sAStsvmBkuPtpakQBwpj_YP2jf6Z7PUsULu37T4nlDA8K1B-yArvWpHbjLoJkA5VXS0uvHvU0hWoGGRjPmenOoegA/s640/Screen+Shot+2020-03-01+at+12.28.29+PM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;&lt;span
        style=&quot;font-size: 12.8px;&quot;&gt;Log-scaled spectrogram: Left: SciPy,
        Right: Neural Network&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nMaybe we can train it for a bit longer and try again.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSVrD6v42Jo2FkXPdZBpxpVcmyh3NdobD8pE5hJka6FtshFQBWnI0NoBYZup-be4ME93Jc6r4POBCU4mSuv-s5WHEABdK-5f3pU6SfR0Eo16GawGAG4_G__TumqlC0ZLMJURIJcA/s1600/Screen+Shot+2020-03-01+at+12.34.27+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;392&quot; data-original-width=&quot;1434&quot;
        height=&quot;174&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSVrD6v42Jo2FkXPdZBpxpVcmyh3NdobD8pE5hJka6FtshFQBWnI0NoBYZup-be4ME93Jc6r4POBCU4mSuv-s5WHEABdK-5f3pU6SfR0Eo16GawGAG4_G__TumqlC0ZLMJURIJcA/s640/Screen+Shot+2020-03-01+at+12.34.27+PM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Left:
        SciPy, Right: Neural Network&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nOh yeah, that&#39;s way better!&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nPeeking into the Model&lt;/h3&gt;\n&lt;br /&gt;\nOkay, so
        we know that this works pretty well. It&#39;s worth taking a little time to
        dig in and see what exactly it learned. The best way to do this is by slicing
        through the layers and examining the weight matrices.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/af81df7faaae90a217e2a48b5251b63a.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\nLucky for us there&#39;s just one layer with (2048, 8514) weights.
        The second dimension (8154) is just the flattened spectrogram for each sample
        in the first. In the code above, we reshaped and transformed the data to make
        it easy to visualize.&lt;br /&gt;\n&lt;br /&gt;\nHere it is below -- the weight
        maps for the first, 11th, 21st, and 31st slices (out of 33) of the output.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRV8G03H9-Xzc1giGrnxzWeq7O2NzAsJelVTkuFl6E0rHdYSBimnTcVrYDKZ8xKDb8nZA-eqqa6XYL7s9ImXVqElW_NNZnXP2721C9aaBDGws7FE_uv02rPmAgn9Az8FElCDtjyw/s1600/Screen+Shot+2020-03-02+at+11.43.05+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;836&quot; data-original-width=&quot;1444&quot;
        height=&quot;370&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRV8G03H9-Xzc1giGrnxzWeq7O2NzAsJelVTkuFl6E0rHdYSBimnTcVrYDKZ8xKDb8nZA-eqqa6XYL7s9ImXVqElW_NNZnXP2721C9aaBDGws7FE_uv02rPmAgn9Az8FElCDtjyw/s640/Screen+Shot+2020-03-02+at+11.43.05+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\nThe vertical
        bands represent activated neurons. You can see how the bands move from left
        to right as they work on a 256-sample slice of the audio. But more interesting
        is the spiral pattern of the windows. What&#39;s going on there? Let&#39;s
        slice through one of the bands and plot just the inner dimension.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/a119bf4bfbe05eb4dc8e383f9355b37b.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\nThis is actually pretty cool -- each of the graphs below is a Hanning-Windowed
        sine wave of an integer frequency along each of the vertical bands. These
        sinusoids are correlated with the audio, one-by-one, to tease out the active
        frequencies in the slice of audio.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhuBIsIVk6YKFkLN2Mn_j4yLWxqYNd8UV8W1l-lABrjd_tWEynRNCzQsX5JektI4FL6N0RgTyaEUTZNaILS0FTL1j5SlrxoSR_MydSeln0smNXQdk-7G9aBf3GnQYbMT_4priqZ9g/s1600/Screen+Shot+2020-03-02+at+11.47.28+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;999&quot; data-original-width=&quot;1600&quot;
        height=&quot;398&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhuBIsIVk6YKFkLN2Mn_j4yLWxqYNd8UV8W1l-lABrjd_tWEynRNCzQsX5JektI4FL6N0RgTyaEUTZNaILS0FTL1j5SlrxoSR_MydSeln0smNXQdk-7G9aBf3GnQYbMT_4priqZ9g/s640/Screen+Shot+2020-03-02+at+11.47.28+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;1, 5,
        and 10hz Sine Waves (Windowed)&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nTo put it simply, those pretty spirally vertical bands are... &lt;b&gt;&lt;i&gt;Fourier
        Transforms&lt;/i&gt;&lt;/b&gt;!&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nLearning the Discrete Fourier Transform&lt;/h3&gt;\n&lt;br
        /&gt;\nExploring that network was fun, however we must go deeper. Let&#39;s
        build a quick network to perform a 128-point DFT, without any windowing, and
        see if there&#39;s more we can learn.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script
        src=&quot;https://gist.github.com/0xfe/5a029d815b9a5f22985933cee1a71562.js&quot;&gt;&lt;/script&gt;\n\nThis
        is a much simpler network, with only about 65k weights. It trains very fast,
        and works like a charm!&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOHIjjzVGyiyn58PQvtk4JzHPvx2opmuS_jPt118WaRlYTeIdrR6d1SnT-WiOdSg-XXlEBI4-C-iuSQmhDJd_mB6UDvnmVDQf09Hja9c51BfQ7VD-9o8aM59Rdmk2AlIREqRQmag/s1600/Screen+Shot+2020-03-02+at+1.36.11+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;346&quot; data-original-width=&quot;1126&quot;
        height=&quot;196&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOHIjjzVGyiyn58PQvtk4JzHPvx2opmuS_jPt118WaRlYTeIdrR6d1SnT-WiOdSg-XXlEBI4-C-iuSQmhDJd_mB6UDvnmVDQf09Hja9c51BfQ7VD-9o8aM59Rdmk2AlIREqRQmag/s640/Screen+Shot+2020-03-02+at+1.36.11+PM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\nDigging into
        the weights, you can clearly see the complex sinusoids used to calculate the
        Fourier transform.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/89a0c10da18fef15602af5b2d59a66d6.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh7-rQnX9r7yc1_mRLb0ffAINnImyrTJAbtAimvFgFb2u5GkTGK-jzfIVcq5NfQVRAlMd5UJaIq8ie42XhyphenhyphenG8dGHEzO2eo3AOnT3SiMUKChTA94ZI5LCfykpHQQbW1w7wrYlq-raA/s1600/Screen+Shot+2020-03-02+at+1.41.30+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;1172&quot; data-original-width=&quot;1108&quot;
        height=&quot;640&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh7-rQnX9r7yc1_mRLb0ffAINnImyrTJAbtAimvFgFb2u5GkTGK-jzfIVcq5NfQVRAlMd5UJaIq8ie42XhyphenhyphenG8dGHEzO2eo3AOnT3SiMUKChTA94ZI5LCfykpHQQbW1w7wrYlq-raA/s640/Screen+Shot+2020-03-02+at+1.41.30+PM.png&quot;
        width=&quot;603&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Real
        (blue) and Imaginary (green) Components&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nIf you look at the weight matrix as a whole, you see the same pattern
        we saw in the vertical bands of the spectrogram NN weights.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align:
        center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMZpKg4uDe5zCWWXae8oWABbYGaVCSm-PeWz6UPu65ZpZ1lYzksc_LKPisXS91Ck8GbR7gKYRwiqyVcDO7fiow1UB28BuTe1FzpVrLBZlgqYCSXECqNaEBLFNuSiI8G6cmKbppLw/s1600/Screen+Shot+2020-03-02+at+1.59.01+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;1376&quot; data-original-width=&quot;1440&quot;
        height=&quot;610&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMZpKg4uDe5zCWWXae8oWABbYGaVCSm-PeWz6UPu65ZpZ1lYzksc_LKPisXS91Ck8GbR7gKYRwiqyVcDO7fiow1UB28BuTe1FzpVrLBZlgqYCSXECqNaEBLFNuSiI8G6cmKbppLw/s640/Screen+Shot+2020-03-02+at+1.59.01+PM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;br /&gt;&lt;/div&gt;\nThere&#39;s
        a lot more we can explore in these networks, but I should probably end here...
        this post is getting way too long.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nFinal Thoughts&lt;/h3&gt;\n&lt;br /&gt;\nIt&#39;s impressive
        how well this works, and how quickly this works. The neural networks we trained
        above are relatively crude, and there are techniques we can explore to optimize
        them.&lt;br /&gt;\n&lt;br /&gt;\nFor example, with the spectrogram networks
        -- instead of having it learn each FFT band independently for each window,
        we could use a different network architecture (like recurrent networks), or
        implement some kind of weight sharing strategy across multiple layers.&lt;br
        /&gt;\n&lt;br /&gt;\nEither way, let me be clear: using Neural Networks to
        perform FFTs or generate spectrograms is &lt;b style=&quot;font-style: italic;&quot;&gt;completely
        impractical, &lt;/b&gt;and you shouldn&#39;t do it. Really, don&#39;t do it!
        It is, however, a great way to explore the guts of machine learning models
        as they learn to perform complicated tasks.&lt;br /&gt;\n&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;br /&gt;&lt;/div&gt;\n</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/1309421684262886131/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2020/03/generating-spectrograms-with-neural.html#comment-form'
        title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1309421684262886131'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1309421684262886131'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2020/03/generating-spectrograms-with-neural.html'
        title='Generating Spectrograms with Neural Networks'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhDM2rOgj22MvXc9tLVrlD3jey8LAzjuXVUJljzhyPgaqEOluN1Fmtta9Iubv_X3rmQHWTv6y236myxVY_Hv-XBEeb3zkSPVbTYSxoW3Gk18XsOf-o9e9nEUzKDmwLaj4K6McaXEg/s72-c/Screen+Shot+2020-03-02+at+11.17.26+AM.png\"
        height=\"72\" width=\"72\"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-6954953458036352732</id><published>2020-02-28T07:44:00.001-05:00</published><updated>2020-02-28T07:44:23.757-05:00</updated><title
        type='text'>Time Frequency Duality</title><content type='html'>&lt;div dir=&quot;ltr&quot;
        style=&quot;text-align: left;&quot; trbidi=&quot;on&quot;&gt;\nAn particularly
        interesting characteristic of Fourier transforms is &lt;b&gt;&lt;i&gt;time-frequency
        duality.&lt;/i&gt;&lt;/b&gt; This duality exposes a beautiful deep symmetry
        between the time and frequency domains of a signal.&lt;br /&gt;\n&lt;br /&gt;\nFor
        example, a sinusoid in the time domain is an impulse in the frequency domain,
        &lt;i&gt;&lt;b&gt;and vice versa&lt;/b&gt;&lt;/i&gt;.&lt;br /&gt;\n&lt;br
        /&gt;\nHere&#39;s what a 1-second 20hz sine wave looks like. If you play this
        on your audio device, you&#39;ll hear a 20hz tone.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script
        src=&quot;https://gist.github.com/0xfe/736216255e9bbcad5929350a29d1b6b6.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;
        text-align: center;&quot;&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfuInGS7azSrsPIEHFf8IRLzX092heOhMA-TvyOl4EWhzTGibkGhEUt317yNEu0jSSE0OlKEQFtxeWHcHPF2GeSyRlN2R41kLaE4xGnwG6qJYqFEt1CHzCBKwfWvJvhvhjIlv6Sg/s1600/Screen+Shot+2020-02-27+at+5.24.39+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;388&quot; data-original-width=&quot;1212&quot;
        height=&quot;204&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfuInGS7azSrsPIEHFf8IRLzX092heOhMA-TvyOl4EWhzTGibkGhEUt317yNEu0jSSE0OlKEQFtxeWHcHPF2GeSyRlN2R41kLaE4xGnwG6qJYqFEt1CHzCBKwfWvJvhvhjIlv6Sg/s640/Screen+Shot+2020-02-27+at+5.24.39+PM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;20hz
        Sine Wave&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br /&gt;\nWhen
        you take the Fourier transform of the wave, and plot the frequency domain
        representation of the signal, you get an impulse in the bin representing the
        20hz. (Ignore the&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Spectral_leakage&quot;&gt;tiny
        neighbours&lt;/a&gt;&amp;nbsp;for now.)&lt;br /&gt;\n&lt;br /&gt;\n&lt;script
        src=&quot;https://gist.github.com/0xfe/d5b29e9f9b987eeefce1148ec3698b60.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi1Bs_O3s1cSwNgTZiRB0dTlIg5GsCMzVK3kCtvwJtNWtpjrmP1FLYNF5mGTLL5EgRHg8j5qvyBSvM0Fi9XTihdyXzNtBPcAsZqkDgOqJt9JnqvKg4UqK_NpVLF32Q-lI-2wNHS8g/s1600/Screen+Shot+2020-02-27+at+5.30.35+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;396&quot; data-original-width=&quot;1224&quot;
        height=&quot;206&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi1Bs_O3s1cSwNgTZiRB0dTlIg5GsCMzVK3kCtvwJtNWtpjrmP1FLYNF5mGTLL5EgRHg8j5qvyBSvM0Fi9XTihdyXzNtBPcAsZqkDgOqJt9JnqvKg4UqK_NpVLF32Q-lI-2wNHS8g/s640/Screen+Shot+2020-02-27+at+5.30.35+PM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Frequency
        Domain of 20hz Sine Wave&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nIf you play this transformed representation out to your audio device,
        you&#39;ll hear a click, generated from the single impulse pushing the speaker&#39;s
        diaphragm. This is effectively an impulse signal.&lt;br /&gt;\n&lt;br /&gt;\nOkay,
        let&#39;s create an impulse signal by hand -- a string of zeros, with a 1
        somewhere in the middle. Play this on your speaker, and, again, you&#39;ll
        hear a click. This signal is no different from the the previous transformed
        signal, except for maybe the position of the impulse.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/db8bbd3c1c8635e3b6fb8c2e28c93e20.js&quot;&gt;&lt;/script&gt;\n\nSo,
        check this out. If you take the the FFT of the impulse and plot the frequency
        domain representation, you get... &lt;i&gt;&lt;b&gt;a sinusoid&lt;/b&gt;&lt;/i&gt;!&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/154b2a1b0be3fd92cdae206b829b38ba.js&quot;&gt;&lt;/script&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFWi8YhKu_nhS72RW8x_rcI2kuNQ4DqzZxYmd39x0KAtnA9PLrNaGEKSAOcTEuTvDOGnpM28adAauZqi26cMFi8MRJfCZJhVicEagWWkIlJXqP0ssEYHgdpDut5_hTAKckcJazMQ/s1600/Screen+Shot+2020-02-28+at+6.39.56+AM.png&quot;
        imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;392&quot;
        data-original-width=&quot;1208&quot; height=&quot;208&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFWi8YhKu_nhS72RW8x_rcI2kuNQ4DqzZxYmd39x0KAtnA9PLrNaGEKSAOcTEuTvDOGnpM28adAauZqi26cMFi8MRJfCZJhVicEagWWkIlJXqP0ssEYHgdpDut5_hTAKckcJazMQ/s640/Screen+Shot+2020-02-28+at+6.39.56+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;\n&lt;br /&gt;\n&lt;br /&gt;\nThis works
        both ways. You can the the &lt;b&gt;&lt;i&gt;inverse FFT&lt;/i&gt;&lt;/b&gt;&amp;nbsp;of
        a sine wave in the frequency domain, to produce an impulse in the time domain.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/fe317c6a7357dea6f23d9968e98dea2e.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgS4gwS_iQX8deUHZMtLPB4Vu4B5OzEvbDx2v8hHRzMbPEFeoEC2Qq6zDb863GrX3a09DYurSEjiAIELYexDHEjVndVw2fgQWVlp3kxft8SM1Cc8A7J0gkvL2rwfCquHr480IqMQQ/s1600/Screen+Shot+2020-02-28+at+6.42.45+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;796&quot; data-original-width=&quot;1214&quot;
        height=&quot;261&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgS4gwS_iQX8deUHZMtLPB4Vu4B5OzEvbDx2v8hHRzMbPEFeoEC2Qq6zDb863GrX3a09DYurSEjiAIELYexDHEjVndVw2fgQWVlp3kxft8SM1Cc8A7J0gkvL2rwfCquHr480IqMQQ/s400/Screen+Shot+2020-02-28+at+6.42.45+AM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Inverse
        Fourier Transform of a Sine Wave&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nThis is a wonderfully striking phenomenon, which I think reveals a
        lot about our perception of nature.&lt;br /&gt;\n&lt;br /&gt;\nFor example,
        here&#39;s another property of time-frequency duality --&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Convolution&quot;&gt;convolutions&lt;/a&gt;&amp;nbsp;in
        the time domain are multiplications in the frequency domain, and vice versa&lt;i&gt;.
        &lt;/i&gt;Because &lt;i&gt;multiplications require far fewer operations than
        convolutions&lt;/i&gt;, it&#39;s much simpler to operate on frequency domain
        representations of signals.&lt;br /&gt;\n&lt;br /&gt;\nYour inner ear consists
        of lots of tiny hairs that vary in thickness and resonate at different frequencies
        sending frequency domain representations of sound to your brain -- i.e.,&amp;nbsp;&lt;i&gt;your
        ear evolved a little DSP chip in&lt;/i&gt; it to make it easier on your brain.&lt;/div&gt;\n</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/6954953458036352732/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2020/02/time-frequency-duality.html#comment-form'
        title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6954953458036352732'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6954953458036352732'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2020/02/time-frequency-duality.html'
        title='Time Frequency Duality'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfuInGS7azSrsPIEHFf8IRLzX092heOhMA-TvyOl4EWhzTGibkGhEUt317yNEu0jSSE0OlKEQFtxeWHcHPF2GeSyRlN2R41kLaE4xGnwG6qJYqFEt1CHzCBKwfWvJvhvhjIlv6Sg/s72-c/Screen+Shot+2020-02-27+at+5.24.39+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-1894211342385136711</id><published>2020-02-22T23:11:00.001-05:00</published><updated>2020-02-23T07:50:40.637-05:00</updated><title
        type='text'>Pitch Detection with Convolutional Networks</title><content type='html'>&lt;div
        dir=&quot;ltr&quot; style=&quot;text-align: left;&quot; trbidi=&quot;on&quot;&gt;\nWhile
        working on &lt;a href=&quot;https://pitchy.ninja/&quot;&gt;Pitchy Ninja&lt;/a&gt;&amp;nbsp;and
        &lt;a href=&quot;https://vexflow.com/&quot;&gt;Vexflow&lt;/a&gt;, I explored
        a variety of different techniques for pitch detection that would also work
        well in a browser. Although, I settled on a relatively well-known algorithm,
        the exploration took me down an interesting path -- I wondered if you could
        build neural networks to classify pitches, intervals, and chords in recorded
        audio.&lt;br /&gt;\n&lt;br /&gt;\nTurns out the answer is &lt;b&gt;&lt;i&gt;yes.&amp;nbsp;&lt;/i&gt;&lt;/b&gt;To
        all of them.&lt;br /&gt;\n&lt;br /&gt;\nThis post details some of the techniques
        I used to build a pitch-detection neural network. Although I focus on single-note
        pitch estimation, these methods seem to work well for multi-note chords too.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nOn Pitch
        Estimation&lt;/h3&gt;\n&lt;br /&gt;\n&lt;a href=&quot;https://en.wikipedia.org/wiki/Pitch_detection_algorithm&quot;&gt;Pitch
        detection&lt;/a&gt; (also called &lt;i&gt;fundamental frequency estimation&lt;/i&gt;)
        is not an exact science. What your brain perceives as pitch is a function
        of lots of different variables, from the physical materials that generate
        the sounds to your body&#39;s physiological structure.&lt;br /&gt;\n&lt;br
        /&gt;\nOne would presume that you can simply transform a signal to its frequency
        domain representation, and look at the peak frequencies. This would work for
        a sine wave, but as soon as you introduce any kind of timbre (e.g., when you
        sing, or play a note on a guitar), the spectrum is flooded with &lt;a href=&quot;https://en.wikipedia.org/wiki/Overtone&quot;&gt;overtones&lt;/a&gt;
        and &lt;a href=&quot;https://en.wikipedia.org/wiki/Harmonic&quot;&gt;harmonic
        partials&lt;/a&gt;.&lt;br /&gt;\n&lt;br /&gt;\nHere&#39;s a 33ms spectrogram
        of the note A4 (440hz) played on a piano. You can see a peak at 440hz, and
        another around 1760hz.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbd4u91YSFmMe3uUXT-tsjfSVygsHoRChlZKlFKRMkN11BNIFJsqrVhRRRxnC7hCeKEmkgiv3OYFjRo395zqpz_0zUBfl9R64ryL8Qdllg22ONbb4raIC5T1zW01BA3nOtzJG7Tw/s1600/Screen+Shot+2020-02-22+at+9.14.50+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;534&quot; data-original-width=&quot;828&quot;
        height=&quot;257&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbd4u91YSFmMe3uUXT-tsjfSVygsHoRChlZKlFKRMkN11BNIFJsqrVhRRRxnC7hCeKEmkgiv3OYFjRo395zqpz_0zUBfl9R64ryL8Qdllg22ONbb4raIC5T1zW01BA3nOtzJG7Tw/s400/Screen+Shot+2020-02-22+at+9.14.50+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;br /&gt;\nHere&#39;s
        the same A4 (440hz), but on a violin.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj61E0xsI4lmYpxhsVxaUh2k7woDBN220o6d_TjgnkEfDdo-yQkpUHq5hr1TYR_GCiGvKzmh9M205x2qbmeziTOydR6pRwyHp9j4X_gv4p2nfuJLPDvuVck8DR49mII0jmEAAABdA/s1600/Screen+Shot+2020-02-22+at+9.15.03+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;526&quot; data-original-width=&quot;820&quot;
        height=&quot;256&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj61E0xsI4lmYpxhsVxaUh2k7woDBN220o6d_TjgnkEfDdo-yQkpUHq5hr1TYR_GCiGvKzmh9M205x2qbmeziTOydR6pRwyHp9j4X_gv4p2nfuJLPDvuVck8DR49mII0jmEAAABdA/s400/Screen+Shot+2020-02-22+at+9.15.03+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\nAnd here&#39;s
        a trumpet.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOL3_A1envcr3tirSEFs5-oOWWYFXg6bgIz5EFpI6w2cQjtP-QBr8KUx1QE9tzGNyi4LSylXsY-BZ-5Aczr1-Icd6VeNjxC_TO5fe09k0jGR8JV7LwTo8rSkLRnh1E1Jd4T4CrIg/s1600/Screen+Shot+2020-02-22+at+9.15.14+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;528&quot; data-original-width=&quot;826&quot;
        height=&quot;255&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOL3_A1envcr3tirSEFs5-oOWWYFXg6bgIz5EFpI6w2cQjtP-QBr8KUx1QE9tzGNyi4LSylXsY-BZ-5Aczr1-Icd6VeNjxC_TO5fe09k0jGR8JV7LwTo8rSkLRnh1E1Jd4T4CrIg/s400/Screen+Shot+2020-02-22+at+9.15.14+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\nNotice how
        the thicker instruments have rich harmonic spectrums? These harmonics are
        what make them beautiful, and also what make pitch detection hard.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nEstimation Techniques&lt;/h3&gt;\n&lt;br
        /&gt;\nA lot of the well understood pitch estimation algorithms resort to
        transformations and heuristics which amplify the fundamental and cancel out
        the overtones. Some, more advanced techniques work on (kind of) fingerprinting
        timbres, and then attempting to correlate them with a signal.&lt;br /&gt;\n&lt;br
        /&gt;\nFor single tones, these techniques work well, but they do break down
        in their own unique ways. After all, they&#39;re heuristics that try to &lt;i&gt;estimate
        human perception&lt;/i&gt;.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nConvolutional Networks&lt;/h3&gt;\n&lt;br /&gt;\nDeep &lt;a
        href=&quot;https://en.wikipedia.org/wiki/Convolutional_neural_network&quot;&gt;convolutional
        networks&lt;/a&gt; have been winning image labeling challenges for nearly
        a decade, starting with &lt;a href=&quot;https://en.wikipedia.org/wiki/AlexNet&quot;&gt;AlexNet
        in 2012&lt;/a&gt;. The key insight in these architectures is that detecting
        objects require some level of locality in pattern recognition, i.e., learned
        features should be agnostic to translations, rotations, intensities, etc.
        Convolutional networks learn multiple layers of filters, each capturing some
        perceptual element.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj2LwwE33Uu5V1Kjy9nZxOQZEbh8LIe4nyUp728tznKUIym01KXtfscXhi8ASVftIu-7wJ8FKfBs4YDvDCTLSl7x2kmn7QPoubI9aBJ8zajZCg9IzGcbXvRDF8DM-pO1r_7IseNqw/s1600/Screen+Shot+2020-02-22+at+9.36.01+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;488&quot; data-original-width=&quot;1458&quot;
        height=&quot;214&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj2LwwE33Uu5V1Kjy9nZxOQZEbh8LIe4nyUp728tznKUIym01KXtfscXhi8ASVftIu-7wJ8FKfBs4YDvDCTLSl7x2kmn7QPoubI9aBJ8zajZCg9IzGcbXvRDF8DM-pO1r_7IseNqw/s640/Screen+Shot+2020-02-22+at+9.36.01+PM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;br /&gt;\nFor
        example, the bottom layer of an image recognition network might detect edges
        and curves, the next might detect simple shapes, and the next would detect
        objects, etc. Here&#39;s an example of extracted features from various layers
        (via &lt;a href=&quot;https://www.groundai.com/project/deepfeat-a-bottom-up-and-top-down-saliency-model-based-on-deep-features-of-convolutional-neural-nets/&quot;&gt;DeepFeat&lt;/a&gt;.)&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijkByp7Wt8FbaM2YIKun1mLOehy2NOU5Oj8xgSKXrky_FeIHYqFkuxjEbtamdj_X_sC5pnC41QRUtTpUJjRXneSK7N5y4X8PiNQAKfB1Uoblcqo94HXEavYWlYQ2zYofVZHIWrdg/s1600/Screen+Shot+2020-02-22+at+9.40.06+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;1092&quot; data-original-width=&quot;1096&quot;
        height=&quot;397&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijkByp7Wt8FbaM2YIKun1mLOehy2NOU5Oj8xgSKXrky_FeIHYqFkuxjEbtamdj_X_sC5pnC41QRUtTpUJjRXneSK7N5y4X8PiNQAKfB1Uoblcqo94HXEavYWlYQ2zYofVZHIWrdg/s400/Screen+Shot+2020-02-22+at+9.40.06+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nConvolutional Networks for Audio&lt;/h3&gt;\n&lt;br /&gt;\nFor
        audio feature extraction, &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_domain&quot;&gt;time
        domain&lt;/a&gt; representations don&#39;t seem to be very useful to convnets.
        However, in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Frequency_domain&quot;&gt;frequency
        domain&lt;/a&gt;, convnets learn features &lt;i&gt;&lt;b&gt;extremely well&lt;/b&gt;&lt;/i&gt;.
        Once networks start looking at spectrograms, all kinds of patterns start to
        emerge.&lt;br /&gt;\n&lt;br /&gt;\nIn the next few sections, we&#39;ll build
        a and train a simple convolutional network to detect fundamental frequencies
        across six octaves.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nGetting Training Data&lt;/h3&gt;\n&lt;br /&gt;\nTo do this
        well, we need data. Labeled. &lt;b&gt;Lots of it!&lt;/b&gt; There are a few
        paths we can take:&lt;br /&gt;\n&lt;br /&gt;\n&lt;b&gt;Option 1&lt;/b&gt;:
        Go find a whole bunch of single-tone music online, slice it up into little
        bits, transcribe and label.&lt;br /&gt;\n&lt;br /&gt;\n&lt;b&gt;Option 2&lt;/b&gt;:
        Take out my trusty guitar, record, slice, and label. Then my keyboard, and
        my trumpet, and my clarinet. And maybe sing too. Ugh!&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;b&gt;Option 3&lt;/b&gt;: Build synthetic samples with... code!&lt;br
        /&gt;\n&lt;br /&gt;\nSince, you know, the ultimate programmer virtue is laziness,
        let&#39;s go with Option 3.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nTools of the Trade&lt;/h3&gt;\n&lt;br /&gt;\nThe goal is
        to build a model that performs well, and &lt;i&gt;generalizes well&lt;/i&gt;,
        so we&#39;ll need to make sure that we account for enough of the variability
        in real audio as we can -- which means using a variety of instruments, velocities,
        effects, envelopes, and noise profiles.&lt;br /&gt;\n&lt;br /&gt;\nWith a
        good MIDI library, a patch bank, and some savvy, we can get this done. Here&#39;s
        what we need:&lt;br /&gt;\n&lt;ul style=&quot;text-align: left;&quot;&gt;\n&lt;li&gt;&lt;a
        href=&quot;https://pypi.org/project/MIDIUtil/&quot;&gt;MIDIUtil&lt;/a&gt;
        - Python library to generate MIDI files.&lt;/li&gt;\n&lt;li&gt;&lt;a href=&quot;http://www.fluidsynth.org/&quot;&gt;FluidSynth&lt;/a&gt;
        - Renders MIDI files to raw audio.&lt;/li&gt;\n&lt;li&gt;&lt;a href=&quot;http://www.schristiancollins.com/generaluser.php&quot;&gt;GeneralUser
        GS&lt;/a&gt;&amp;nbsp;- A bank of GM instrument patches for FluidSynth.&lt;/li&gt;\n&lt;li&gt;&lt;a
        href=&quot;http://sox.sourceforge.net/sox.html&quot;&gt;sox&lt;/a&gt; - To
        post-process the audio (resample, normalize, etc.)&lt;/li&gt;\n&lt;li&gt;&lt;a
        href=&quot;https://www.scipy.org/&quot;&gt;scipy.io&lt;/a&gt; - For generating
        spectrograms&lt;/li&gt;\n&lt;li&gt;&lt;a href=&quot;https://tensorflow.org/&quot;&gt;Tensorflow&lt;/a&gt;
        - For building and training the models.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div&gt;\n&lt;br
        /&gt;\nAll of these are open-source and freely available. Download and install
        them before proceeding.&lt;/div&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\n&lt;/h3&gt;\n&lt;h3
        style=&quot;text-align: left;&quot;&gt;\n&lt;/h3&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\n&lt;br /&gt;&lt;/h3&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nSynthesizing
        the Data&lt;/h3&gt;\n&lt;br /&gt;\nWe start with picking a bunch of instruments
        encompassing a variety of different timbres and tonalities.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/39f374a4ec66a1dc6af2a622851b2e74.js&quot;&gt;&lt;/script&gt;&lt;br
        /&gt;\n&lt;div&gt;\n&lt;br /&gt;\nPick the notes and octaves you want to be
        able to classify. I used all 12 tones between octaves 2 and 8 (and added some
        random detunings.) Here&#39;s a handy class to deal with note to MIDI value
        conversions.&lt;br /&gt;\n&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/0b8b66bf4e34caedcacb5894164e7c7c.js&quot;&gt;&lt;/script&gt;\n\nThe
        next section is where the meat of the synthesis happens. It does the following:&lt;br
        /&gt;\n&lt;ul&gt;\n&lt;li&gt;Renders the MIDI files to raw audio (wav) using
        FluidSynth and a free GM sound font.&lt;/li&gt;\n&lt;li&gt;Resamples to single-channel,
        unsigned 16-bit, at 44.1khz, normalized.&lt;/li&gt;\n&lt;li&gt;Slices the
        sample up into its envelope components (attack, sustain, decay.)&lt;/li&gt;\n&lt;li&gt;Detunes
        some of the samples to cover more of the harmonic surface.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div&gt;\n&lt;script
        src=&quot;https://gist.github.com/0xfe/f01e3186b14543b42303e6af96286262.js&quot;&gt;&lt;/script&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\nFinally, we use the &lt;b&gt;Sample&lt;/b&gt;&amp;nbsp;class
        to generate thousands of different 33ms long MIDI files, each playing a single
        note.&amp;nbsp; The labels are part of the filename, and include the note,
        octave, frequency, and envelope component.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script
        src=&quot;https://gist.github.com/0xfe/29aedb7cc2733e7bde767eebcdd1d204.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nBuilding
        the Network&lt;/h3&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;div&gt;\nNow
        that we have the training data, let&#39;s design the network.&lt;br /&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;div&gt;\nI experimented with a variety of different
        architectures before I got here, starting with simple dense (non-convolution)
        networks with time-domain inputs, then moving on to one-dimensional LSTMs,
        then two-dimensional convolutional networks (convnets) with frequency-domain
        inputs.&lt;/div&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;div&gt;\nAs
        you can guess, the 2D networks with frequency-domain inputs worked &lt;b&gt;significantly
        better.&lt;/b&gt; As soon as I got decent baseline performance with them,
        I focused on incrementally improving accuracy by reducing validation loss.&lt;/div&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nModel Inputs&lt;/h3&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;div&gt;\nThe inputs to the network will be &lt;a href=&quot;https://en.wikipedia.org/wiki/Spectrogram&quot;&gt;spectrograms&lt;/a&gt;,
        which are 2D images representing a slice of audio. The X-axis is usually time,
        and the Y-axis is frequency. They&#39;re great for visualizing audio spectrums,
        but also for more advanced audio analysis.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table
        align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfBj4NcA-QJtuTsDM3Rv6rNxZJumr7qXjNgspGKe9lOnv9XRUjsjfqZZ3GSa50F76ayZn7BMIPcjV6MWOsihu8z4Pb0vBijwEQrV5x8VEs8zhe5llGV766O1lmXrJS0VidEAisJw/s1600/Screen+Shot+2020-02-22+at+9.17.27+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;526&quot; data-original-width=&quot;840&quot;
        height=&quot;250&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfBj4NcA-QJtuTsDM3Rv6rNxZJumr7qXjNgspGKe9lOnv9XRUjsjfqZZ3GSa50F76ayZn7BMIPcjV6MWOsihu8z4Pb0vBijwEQrV5x8VEs8zhe5llGV766O1lmXrJS0VidEAisJw/s400/Screen+Shot+2020-02-22+at+9.17.27+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;A Church
        Organ playing A4 (440hz)&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;div&gt;\nSpectrograms
        are typically generated with &lt;a href=&quot;https://en.wikipedia.org/wiki/Short-time_Fourier_transform&quot;&gt;Short
        Time Fourier Transforms (STFTs)&lt;/a&gt;. In short, the algorithm slides
        a window over the audio, running &lt;a href=&quot;https://en.wikipedia.org/wiki/Fast_Fourier_transform&quot;&gt;FFTs&lt;/a&gt;
        over the windowed data. Depending on the parameters of the STFT (and the associated
        FFTs), the precision of the detected frequencies can be tweaked to match the
        use case.&lt;/div&gt;\n&lt;br /&gt;\nFor this experiment, we&#39;re working
        with 44.1khz 16-bit samples, 33ms long -- which is about 14,500 data points
        per sample. We first &lt;b&gt;downsample&lt;/b&gt; the audio to 16khz, yielding
        5280 data points per sample.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/86a9c94f75bd06bde76cb6a612744d49.js&quot;&gt;&lt;/script&gt;\n\nThe
        spectrogram will be generated via STFT, using a window size of 256, an overlap
        of 200, and a 1024 point FFT zero-padded on both sides. This yields one &lt;b&gt;513x90&lt;/b&gt;
        pixel image per sample.&lt;br /&gt;\n&lt;br /&gt;\nThe 1024-point FFT also
        &lt;b&gt;&lt;i&gt;caps the resolution&lt;/i&gt;&lt;/b&gt; to about 19hz, which
        isn&#39;t perfect, but fine for distinguishing pitches.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\n\nThe Network Model&lt;/h3&gt;\n&lt;br
        /&gt;\nOur network consists of 4 convolutional layers, with 64, 128, 128,
        and 256 filters respectively, which are then immediately downsampled with
        &lt;a href=&quot;https://computersciencewiki.org/index.php/Max-pooling_/_Pooling&quot;&gt;max-pooling&lt;/a&gt;
        layers. The input layer reshapes the input tensors by adding a &lt;i&gt;channels&lt;/i&gt;
        dimension for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D&quot;&gt;Conv2D&lt;/a&gt;.
        We close out the model with two densely connected layers, and a final output
        node for the floating-point frequency.&lt;br /&gt;\n&lt;br /&gt;\nTo prevent
        overfitting, we &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Regularization_(mathematics)&quot;&gt;regularize&lt;/a&gt;&lt;/i&gt;
        by aggressively adding &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout&quot;&gt;dropout&lt;/a&gt;
        layers, including one right at the input which also doubles as an ad-hoc noise
        generator.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/56f14b33ac8e09e94d65e77f50a61280.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\nAlthough we use &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;mean-squared-error&lt;/a&gt;
        as our loss function, it&#39;s the &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;mean-absolute-error&lt;/a&gt;
        that we need to watch, since it&#39;s easier to reason about. Let&#39;s take
        a look at the model summary.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjLUdV6YW8fwFUwMsC0TGRx55VxkPmtXTC8mmDgu8iqKbGveU6Yz3pyyNTSRpX5rvgA2dtL6948KcbyiO1-h52ryC_R7KXom92l89UwACMadN_J9EmD7fB5_i72_ai6QtLRDGufTg/s1600/Screen+Shot+2020-02-22+at+5.08.33+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;1364&quot; data-original-width=&quot;1124&quot;
        height=&quot;640&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjLUdV6YW8fwFUwMsC0TGRx55VxkPmtXTC8mmDgu8iqKbGveU6Yz3pyyNTSRpX5rvgA2dtL6948KcbyiO1-h52ryC_R7KXom92l89UwACMadN_J9EmD7fB5_i72_ai6QtLRDGufTg/s640/Screen+Shot+2020-02-22+at+5.08.33+PM.png&quot;
        width=&quot;524&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;br /&gt;\nWow,
        &lt;b&gt;12 million&lt;/b&gt; parameters! Feels like a lot for an experiment,
        but it turns out we can build a model in less than 10 minutes on a modern
        GPU. Let&#39;s start training.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/6a7234fe6e368bbd346f5fdddd88fa12.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\nAfter 100 epochs, we can achieve a validation MSE of 0.002, and a validation
        MAE of 0.03.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjW4345UjhQ7l9tyvSRWymJ0Ic-usaJeM-C6VcBKpNU_Al2ur3xoDRFSjz-xtEOsfqiCUbTxn1yd91VDmWVvZAOWbS-0dGfV4gUtnH5sxDSHAdeZ_ToAK4c8L_kYPEDBZ9yS-MIYA/s1600/Screen+Shot+2020-02-22+at+11.03.15+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;1066&quot; data-original-width=&quot;814&quot;
        height=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjW4345UjhQ7l9tyvSRWymJ0Ic-usaJeM-C6VcBKpNU_Al2ur3xoDRFSjz-xtEOsfqiCUbTxn1yd91VDmWVvZAOWbS-0dGfV4gUtnH5sxDSHAdeZ_ToAK4c8L_kYPEDBZ9yS-MIYA/s400/Screen+Shot+2020-02-22+at+11.03.15+PM.png&quot;
        width=&quot;305&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\nYou may be
        wondering why the validation MAE is so much better than the training MAE.
        This is because of the aggressive dropout regularization. Dropout layers are
        only activated during training, not prediction.&lt;br /&gt;\n&lt;br /&gt;\nThese
        results are quite promising for an experiment! For classification problems,
        we could use &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;confusion
        matrices&lt;/a&gt; to see where the models mispredict. For regression problems
        (like this one), we can explore the losses a bit more by plotting a graph
        of errors by pitch.&lt;br /&gt;\n&lt;br /&gt;\n&lt;script src=&quot;https://gist.github.com/0xfe/3e4d90436dce46ec121b9f94948001a1.js&quot;&gt;&lt;/script&gt;\n\n&lt;br
        /&gt;\n&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align:
        center;&quot;&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;table
        align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFvd_SBwOkcp64POT5Y_z7-tn1eNFhP4vMU8nPBGWtXkAv-Cn8XvQjzPc4VuFLgHNKSPSpPDJXB5MbwS0RmijcQoRiUtGZ4HZPAr_QM1mdBYaerG7V1OYCNXviTT0iJvDFF_6jGg/s1600/Screen+Shot+2020-02-22+at+10.25.46+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;512&quot; data-original-width=&quot;786&quot;
        height=&quot;260&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFvd_SBwOkcp64POT5Y_z7-tn1eNFhP4vMU8nPBGWtXkAv-Cn8XvQjzPc4VuFLgHNKSPSpPDJXB5MbwS0RmijcQoRiUtGZ4HZPAr_QM1mdBYaerG7V1OYCNXviTT0iJvDFF_6jGg/s400/Screen+Shot+2020-02-22+at+10.25.46+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Prediction
        Errors by Pitch&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;br
        /&gt;\nAlready, we can see that the prediction errors are on the highest octaves.
        This is very likely due to our downsampling to 16khz, causing &lt;a href=&quot;https://en.wikipedia.org/wiki/Aliasing&quot;&gt;aliasing&lt;/a&gt;
        in the harmonics and confusing the model.&lt;br /&gt;\n&lt;br /&gt;\nAfter
        discarding the last octave, we can take the mean of the prediction error,
        and what do we see?&lt;br /&gt;\n&lt;div style=&quot;background-color: #fffffe;
        font-family: monospace, Menlo, Monaco, &amp;quot;Courier New&amp;quot;, monospace;
        font-size: 14px; line-height: 19px; white-space: pre;&quot;&gt;\nnp.mean(np.nan_to_num(errors_by_key[&lt;span
        style=&quot;color: #09885a;&quot;&gt;0&lt;/span&gt;:&lt;span style=&quot;color:
        #09885a;&quot;&gt;80&lt;/span&gt;]))&lt;/div&gt;\n&lt;span style=&quot;background-color:
        white; color: #212121; font-family: monospace; font-size: 14px; white-space:
        pre;&quot;&gt;19.244542657486097&lt;/span&gt;&lt;br /&gt;\n&lt;br /&gt;\nPretty
        much exactly the resolution of the FFT we used. It&#39;s very hard to do better
        given the inputs.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nThe Real Test&lt;/h3&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\nSo,
        how does this perform in the wild? To answer this question, I recorded a few
        samples of myself playing single notes on the guitar, and pulled some youtube
        videos of various instruments and sliced them up for analysis. I also crossed
        my fingers and sacrificed a dozen goats.&lt;br /&gt;\n&lt;br /&gt;\nAs hoped,
        the predictions were &lt;b&gt;&lt;i&gt;right within the tolerances&lt;/i&gt;&lt;/b&gt;
        of the model. Try it yourself and let me know how it works out.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nImprovements and Variations&lt;/h3&gt;\n&lt;br
        /&gt;\nThere&#39;s a few things we can do to improve what we have -- larger
        FFT and window sizes, higher sample rates, better data, etc. We can also turn
        this into a classification problem by using &lt;a href=&quot;https://en.wikipedia.org/wiki/Softmax_function&quot;&gt;softmax&lt;/a&gt;
        at the bottom layer and training directly on musical pitches instead of frequencies.&lt;br
        /&gt;\n&lt;br /&gt;\nThis experiment was part of a whole suite of models I
        built for music recognition. In a future post I&#39;ll describe a more complex
        set of models I built to recognize roots, intervals, and 2-4 note chords.&lt;br
        /&gt;\n&lt;br /&gt;\nUntil then, hope you enjoyed this post. If you did, drop
        me a note at &lt;a href=&quot;https://twitter.com/11111110b&quot;&gt;@11111110b&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\nAll the source code for these experiments will be available
        on &lt;a href=&quot;https://github.com/0xfe&quot;&gt;my Github page&lt;/a&gt;
        as soon as it&#39;s in slightly better shape.&lt;br /&gt;\n&lt;br /&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;/div&gt;\n</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/1894211342385136711/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2020/02/pitch-detection-with-convolutional.html#comment-form'
        title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1894211342385136711'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1894211342385136711'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2020/02/pitch-detection-with-convolutional.html'
        title='Pitch Detection with Convolutional Networks'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbd4u91YSFmMe3uUXT-tsjfSVygsHoRChlZKlFKRMkN11BNIFJsqrVhRRRxnC7hCeKEmkgiv3OYFjRo395zqpz_0zUBfl9R64ryL8Qdllg22ONbb4raIC5T1zW01BA3nOtzJG7Tw/s72-c/Screen+Shot+2020-02-22+at+9.14.50+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-541596065311835171</id><published>2020-02-19T13:26:00.005-05:00</published><updated>2020-02-20T08:38:01.568-05:00</updated><title
        type='text'>No Servers, Just Buckets: Hosting Static Websites on the Cloud</title><content
        type='html'>&lt;div dir=&quot;ltr&quot; style=&quot;text-align: left;&quot;
        trbidi=&quot;on&quot;&gt;\n&lt;br /&gt;\nFor over two decades, I&#39;ve hosted
        websites on managed servers. Starting with web hosting providers, going to
        dedicated machines, then dedicated VMs, then cloud VMs. Maintaining these
        servers tend to come at a high cognitive cost -- machine and network setup,
        OS patches, web server configuration, replication and high-availability, TLS
        and cert management, security... the list goes on.&lt;br /&gt;\n&lt;br /&gt;\nLast
        year, I moved [&lt;a href=&quot;https://pitchy.ninja/&quot;&gt;almost&lt;/a&gt;]
        [&lt;a href=&quot;https://muthanna.com/&quot;&gt;all&lt;/a&gt;]&amp;nbsp;[&lt;a
        href=&quot;https://float64.dev/&quot;&gt;my&lt;/a&gt;]&amp;nbsp;[&lt;a href=&quot;https://vexflow.com/&quot;&gt;websites&lt;/a&gt;]
        to cloud buckets, and it has been amazing! Life just got simpler. With just
        a few commands I got:&lt;br /&gt;\n&lt;br /&gt;\n&lt;ul style=&quot;text-align:
        left;&quot;&gt;\n&lt;li&gt;A HTTP(s) web-server hosting my content.&lt;/li&gt;\n&lt;li&gt;Managed
        TLS certificates.&lt;/li&gt;\n&lt;li&gt;Compression, Caching, and Content
        Delivery.&lt;/li&gt;\n&lt;li&gt;Replication and High availability.&lt;/li&gt;\n&lt;li&gt;IPv6!&lt;/li&gt;\n&lt;li&gt;Fewer
        headaches, and more spending money. :-)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;br /&gt;\nIf
        you don&#39;t need tight control over how your data is served, I would strongly
        recommend that you host your sites on Cloud Buckets. (Yes, of course, servers
        are still involved, you just don&#39;t need to worry about them.)&lt;br /&gt;\n&lt;br
        /&gt;\nIn this post, I&#39;ll show you how I got the&amp;nbsp;&lt;a href=&quot;https://float64.dev/&quot;&gt;float64
        website&lt;/a&gt;&amp;nbsp;up and serving in almost no time.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nWhat are Cloud Buckets?&lt;/h3&gt;\n&lt;br
        /&gt;\nBuckets are a storage abstraction for blobs of data offered by cloud
        providers. E.g., &lt;a href=&quot;https://cloud.google.com/storage&quot;&gt;Google
        Cloud Storage&lt;/a&gt; or &lt;a href=&quot;https://aws.amazon.com/s3/&quot;&gt;Amazon
        S3&lt;/a&gt;. Put simply, they&#39;re a place in the cloud where you can store
        directories of files (typically called objects.)&lt;br /&gt;\n&lt;br /&gt;\nData
        in buckets are managed by cloud providers -- they take care of all the heavy
        lifting around storing the data, replicating, backing up, and serving. You
        can access this data with command line tools, via language APIs, or from the
        browser. You can also manage permissions, ownership, replication, retention,
        encryption, and audit controls.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\n&lt;/h3&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nHosting
        Websites on Cloud Buckets&lt;/h3&gt;\n&lt;br /&gt;\nMany cloud providers now
        allow you to serve files (sometimes called bucket objects) over the web, and
        let you distribute content over their respective CDNs. For this post, we&#39;ll
        upload a website to a &lt;a href=&quot;https://cloud.google.com/storage&quot;&gt;Google
        Cloud Storage&lt;/a&gt; bucket and serve it over the web.&lt;br /&gt;\n&lt;br
        /&gt;\nMake sure you have your &lt;a href=&quot;https://cloud.google.com/&quot;&gt;Google
        Cloud&lt;/a&gt;&amp;nbsp;account setup, &lt;a href=&quot;https://cloud.google.com/sdk&quot;&gt;command-line
        tools installed&lt;/a&gt;, and are logged in on your terminal.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;code&gt;\ngcloud auth login&lt;br /&gt;\ngcloud config set project
        &amp;lt;your-project-id&amp;gt;&lt;/code&gt;&lt;br /&gt;\n&lt;code&gt;&lt;br
        /&gt;&lt;/code&gt;\n\nCreate your storage bucket with &lt;a href=&quot;https://cloud.google.com/storage/docs/creating-buckets&quot;&gt;gsutil
        mb&lt;/a&gt;. Bucket names must be globally unique, so you&#39;ll have to
        pick something no one else has used. Here I&#39;m using &lt;i&gt;float64&lt;/i&gt;
        as my bucket name.&lt;br /&gt;\n&lt;br /&gt;\n&lt;code&gt;gsutil mb gs://float64&lt;/code&gt;\n&lt;br
        /&gt;\n&lt;code&gt;&lt;br /&gt;&lt;/code&gt;\nCopy your website content over
        to the bucket. We specify &#39;-&lt;a href=&quot;https://cloud.google.com/storage/docs/gsutil/commands/cp&quot;&gt;a
        public-read&lt;/a&gt;&#39; to make the objects world-readable.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;code&gt;gsutil cp -a public-read index.html style.css index.AF4C.js
        gs://float64&lt;/code&gt;\n&lt;br /&gt;\n&lt;code&gt;&lt;br /&gt;&lt;/code&gt;\nThat&#39;s
        it. Your content is now available at &lt;i&gt;https://storage.googleapis.com/&amp;lt;BUCKET&amp;gt;/index.html&lt;/i&gt;.
        Like mine is here:&amp;nbsp;&lt;a href=&quot;https://storage.googleapis.com/float64/index.html&quot;&gt;https://storage.googleapis.com/float64/index.html&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\n&lt;/h3&gt;\n&lt;h3
        style=&quot;text-align: left;&quot;&gt;\nUsing your own Domain&lt;/h3&gt;\n&lt;br
        /&gt;\nTo serve data over your own domain using HTTPS, you need to create
        a &lt;a href=&quot;https://cloud.google.com/load-balancing&quot;&gt;Cloud
        Load Balancer&lt;/a&gt; (or use an existing one.) Go to the &lt;a href=&quot;https://console.cloud.google.com/net-services/loadbalancing&quot;&gt;Load
        Balancer Console&lt;/a&gt;, click &quot;Create Load Balancer&quot;, and select
        the HTTP/HTTPS option.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhipsKbza7Qsm2JCe2LJwWdOlpRexWoh8IwF0JVLK9BsUaaiV9jaUctCtiSiG6FNjoHpspbjVPED27FoXPYh8L671CzC-azbBzqp3LQ0LyJtMvQw78R3yLdjX963KIRUSd87b3Azg/s1600/Screen+Shot+2020-02-19+at+8.28.36+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;652&quot; data-original-width=&quot;878&quot;
        height=&quot;295&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhipsKbza7Qsm2JCe2LJwWdOlpRexWoh8IwF0JVLK9BsUaaiV9jaUctCtiSiG6FNjoHpspbjVPED27FoXPYh8L671CzC-azbBzqp3LQ0LyJtMvQw78R3yLdjX963KIRUSd87b3Azg/s400/Screen+Shot+2020-02-19+at+8.28.36+AM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\nThe balancer
        configuration has three main parts: backend, routing rules, and frontend.&lt;br
        /&gt;\n&lt;br /&gt;\nFor the backend, select &quot;backend buckets&quot;,
        and pick the bucket that you just created. Check the &#39;Enable CDN&#39;
        box if you want your content cached and delivered over Google&#39;s worldwide
        Content Delivery Network.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh9YZ38AmPpWnQ2YCL3PGI9xzJSbPD4GgyN776Ha5bZ82BubM7CjwmJ7qexivA9WywQpWBsEmKoFYRLrlvIMA3tfRkt95YDp7bZUnQbMC_8vw_OxGg5xq0J7MGNC8FyLZyT5jq3wQ/s1600/Screen+Shot+2020-02-19+at+8.31.48+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;100&quot; data-original-width=&quot;280&quot;
        height=&quot;71&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh9YZ38AmPpWnQ2YCL3PGI9xzJSbPD4GgyN776Ha5bZ82BubM7CjwmJ7qexivA9WywQpWBsEmKoFYRLrlvIMA3tfRkt95YDp7bZUnQbMC_8vw_OxGg5xq0J7MGNC8FyLZyT5jq3wQ/s200/Screen+Shot+2020-02-19+at+8.31.48+AM.png&quot;
        width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;br /&gt;\nFor
        the routing rules, simply use your domain name (float64.dev) in the host field,
        your bucket (float64) in the backends field, and &lt;code&gt;&lt;b&gt;/*&lt;/b&gt;&lt;/code&gt;
        in Paths to say that all paths get routed to your bucket.&lt;br /&gt;\n&lt;br
        /&gt;\nFinally, for the frontend, add a new IP address, and point your domain&#39;s
        &lt;i&gt;A&lt;/i&gt; record at it. If you&#39;re with the times, you can also
        add an IPv6 address, and point your domain&#39;s &lt;i&gt;AAAA&lt;/i&gt; record
        at it.&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZYmJHBFv8QyXiXv30K_XVUf62MvxDLSmb4GijnBsHnc2vouiVM2bAqEtM0qpjfoj7_cCcg1p17ZVXntlwmSzctH0cWHKXAFRa38IfK5yS28Am_UCy1B140zhdfmzkB6AtPM0cKA/s1600/Screen+Shot+2020-02-19+at+8.29.55+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; data-original-height=&quot;272&quot; data-original-width=&quot;962&quot;
        height=&quot;179&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZYmJHBFv8QyXiXv30K_XVUf62MvxDLSmb4GijnBsHnc2vouiVM2bAqEtM0qpjfoj7_cCcg1p17ZVXntlwmSzctH0cWHKXAFRa38IfK5yS28Am_UCy1B140zhdfmzkB6AtPM0cKA/s640/Screen+Shot+2020-02-19+at+8.29.55+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;br /&gt;\nIf
        you&#39;re serving over HTTPS, you can create a new &lt;a href=&quot;https://cloud.google.com/load-balancing/docs/ssl-certificates&quot;&gt;managed
        certificate&lt;/a&gt;. These certs are issued by Let&#39;s Encrypt and managed
        by Google (i.e., Goole takes care of attaching, verifying, and renewing them.)
        The certificates take about 30 minutes to propagate.&lt;br /&gt;\n&lt;br /&gt;\nSave
        and apply your changes, and your custom HTTPS website is up! A few more odds
        and ends before we call it a day.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nSetup Index and Error Pages&lt;/h3&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;div&gt;\nYou probably don&#39;t want your users typing
        in the name of the index HTML file (&lt;a href=&quot;https://float64.dev/index.html&quot;&gt;https://float64.dev/index.html&lt;/a&gt;)
        every time they visit your site. You also probably want invalid URLs showing
        a pretty error page.&lt;/div&gt;\n&lt;br /&gt;\nYou can use &lt;a href=&quot;https://cloud.google.com/storage/docs/gsutil/commands/web&quot;&gt;&lt;b&gt;gsutil
        web&lt;/b&gt;&lt;/a&gt;&amp;nbsp;to configure the index and 404 pages for
        the bucket.&lt;br /&gt;\n&lt;br /&gt;\n&lt;code&gt;gsutil web set gs://my-super-bucket
        -m index.html -e 404.html&lt;/code&gt;&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nCaching, Compression, and Content Delivery&lt;/h3&gt;\n&lt;br
        /&gt;\nTo take advantage of Google&#39;s CDN (or even simply to improve bandwidth
        usage and latency), you should set the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control&quot;&gt;Cache-Control
        headers&lt;/a&gt; on your files. I like to keep the expiries for the index
        page short, and everything else long (of course, also adding content hashes
        to frequently modified files.)&lt;br /&gt;\n&lt;br /&gt;\nWe also want to
        make sure that text files are served with &lt;i&gt;gzip&lt;/i&gt; compression
        enabled. The &lt;code&gt;&lt;b&gt;-z&lt;/b&gt;&lt;/code&gt; flag compresses
        the file, and sets the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding&quot;&gt;content-encoding&lt;/a&gt;
        to &lt;i&gt;gzip&lt;/i&gt; while serving over HTTP(s).&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;code&gt;\ngsutil -h &quot;Cache-control:public,max-age=86400&quot;
        -m \\&lt;/code&gt;&lt;br /&gt;\n&lt;code&gt;&amp;nbsp; cp -a public-read -z
        js,map,css,svg \\&lt;br /&gt;\n&amp;nbsp; &amp;nbsp; $DIST/*.js $DIST/*.map
        $DIST/*.css \\&lt;br /&gt;\n&amp;nbsp; &amp;nbsp; $DIST/*.jpg $DIST/*.svg
        $DIST/*.png $DIST/*.ico \\&lt;br /&gt;\n&amp;nbsp; &amp;nbsp; gs://float64&lt;/code&gt;&lt;br
        /&gt;\n&lt;code&gt;&lt;br /&gt;\ngsutil -h &quot;Cache-control:public,max-age=300&quot;
        -m \\&lt;/code&gt;&lt;br /&gt;\n&lt;code&gt;&amp;nbsp; cp -a public-read -z
        html \\&lt;/code&gt;&lt;br /&gt;\n&lt;code&gt;&amp;nbsp; $DIST/index.html
        gs://float64&lt;/code&gt;&lt;br /&gt;\n&lt;code&gt;&lt;br /&gt;&lt;/code&gt;\nIf
        you&#39;ve made it this far, you now have a (nearly) production-ready website
        up and running. Congratulations!&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nSo, how much does it cost?&lt;/h3&gt;\n&lt;br /&gt;\nI have
        about 8 different websites running on different domains, all using managed
        certificates and the CDN, and I pay about $20 a month.&lt;br /&gt;\n&lt;br
        /&gt;\nI use a single load balancer ($18/mo) and one IP address ($2/mo) for
        all of them. I get about 10 - 20k requests a day across all my sites, and
        bandwidth costs are in the pennies.&lt;br /&gt;\n&lt;br /&gt;\nNot cheap,
        but not expensive either given the cognitive savings. And there are cheaper
        options (as you&#39;ll see in the next section).&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3
        style=&quot;text-align: left;&quot;&gt;\nAlternatives&lt;/h3&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\nThere are many ways to serve web content out of storage
        buckets, and this is just one. Depending on your traffic, the number of sites
        you&#39;re running, and what kinds of tradeoffs you&#39;re willing to make,
        you can optimize costs further.&lt;br /&gt;\n&lt;br /&gt;\n&lt;a href=&quot;https://firebase.google.com/docs/hosting&quot;&gt;Firebase
        Hosting&lt;/a&gt;&amp;nbsp;sticks all of this into one pretty package, with
        a lower upfront cost (however, the bandwidth costs are higher as your traffic
        increases.)&lt;br /&gt;\n&lt;br /&gt;\n&lt;a href=&quot;https://www.cloudflare.com/&quot;&gt;Cloudflare&lt;/a&gt;&amp;nbsp;has
        a&amp;nbsp;free plan and lets you stick an SSL server and CDN in front of
        your Cloud Storage bucket. However if you want dedicated certificates, they
        charge you $5 each. Also, the minimum TTL on the free plan is 2 hours, which
        is not great if you&#39;re building static Javascript applications.&lt;br
        /&gt;\n&lt;br /&gt;\nAnd there&#39;s &lt;a href=&quot;https://aws.amazon.com/cloudfront/&quot;&gt;CloudFront&lt;/a&gt;,
        &lt;a href=&quot;http://www.fastly.com/&quot;&gt;Fastly&lt;/a&gt;, &lt;a href=&quot;https://netlify.com/&quot;&gt;Netlify&lt;/a&gt;,
        all which provide various levels of managed infrastructure, still all better
        than running your own servers.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align:
        left;&quot;&gt;\nCaveats&lt;/h3&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;div&gt;\nObviously,
        there&#39;s no free lunch, and good engineering requires making tradeoffs,
        and here are a few things to consider before you decide to migrate from servers
        to buckets:&lt;/div&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;div&gt;\n&lt;ul
        style=&quot;text-align: left;&quot;&gt;\n&lt;li&gt;&lt;b&gt;Vendor lock-in.&lt;/b&gt;
        Are you okay with using proprietary technologies for your stack. If not, you&#39;re
        better off running your own servers.&lt;/li&gt;\n&lt;li&gt;&lt;b&gt;Control
        and Flexibility.&lt;/b&gt; Do you want advanced routing, URL rewriting, or
        other custom behavior? If so you&#39;re better off running your own servers.&lt;/li&gt;\n&lt;li&gt;&lt;b&gt;Cost
        transparency.&lt;/b&gt; Although both Google and Amazon do great jobs with
        billing and detailed price breakdowns, they are super complicated and can
        change on a whim.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div&gt;\nFor a lot of what
        I do, these downsides are well worth it. The vendor lock-in troubles me the
        most, however it&#39;s not hard to migrate this stuff to other providers if
        I need to.&lt;/div&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\n&lt;div&gt;\nIf
        you liked this, check out some of &lt;a href=&quot;https://0xfe.blogspot.com/&quot;&gt;my
        other stuff&lt;/a&gt; on this blog.&lt;/div&gt;\n&lt;br /&gt;\n&lt;br /&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/541596065311835171/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2020/02/no-servers-just-buckets-hosting-static.html#comment-form'
        title='1 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/541596065311835171'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/541596065311835171'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2020/02/no-servers-just-buckets-hosting-static.html'
        title='No Servers, Just Buckets: Hosting Static Websites on the Cloud'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhipsKbza7Qsm2JCe2LJwWdOlpRexWoh8IwF0JVLK9BsUaaiV9jaUctCtiSiG6FNjoHpspbjVPED27FoXPYh8L671CzC-azbBzqp3LQ0LyJtMvQw78R3yLdjX963KIRUSd87b3Azg/s72-c/Screen+Shot+2020-02-19+at+8.28.36+AM.png\"
        height=\"72\" width=\"72\"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-421690605020819859</id><published>2016-07-12T09:44:00.000-04:00</published><updated>2016-07-12T10:23:04.730-04:00</updated><title
        type='text'>New in VexFlow: ES6, Visual Regression Tests, and more!</title><content
        type='html'>&lt;div dir=&quot;ltr&quot; style=&quot;text-align: left;&quot;
        trbidi=&quot;on&quot;&gt;\nLots of developments since the last time I posted
        about VexFlow.&lt;br /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\n&lt;/h3&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nVexFlow
        is ES6&lt;/h3&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\nThanks to the heroics
        of &lt;a href=&quot;http://github.com/SilverWolf90&quot;&gt;SilverWolf90&lt;/a&gt;
        and &lt;a href=&quot;http://github.com/AaronMars&quot;&gt;AaronMars&lt;/a&gt;,
        and the help from many others, VexFlow&#39;s entire &lt;code&gt;src/&lt;/code&gt;
        tree has been migrated to ES6. This is a huge benefit to the project and to
        the health of the codebase. Some of the wins are:&lt;br /&gt;\n&lt;br /&gt;\n&lt;ul
        style=&quot;text-align: left;&quot;&gt;\n&lt;li&gt;Real modules, which allows
        us to extract explicit dependency information and generate graphs like &lt;a
        href=&quot;https://github.com/0xfe/vexflow/wiki/VexFlow-Dependency-Graph&quot;&gt;this&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;Const-correctness
        and predictable variable scoping with &lt;code&gt;const&lt;/code&gt; and &lt;code&gt;let&lt;/code&gt;.&lt;/li&gt;\n&lt;li&gt;Classes,
        lambda functions, and lots of other structural enhancements that vastly improve
        the clarity and conciseness of the codebase.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div&gt;\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3aiqkRZhH7qzKgGfHCA1yXvmcc4CvQwetLQEHvrQej3ugBVywShEIL3tPMIFw93rJU4Qf7yyerY2Ha60AgIvadGwq98fZLMrTLbzRg0h0y9v1XG_sIyFh4lVEmi2tq-HbikKDMg/s1600/Screen+Shot+2016-07-12+at+10.06.20+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;390&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3aiqkRZhH7qzKgGfHCA1yXvmcc4CvQwetLQEHvrQej3ugBVywShEIL3tPMIFw93rJU4Qf7yyerY2Ha60AgIvadGwq98fZLMrTLbzRg0h0y9v1XG_sIyFh4lVEmi2tq-HbikKDMg/s640/Screen+Shot+2016-07-12+at+10.06.20+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;br /&gt;\nPart
        of the migration effort also involved making everything lint-clean, improving
        the overall style and consistency of the codebase -- see &lt;a href=&quot;http://github.com/SilverWolf90&quot;&gt;SilverWolf90&lt;/a&gt;&#39;s
        brief document on how &lt;a href=&quot;https://github.com/0xfe/vexflow/wiki/Migrating-to-ESLint&quot;&gt;here&lt;/a&gt;.&lt;/div&gt;\n&lt;h3
        style=&quot;text-align: left;&quot;&gt;\n&lt;/h3&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nVisual
        Regression Tests&lt;/h3&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\nVexFlow
        now has a visual regression test system, and all image-generating QUnit tests
        are automatically included.&lt;br /&gt;\n&lt;br /&gt;\nThe goal of this system
        is to detect differences in the rendered output without having to rely on
        human eyeballs, especially given the huge number of tests that exist today.
        It does this by calculating a perceptual hash (PHASH) of each test image and
        comparing it with the hash of a good known blessed image. The larger the arithmetic
        distance between the hashes, the more different are the two images.&lt;br
        /&gt;\n&lt;br /&gt;\nThe system also generates a diff image, which is an overlay
        of the two images, with the differences highlighted, to ease debugging. Here&#39;s
        an example of a failing test:&lt;br /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxeptv0TDTSQB4_RFZOumVUFEhBNkP8P3mIiTWAJSVescGm8Fx5x0-qqZYZiPSfK8Vfrc9GiNxsjhdTzalnb243CDZ_LmqI8Y-TvxblFvAxOKT_aK_j7I4q6SZ8DcdUqIGuZlSvA/s1600/Screen+Shot+2016-07-12+at+9.46.16+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;640&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxeptv0TDTSQB4_RFZOumVUFEhBNkP8P3mIiTWAJSVescGm8Fx5x0-qqZYZiPSfK8Vfrc9GiNxsjhdTzalnb243CDZ_LmqI8Y-TvxblFvAxOKT_aK_j7I4q6SZ8DcdUqIGuZlSvA/s640/Screen+Shot+2016-07-12+at+9.46.16+AM.png&quot;
        width=&quot;600&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;br /&gt;\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;/div&gt;\nThese
        tests are run automatically for all PRs, commits, and releases. Props to &lt;a
        href=&quot;http://github.com/panarch&quot;&gt;Taehoon Moon&lt;/a&gt; for migrating
        the regression tests from NodeJS to SlimerJS, giving us headless support and
        Travis CI integration. To find out more, read the Wiki page on &lt;a href=&quot;https://github.com/0xfe/vexflow/wiki/Visual-Regression-Tests&quot;&gt;Visual
        Regression Tests&lt;/a&gt;.&lt;br /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\n&lt;/h3&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nNative
        SVG&lt;/h3&gt;\n&lt;div&gt;\n&lt;br /&gt;&lt;/div&gt;\nThanks to the awesome
        contribution of &lt;a href=&quot;http://github.com/gristow&quot;&gt;Gregory
        Ristow&lt;/a&gt;, VexFlow now has a native SVG rendering backend, and the
        &lt;a href=&quot;http://raphaeljs.com/&quot;&gt;RaphaelJS&lt;/a&gt; backend
        has been deprecated. This not only reduces the overall size and bloat, but
        also hugely improves rendering performance.&lt;br /&gt;\n&lt;br /&gt;\nThe
        new backend is called &lt;code&gt;Rendering.Backends.SVG&lt;/code&gt; with
        the code at&amp;nbsp;&lt;a href=&quot;https://github.com/0xfe/vexflow/blob/master/src/svgcontext.js&quot;&gt;Vex.Flow.SVGContext&lt;/a&gt;.
        Here is a quick example of how to use the new backend:&amp;nbsp;&lt;a href=&quot;https://jsfiddle.net/nL0cn3vL/2/&quot;&gt;https://jsfiddle.net/nL0cn3vL/2/&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nImproved
        Microtonal Support&lt;/h3&gt;\n&lt;br /&gt;\nVexFlow now has better support
        for Arabic, Turkish, and other microtonal music via accidentals and key signatures.
        Thanks to &lt;a href=&quot;http://github.com/infojunkie&quot;&gt;infojunkie&lt;/a&gt;
        for a lot of the heavy lifting here, and to all the contributors in the &lt;a
        href=&quot;https://github.com/0xfe/vexflow/issues/318&quot;&gt;GitHub issue&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKqsOnWIHkdB5VVqFfq6gj2wgiwJXzN1Sk8XR2qJX_6EZ-2xnrzBYL5eZy23MiDbm5GCvgNA_TBzjFQ8JOCoA2JlOVMD7rw3jQxk4YphClucw6TQGtnc1-ZJgNhWYtX18BKHKMcQ/s1600/Screen+Shot+2016-07-12+at+9.50.40+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;212&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKqsOnWIHkdB5VVqFfq6gj2wgiwJXzN1Sk8XR2qJX_6EZ-2xnrzBYL5eZy23MiDbm5GCvgNA_TBzjFQ8JOCoA2JlOVMD7rw3jQxk4YphClucw6TQGtnc1-ZJgNhWYtX18BKHKMcQ/s640/Screen+Shot+2016-07-12+at+9.50.40+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYh59DufskkVVEVorHw4Of9VzlaEjU2i2GG8p8q3-PpWfFZrbEcWs8rvfyiEvJ1gfJwvRoEjzkW88AzO4O2LUo-Vs3PU97AmA6ZINyvz5zm4vwfU_s89qNFNrcf56tys6hDXVN6w/s1600/Screen+Shot+2016-07-12+at+9.50.52+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;272&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYh59DufskkVVEVorHw4Of9VzlaEjU2i2GG8p8q3-PpWfFZrbEcWs8rvfyiEvJ1gfJwvRoEjzkW88AzO4O2LUo-Vs3PU97AmA6ZINyvz5zm4vwfU_s89qNFNrcf56tys6hDXVN6w/s640/Screen+Shot+2016-07-12+at+9.50.52+AM.png&quot;
        width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;\n&lt;br /&gt;\nMicrotonal
        support is by no means complete, but this is a noteworthy step forward in
        the space.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3 style=&quot;text-align: left;&quot;&gt;\nOther
        Stuff&lt;/h3&gt;\n&lt;br /&gt;\nLots of other stuff worth mentioning:&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;ul style=&quot;text-align: left;&quot;&gt;\n&lt;li&gt;Support
        for user interactivity in SVG notation. You can attach event-handlers to elements
        (or groups of elements) and dynamically modify various properties of the score.&lt;/li&gt;\n&lt;li&gt;Improved
        bounding-box support.&lt;/li&gt;\n&lt;li&gt;Alignment of clef, timesignature,
        and other stave modifiers during mid-measure changes.&lt;/li&gt;\n&lt;li&gt;Lots
        of improvements to the build system and Travis CI integration.&lt;/li&gt;\n&lt;li&gt;Lots
        of bug fixes related to beaming, tuplets, annotations, etc.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div&gt;\n&lt;br
        /&gt;&lt;/div&gt;\n&lt;div&gt;\nMany thanks to all the contributors involved!&lt;/div&gt;\n&lt;/div&gt;\n</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/421690605020819859/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2016/07/new-in-vexflow-es6-visual-regression.html#comment-form'
        title='2 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/421690605020819859'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/421690605020819859'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2016/07/new-in-vexflow-es6-visual-regression.html'
        title='New in VexFlow: ES6, Visual Regression Tests, and more!'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3aiqkRZhH7qzKgGfHCA1yXvmcc4CvQwetLQEHvrQej3ugBVywShEIL3tPMIFw93rJU4Qf7yyerY2Ha60AgIvadGwq98fZLMrTLbzRg0h0y9v1XG_sIyFh4lVEmi2tq-HbikKDMg/s72-c/Screen+Shot+2016-07-12+at+10.06.20+AM.png\"
        height=\"72\" width=\"72\"/><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-2970930225553638408</id><published>2014-05-02T11:18:00.000-04:00</published><updated>2014-05-02T11:18:34.873-04:00</updated><title
        type='text'>New in VexFlow (May 2014)</title><content type='html'>Lots of
        commits into the repository lately. Thanks to Cyril Silverman for may of these.
        Here are some of the highlights:\n\n&lt;p/&gt;\n\n&lt;h3&gt;Chord Symbols&lt;/h3&gt;\nThis
        includes subscript/superscript support in &lt;code&gt;TextNote&lt;/code&gt;
        and support for common symbols (dim, half-dim, maj7, etc.)\n&lt;p/&gt;\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhARWln9YaHdtVL5iBAiFKZHcGI85eDMyNLhN3USobfFRbFuq6FAZPsXK746YLJHrXEcb0Hpkbza1giiZ8sCb6I-1BVwuPTCNwkY8boODT0d1x7hYEnbys1OzHbdVRmwGwEYMSaSw/s1600/Screen+Shot+2014-05-02+at+10.51.12+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhARWln9YaHdtVL5iBAiFKZHcGI85eDMyNLhN3USobfFRbFuq6FAZPsXK746YLJHrXEcb0Hpkbza1giiZ8sCb6I-1BVwuPTCNwkY8boODT0d1x7hYEnbys1OzHbdVRmwGwEYMSaSw/s400/Screen+Shot+2014-05-02+at+10.51.12+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\n\n&lt;h3&gt;Stave Line Arrows&lt;/h3&gt;\nThis
        is typically used in instructional material.\n&lt;p/&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgNZTalVSVd5H_a4RBTaURK2A7MhCwpKTZDwqEC6j3ZALkCB3TFv4jfVQyX6GoiALkwsTkxnRK_Ntw7HuRm3S7n6ehmw8M1xa1qqysNo7HVxG06zc1y2TNE09PNp41kaGqiHo32tg/s1600/Screen+Shot+2014-05-02+at+10.50.57+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgNZTalVSVd5H_a4RBTaURK2A7MhCwpKTZDwqEC6j3ZALkCB3TFv4jfVQyX6GoiALkwsTkxnRK_Ntw7HuRm3S7n6ehmw8M1xa1qqysNo7HVxG06zc1y2TNE09PNp41kaGqiHo32tg/s400/Screen+Shot+2014-05-02+at+10.50.57+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgdoHUP3nNvIHRvV0nF_w0sv1dI7Lrir4jLiyzMNMQgMUrsgH-HkATiIUUjoYYprV9rOSCkX8-UyUCRT-331MsHJ-BTkjuBh3k-Zqq019RbKHpYP3vOjZcd3mKY7p_xiUmPkJlK5Q/s1600/Screen+Shot+2014-05-02+at+10.51.06+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgdoHUP3nNvIHRvV0nF_w0sv1dI7Lrir4jLiyzMNMQgMUrsgH-HkATiIUUjoYYprV9rOSCkX8-UyUCRT-331MsHJ-BTkjuBh3k-Zqq019RbKHpYP3vOjZcd3mKY7p_xiUmPkJlK5Q/s400/Screen+Shot+2014-05-02+at+10.51.06+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\n\n&lt;h3&gt;Slurs&lt;/h3&gt;\nFinally,
        we have slurs. This uses a new VexFlow class called &lt;code&gt;Curve&lt;/code&gt;.
        Slurs are highly configurable.\n&lt;p/&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiwVjQOCOtb9K1roaI9Fkpdjer-LJGK_ItJNjilN5fxykR6nkpjO_ZG_Ows3HH20ix8sIOZrzb0jm5Z-VmqP2JjwAB_KuRQgvIXF618OUC7R4T6r5WfPzFq_E4ogC_Lak_wYGIkhg/s1600/Screen+Shot+2014-05-02+at+10.51.24+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiwVjQOCOtb9K1roaI9Fkpdjer-LJGK_ItJNjilN5fxykR6nkpjO_ZG_Ows3HH20ix8sIOZrzb0jm5Z-VmqP2JjwAB_KuRQgvIXF618OUC7R4T6r5WfPzFq_E4ogC_Lak_wYGIkhg/s400/Screen+Shot+2014-05-02+at+10.51.24+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhatECDRLVFWQyBskqVOcVUOZg66Jcywok5t9qyAfIVcqHoUfCZa1J2Ga1Gxrp3dpiFA7Zbm6I1XGGRrWBMX6fcZ5oZDxlWZu0hR1UVipMdAgmEf-96gHbWgppln4Dp2DOsBhIAxg/s1600/Screen+Shot+2014-05-02+at+10.51.29+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhatECDRLVFWQyBskqVOcVUOZg66Jcywok5t9qyAfIVcqHoUfCZa1J2Ga1Gxrp3dpiFA7Zbm6I1XGGRrWBMX6fcZ5oZDxlWZu0hR1UVipMdAgmEf-96gHbWgppln4Dp2DOsBhIAxg/s400/Screen+Shot+2014-05-02+at+10.51.29+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgc_eVlyXPeFIevIo9au9bCa75PKtHctY2oRecgdQl15Gspn0s_i7uZK_7t6UclD-UAqCXFCJrozYETXUqg45BobYrgRGs0EZkTpCMriR21P0CdLfaH5sDfSVljgqHokOQwHM7Kbw/s1600/Screen+Shot+2014-05-02+at+10.51.36+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgc_eVlyXPeFIevIo9au9bCa75PKtHctY2oRecgdQl15Gspn0s_i7uZK_7t6UclD-UAqCXFCJrozYETXUqg45BobYrgRGs0EZkTpCMriR21P0CdLfaH5sDfSVljgqHokOQwHM7Kbw/s400/Screen+Shot+2014-05-02+at+10.51.36+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiedlG-ypZuwWHvQl6PNXpcjXV-qnrHI4QbHCX4b-xPrLfwm7i9JJjhDTORtXX2WYL-N5hzGEuGK0PFvdifZmnqU-QjRA9L1HeZ2LDC5XLe0SpiprIkafTO1_CS-66aWyGiSZpNsw/s1600/Screen+Shot+2014-05-02+at+10.51.45+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiedlG-ypZuwWHvQl6PNXpcjXV-qnrHI4QbHCX4b-xPrLfwm7i9JJjhDTORtXX2WYL-N5hzGEuGK0PFvdifZmnqU-QjRA9L1HeZ2LDC5XLe0SpiprIkafTO1_CS-66aWyGiSZpNsw/s400/Screen+Shot+2014-05-02+at+10.51.45+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\n\n&lt;h3&gt;Improved auto-positioning
        of Annotations and Articulations&lt;/h3&gt;\nAnnotations and Articulations
        now self-position based on note, stem, and beam configuration.\n&lt;p/&gt;\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgU13FCOX7XCOL9mnXofqMUGuOmGJbJvbCtUIixCdxqASZmSCLZNmPQ773x2hY5lWiPHorbJak3YtUg1BuhcV1HajHha3ryLrlId4AczhzrqALlOhdvm2wyBiz7ha8SZwRliBj11A/s1600/Screen+Shot+2014-05-02+at+10.54.03+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgU13FCOX7XCOL9mnXofqMUGuOmGJbJvbCtUIixCdxqASZmSCLZNmPQ773x2hY5lWiPHorbJak3YtUg1BuhcV1HajHha3ryLrlId4AczhzrqALlOhdvm2wyBiz7ha8SZwRliBj11A/s400/Screen+Shot+2014-05-02+at+10.54.03+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\n\n&lt;h3&gt;Grace Notes&lt;/h3&gt;\nVexFlow
        now has full support for Grace Notes. Grace Note groups can contain complex
        rhythmic elements, and are formatted using the same code as regular notes.\n\n&lt;p/&gt;\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSotGzQBCA_ljoJpIQM6N011kQTZ5AhkdoLgqO8ORq42h05hh82Rs_q9HBUN5lEkkba8_TbMNhx04aJ48K0GyPzsH1BHXG-1cNljOjvZgVfz7qGhcHD-N8KhS1juvDqSu7ECcd6g/s1600/Screen+Shot+2014-05-02+at+10.54.30+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSotGzQBCA_ljoJpIQM6N011kQTZ5AhkdoLgqO8ORq42h05hh82Rs_q9HBUN5lEkkba8_TbMNhx04aJ48K0GyPzsH1BHXG-1cNljOjvZgVfz7qGhcHD-N8KhS1juvDqSu7ECcd6g/s400/Screen+Shot+2014-05-02+at+10.54.30+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZOxD9_LTKefUh0Vs9iqFpzlLI55B7tYSYKx79Zv43GL0BhyMqmfi63i7ulWmY1FrXmN_5HnFmORvMqCNA0yUX-jQEi6MJOv4cO3HBBvde5m1VOeRPzEXxvEO_FwR2qceVl1Zixg/s1600/Screen+Shot+2014-05-02+at+10.54.37+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZOxD9_LTKefUh0Vs9iqFpzlLI55B7tYSYKx79Zv43GL0BhyMqmfi63i7ulWmY1FrXmN_5HnFmORvMqCNA0yUX-jQEi6MJOv4cO3HBBvde5m1VOeRPzEXxvEO_FwR2qceVl1Zixg/s400/Screen+Shot+2014-05-02+at+10.54.37+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\n\n&lt;h3&gt;Auto-Beam Imnprovements&lt;/h3&gt;\nLots
        more beaming options, including beaming over rests, stemlet rendering, and
        time-signature aware beaming.\n\n&lt;p/&gt;\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjULM-Ju99byoC-ygScvma7aMv67b6ruuqb27v6rZiaQf-kvPep0n_nn8SSmm1XFFdML16g8vhXjFNaJu3gfNDCqiQ5UD69eWnvx0IFj9lfC6RRhHLcmv_v8C0MeHdwizCb01XJTg/s1600/Screen+Shot+2014-05-02+at+10.54.58+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjULM-Ju99byoC-ygScvma7aMv67b6ruuqb27v6rZiaQf-kvPep0n_nn8SSmm1XFFdML16g8vhXjFNaJu3gfNDCqiQ5UD69eWnvx0IFj9lfC6RRhHLcmv_v8C0MeHdwizCb01XJTg/s400/Screen+Shot+2014-05-02+at+10.54.58+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgovZ5gaOWJyLcc9DxyQX0yI54NK-hy3hSgukICa5-gMrGTaFbVR1OXhoWjS7TkX5CDtoiBRQC4S88QBNv_IHsnRU5U8nKB0H8xHPEuU2o3goALytt_ayQgkMyCNicq7dCJ8qmgQg/s1600/Screen+Shot+2014-05-02+at+10.55.15+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgovZ5gaOWJyLcc9DxyQX0yI54NK-hy3hSgukICa5-gMrGTaFbVR1OXhoWjS7TkX5CDtoiBRQC4S88QBNv_IHsnRU5U8nKB0H8xHPEuU2o3goALytt_ayQgkMyCNicq7dCJ8qmgQg/s400/Screen+Shot+2014-05-02+at+10.55.15+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihdUTDYtKZhcd-HQjXBxzNPfL0VycfORZBI7xoQWZ3Re4VpaLb9Ka59EL1WivBVfmt1cERK5RhN7zs0mbvxFwzbucMkfL50UYk7epEViA7L3UDk5ihFNJIGVdHmNTgZQ0gjPGrHg/s1600/Screen+Shot+2014-05-02+at+10.55.25+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihdUTDYtKZhcd-HQjXBxzNPfL0VycfORZBI7xoQWZ3Re4VpaLb9Ka59EL1WivBVfmt1cERK5RhN7zs0mbvxFwzbucMkfL50UYk7epEViA7L3UDk5ihFNJIGVdHmNTgZQ0gjPGrHg/s400/Screen+Shot+2014-05-02+at+10.55.25+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg7hzcAqJ2cabV3VXA9JCKovDSwx5yKTJB8lKEOmOmHZ_VKoM9uTktsiIR6f2ulKVShwrOm7v7dUuPvNPM3E5EZ-YupxVdfz9EXHRr_FMaOlhsoP5At99tKHoVBmU9CX9-YpIMjhA/s1600/Screen+Shot+2014-05-02+at+10.55.35+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg7hzcAqJ2cabV3VXA9JCKovDSwx5yKTJB8lKEOmOmHZ_VKoM9uTktsiIR6f2ulKVShwrOm7v7dUuPvNPM3E5EZ-YupxVdfz9EXHRr_FMaOlhsoP5At99tKHoVBmU9CX9-YpIMjhA/s400/Screen+Shot+2014-05-02+at+10.55.35+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\n&lt;h3&gt;Tab-Stem Features&lt;/h3&gt;\n\nYou
        can (optionally) render Tab Stems through stave lines.\n&lt;p/&gt;\n\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjfsQjfpN66Lpyq_IC4dTlXCypbUy3s8wEOE1Tf-j0hRUS3JkAYk2C5topEC4P0cA2ZgQ2A7gxP1djMAp8ecedWzJgaO_lHOELzrFZq8EebqIO3Y7QZxa67UAKluCDHNhv-QgNkWQ/s1600/Screen+Shot+2014-05-02+at+10.57.42+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjfsQjfpN66Lpyq_IC4dTlXCypbUy3s8wEOE1Tf-j0hRUS3JkAYk2C5topEC4P0cA2ZgQ2A7gxP1djMAp8ecedWzJgaO_lHOELzrFZq8EebqIO3Y7QZxa67UAKluCDHNhv-QgNkWQ/s400/Screen+Shot+2014-05-02+at+10.57.42+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\n\nThat&#39;s all, Folks!</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/2970930225553638408/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2014/05/new-in-vexflow.html#comment-form'
        title='19 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/2970930225553638408'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/2970930225553638408'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2014/05/new-in-vexflow.html'
        title='New in VexFlow (May 2014)'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhARWln9YaHdtVL5iBAiFKZHcGI85eDMyNLhN3USobfFRbFuq6FAZPsXK746YLJHrXEcb0Hpkbza1giiZ8sCb6I-1BVwuPTCNwkY8boODT0d1x7hYEnbys1OzHbdVRmwGwEYMSaSw/s72-c/Screen+Shot+2014-05-02+at+10.51.12+AM.png\"
        height=\"72\" width=\"72\"/><thr:total>19</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-6880188793332322250</id><published>2012-01-02T13:34:00.000-05:00</published><updated>2012-01-02T13:34:24.100-05:00</updated><title
        type='text'>More K-Means Clustering Experiments on Images</title><content
        type='html'>I spent a little more time experimenting with &lt;a href=&quot;http://0xfe.blogspot.com/2011/12/k-means-clustering-and-art.html&quot;&gt;k-means
        clustering&lt;/a&gt; on images and realized that I could use these clusters
        to recolor the image in interesting ways.\n&lt;p/&gt;\nI wrote the function
        &lt;code&gt;save_recolor&lt;/code&gt; to replace pixels from the given clusters
        (&lt;code&gt;replacements&lt;/code&gt;) with new ones of equal intensity,
        as specified by the &lt;code&gt;rgb_factors&lt;/code&gt; vector. For example,
        the following code will convert pixels of the first two clusters to greyscale.\n&lt;p/&gt;\n&lt;pre
        class=&quot;prettyprint&quot;&gt;\n&amp;gt; save_recolor(&quot;baby.jpeg&quot;,
        &quot;baby_new.jpg&quot;, replacements=c(1,2),\n               rgb_factors=c(1/3,
        1/3, 1/3))\n&lt;/pre&gt;\n&lt;p/&gt;\nIt&#39;s greyscale because the &lt;code&gt;rgb_factors&lt;/code&gt;
        distributes the pixel intensity evenly among the channels. A factor of &lt;code&gt;c(20/100,
        60/100, 20/100)&lt;/code&gt; would make pixels from the cluster 60% more green.\n&lt;p/&gt;\nLet&#39;s
        get to some examples. Here&#39;s an unprocessed image, alongside its color
        clusters. I picked &lt;code&gt;k=10&lt;/code&gt;. You can set &lt;code&gt;k&lt;/code&gt;
        by specifying the &lt;code&gt;palette_size&lt;/code&gt; parameter to &lt;code&gt;save_recolor&lt;/code&gt;.\n\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnRdj14UpXHdCnqTwLonrOWUuqLfH09kzSImmQpt8gaPgq8udoZZCtbCcvejK2mvW0u9RKzC355jFpINb2sxNvMccNBy5z8j477Vx0HLeTB87Mww1nldLP6aQ7qZn5mOalIi7-Tw/s1600/Screen+shot+2012-01-01+at+12.16.45+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;274&quot; width=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnRdj14UpXHdCnqTwLonrOWUuqLfH09kzSImmQpt8gaPgq8udoZZCtbCcvejK2mvW0u9RKzC355jFpINb2sxNvMccNBy5z8j477Vx0HLeTB87Mww1nldLP6aQ7qZn5mOalIi7-Tw/s400/Screen+shot+2012-01-01+at+12.16.45+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\nHere&#39;s what happens when I
        remove the red (the first cluster).\n\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj21ggbKmvK0T2hmbK5tWykQeThSTgl-n-NtJnxUF0v7xQf0DAQV6IXutPz2DuPxFVqBNim_dAvmKQ3xWcGOXrN1tc9NSb-LM2rj-1sAMVV_W6YLkX3dVST_CnlzaE6D4IzfwMUFw/s1600/arkin_recolor_nored.jpg&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;400&quot; width=&quot;300&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj21ggbKmvK0T2hmbK5tWykQeThSTgl-n-NtJnxUF0v7xQf0DAQV6IXutPz2DuPxFVqBNim_dAvmKQ3xWcGOXrN1tc9NSb-LM2rj-1sAMVV_W6YLkX3dVST_CnlzaE6D4IzfwMUFw/s400/arkin_recolor_nored.jpg&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;pre class=&quot;prettyprint&quot;&gt;\n&amp;gt;
        save_recolor(&quot;baby.jpeg&quot;, &quot;baby_new.jpg&quot;, replacements=1)\n&lt;/pre&gt;\n\n\n&lt;p/&gt;\nIn
        the next image, I keep the red, and remove everything else.\n\n&lt;div class=&quot;separator&quot;
        style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhA27bcS661NHy3BNusm97m9j8-jR-DYdF-rRYXgjwfZcSE08rY8qwFakOGzHk35tbuanWAJBf4QRySbcDvzE0vmDvlM0S4l1AOGHb8J6NIjCeBWAaDIZNfp8WH3puF_uqPN7K4DA/s1600/arkin_recolor_red.jpeg&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;400&quot; width=&quot;300&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhA27bcS661NHy3BNusm97m9j8-jR-DYdF-rRYXgjwfZcSE08rY8qwFakOGzHk35tbuanWAJBf4QRySbcDvzE0vmDvlM0S4l1AOGHb8J6NIjCeBWAaDIZNfp8WH3puF_uqPN7K4DA/s400/arkin_recolor_red.jpeg&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;pre class=&quot;prettyprint&quot;&gt;\n&amp;gt;
        save_recolor(&quot;baby.jpeg&quot;, &quot;baby_new.jpg&quot;, replacements=2:10)\n&lt;/pre&gt;\n\n\n&lt;p/&gt;\nBelow,
        I replace the red cluster pixels, with green ones of corresponding intensity.\n\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiwxVeNhcer-um9mLCAKIdpVqaI5GsohQzeHECRjZ7bI6gDEHzsp45SuCy7GjANE9IYAXdI0qBmf4ZEO8yWwgPWWy8MOW_O8MGnr1BDR1A3P4U90SXaYy1fmBlQU8pRiSNHXZdKug/s1600/arkin_recolor_green.jpg&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;400&quot; width=&quot;300&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiwxVeNhcer-um9mLCAKIdpVqaI5GsohQzeHECRjZ7bI6gDEHzsp45SuCy7GjANE9IYAXdI0qBmf4ZEO8yWwgPWWy8MOW_O8MGnr1BDR1A3P4U90SXaYy1fmBlQU8pRiSNHXZdKug/s400/arkin_recolor_green.jpg&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;pre class=&quot;prettyprint&quot;&gt;\n&amp;gt;
        save_recolor(&quot;baby.jpeg&quot;, &quot;baby_new.jpg&quot;, replacements=1,\n
        \              rgb_factors=c(10/100, 80/100, 10/100))\n&lt;/pre&gt;\n\n&lt;p/&gt;\nAnd
        this is a fun one: Get rid of everything, keep just the grass.\n\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSuSiJ8ulDFAstlCFQkYTAJIRIhYSVl_jrUYMaC-G4D9hmpIEBMnkl3DI4B54Kvi28b5q4qJPBS8M9w0OBPqLebGd5-nNN32MUJioCg-cFx3hhoEwARmexWb9kLyd20u8NIAu_Aw/s1600/arkin_recolor_grass.jpg&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;400&quot; width=&quot;300&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSuSiJ8ulDFAstlCFQkYTAJIRIhYSVl_jrUYMaC-G4D9hmpIEBMnkl3DI4B54Kvi28b5q4qJPBS8M9w0OBPqLebGd5-nNN32MUJioCg-cFx3hhoEwARmexWb9kLyd20u8NIAu_Aw/s400/arkin_recolor_grass.jpg&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n\n&lt;pre class=&quot;prettyprint&quot;&gt;\n&amp;gt;
        save_recolor(&quot;baby.jpeg&quot;, &quot;baby_new.jpg&quot;, replacements=c(1,3:10))\n&lt;/pre&gt;\n\n&lt;p/&gt;\nI
        tried this on various images, using different cluster sizes, replacements,
        and RGB factors, with lots of interesting results. Anyhow, you should experiment
        with this yourselves and let me know what you find.\n&lt;p/&gt;\nI should
        point out that nothing here is novel or new -- it&#39;s all well known in
        image processing circles. It&#39;s still pretty impressive what you can do
        when you apply simple machine learning algorithms to other areas.\n\n&lt;p&gt;\nOkay,
        as in all my posts, the code is available in my &lt;a href=&quot;http://github.com/0xfe&quot;&gt;GitHub
        repository&lt;/a&gt;:\n&lt;p/&gt;\n&lt;a href=&quot;https://github.com/0xfe/experiments/blob/master/r/recolor.rscript&quot;&gt;https://github.com/0xfe/experiments/blob/master/r/recolor.rscript&lt;/a&gt;\n\n&lt;p/&gt;\nHappy
        new year!</content><link rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/6880188793332322250/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2012/01/more-k-means-clustering-experiments-on.html#comment-form'
        title='3 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6880188793332322250'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6880188793332322250'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2012/01/more-k-means-clustering-experiments-on.html'
        title='More K-Means Clustering Experiments on Images'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjnRdj14UpXHdCnqTwLonrOWUuqLfH09kzSImmQpt8gaPgq8udoZZCtbCcvejK2mvW0u9RKzC355jFpINb2sxNvMccNBy5z8j477Vx0HLeTB87Mww1nldLP6aQ7qZn5mOalIi7-Tw/s72-c/Screen+shot+2012-01-01+at+12.16.45+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-8650024762996646704</id><published>2011-12-31T10:27:00.000-05:00</published><updated>2011-12-31T14:14:34.568-05:00</updated><title
        type='text'>K-Means Clustering and Art</title><content type='html'>&lt;i&gt;Cross
        posted from &lt;a href=&quot;https://plus.google.com/u/0/111867441083313519234/posts/dxp5w3R7ts3&quot;&gt;Google+&lt;/a&gt;.&lt;/i&gt;\n&lt;p/&gt;\nMy
        coworker at Google, Tony Rippy, has for a while been working on a fascinating
        problem. Take all the pixels of a photograph, and rearrange them so that the
        final image looks like an artist&#39;s palette -- something to which you can
        take a paintbrush and recreate the original image.\n&lt;p/&gt;\nHe&#39;s got
        some really good looking solutions which he might post if you ask him nicely.
        :-)\n&lt;p/&gt;\nThis turns out to be a tricky problem, and its hard to come
        up with an objective measure of the quality of any given solution. In fact,
        the quality is very subjective.\n&lt;p/&gt;\nAnyhow, while studying the &lt;a
        href=&quot;http://en.wikipedia.org/wiki/K-means_clustering&quot;&gt;K-means
        clustering algorithm&lt;/a&gt; from &lt;a href=&quot;http://www.ml-class.org&quot;&gt;ml-class&lt;/a&gt;,
        it struck me that &lt;i&gt;k-means&lt;/i&gt; could be used to help with extracting
        a small palette of colors from an image. For example, by using each of the
        RGB channels as features, and euclidian distance as the similarity metric,
        one could run stock &lt;i&gt;k-means&lt;/i&gt; to generate clusters of similar
        colors.\n&lt;p/&gt;\nI coded up a quick R script to test this and got some
        interesting results. Here is an example of an image with its potential palette.
        Recall that the second image is simply the first image with the pixels rearranged.\n&lt;p/&gt;\n\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxNbcvY4I9RIAU91lzjK2m8HR9V5o9fhVa8AYncnYU1uhzq6uHAB3r0NgMlndNIw_TZG5S0gqcZmf-cV6A0A5ll8v66DqrHqoC9nPSWGVpfdAW1qGMape3yvvrC5_q019LmHJ74g/s1600/Screen+shot+2011-12-30+at+1.58.13+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;180&quot; width=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxNbcvY4I9RIAU91lzjK2m8HR9V5o9fhVa8AYncnYU1uhzq6uHAB3r0NgMlndNIw_TZG5S0gqcZmf-cV6A0A5ll8v66DqrHqoC9nPSWGVpfdAW1qGMape3yvvrC5_q019LmHJ74g/s400/Screen+shot+2011-12-30+at+1.58.13+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n\n&lt;p/&gt;\nI experimented with various values
        of &lt;i&gt;k&lt;/i&gt; (number of clusters) for the different images. It
        turns out that it&#39;s pretty hard to algorithmically pre-determine this
        number (although there are various techniques that do exist.) The water villa
        pic above has 15 clusters, the nursery pic below has 20, and the cartoon has
        6.\n&lt;p/&gt;\n&lt;div class=&quot;separator&quot; style=&quot;clear: both;
        text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-MFHMYHmP27nm5qteBSwvHnYI6jfyLCVledC8UBk9t8tjffNwLd4jldB691bTfQmNuBkQaQXQ-bEuEFYo-Z09908pU09B1VrhQmccYFw9hyphenhyphen0WL69_XQXRn2GnnWppDi64dVW_lg/s1600/Screen+shot+2011-12-30+at+1.57.12+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;235&quot; width=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-MFHMYHmP27nm5qteBSwvHnYI6jfyLCVledC8UBk9t8tjffNwLd4jldB691bTfQmNuBkQaQXQ-bEuEFYo-Z09908pU09B1VrhQmccYFw9hyphenhyphen0WL69_XQXRn2GnnWppDi64dVW_lg/s400/Screen+shot+2011-12-30+at+1.57.12+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\nNote that this is only one subproblem
        of the original one; there is also the subproblem of placement, which I skirted
        around by simply arranging the colors in vertical bands across the final image.
        I&#39;m pretty sure no artist&#39;s palette looks like this.\n&lt;p/&gt;\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhlwZAhtmIefeK5li5WDXi9R8ieeu1d9aKww6_JScrZ9IbPnQqT1um3HKhpVcsH7X7yG-T0j873HOt-t0kOz3W4UryfCA_qzFFYNzbVv66X0zBGUzx_rP7dZiKnSXd8RkWNhGreQg/s1600/Screen+shot+2011-12-30+at+1.57.49+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;182&quot; width=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhlwZAhtmIefeK5li5WDXi9R8ieeu1d9aKww6_JScrZ9IbPnQqT1um3HKhpVcsH7X7yG-T0j873HOt-t0kOz3W4UryfCA_qzFFYNzbVv66X0zBGUzx_rP7dZiKnSXd8RkWNhGreQg/s400/Screen+shot+2011-12-30+at+1.57.49+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n\n&lt;p/&gt;\nAlso, these palettes aren&#39;t
        very &quot;clean&quot;. Since the original pictures themselves are noisy,
        some of this noise arbitrarily creep into the various clusters. Working with
        a filtered version of the picture would be cheating, so we won&#39;t do that.
        But we might be able to extract the noisy pixels, put them in a special cluster,
        and run &lt;i&gt;k-means&lt;/i&gt; on the remaining pixels.\n&lt;p/&gt;\nOkay,
        enough talk. Here&#39;s the code: &lt;a href=&quot;https://github.com/0xfe/experiments/blob/master/r/palette.rscript&quot;&gt;https://github.com/0xfe/experiments/blob/master/r/palette.rscript&lt;/a&gt;\n&lt;p/&gt;\nFirst
        install &lt;code&gt;cclust&lt;/code&gt; and &lt;code&gt;ReadImages&lt;/code&gt;
        packages from &lt;a href=&quot;http://cran.r-project.org&quot;&gt;CRAN&lt;/a&gt;,
        and try out the algorithm in an R console:\n&lt;p/&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;\n&amp;gt;
        source(&#39;/path/to/palette.rscript&#39;)\n&amp;gt; plot_palette(&#39;/path/to/some/image.jpg&#39;)\n&lt;/pre&gt;\n&lt;p/&gt;\nThis
        will produce a plot with the original image and the transformed one next to
        each other, like the attached pics below. It uses 10 clusters by default,
        for a palette of 10 colors. You can change this by passing the cluster count
        as the second parameter to &lt;code&gt;plot_palette&lt;/code&gt;.\n&lt;p/&gt;\n&lt;pre
        class=&quot;prettyprint&quot;&gt;\n&amp;gt; plot_palette(&#39;/path/to/some/image.jpg&#39;,
        20)\n&lt;/pre&gt;\n&lt;p/&gt;\nThat&#39;s all folks!</content><link rel='replies'
        type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/8650024762996646704/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2011/12/k-means-clustering-and-art.html#comment-form'
        title='18 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/8650024762996646704'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/8650024762996646704'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2011/12/k-means-clustering-and-art.html'
        title='K-Means Clustering and Art'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxNbcvY4I9RIAU91lzjK2m8HR9V5o9fhVa8AYncnYU1uhzq6uHAB3r0NgMlndNIw_TZG5S0gqcZmf-cV6A0A5ll8v66DqrHqoC9nPSWGVpfdAW1qGMape3yvvrC5_q019LmHJ74g/s72-c/Screen+shot+2011-12-30+at+1.58.13+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>18</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-7852661428465635210</id><published>2011-08-21T11:15:00.000-04:00</published><updated>2011-08-21T21:37:53.266-04:00</updated><category
        scheme=\"http://www.blogger.com/atom/ns#\" term=\"webaudio\"/><title type='text'>A
        Web Audio Spectrum Analyzer</title><content type='html'>In my last post, I
        went over some of the &lt;a href=&quot;http://0xfe.blogspot.com/2011/08/generating-tones-with-web-audio-api.html&quot;&gt;basics
        of the Web Audio API&lt;/a&gt; and showed you how to generate &lt;a href=&quot;http://0xfe.muthanna.com/tone&quot;&gt;sine
        waves&lt;/a&gt; of various frequencies and amplitudes. We were introduced
        to some key &lt;a href=&quot;https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html&quot;&gt;Web
        Audio classes&lt;/a&gt;, such as &lt;code&gt;AudioContext&lt;/code&gt;, &lt;code&gt;AudioNode&lt;/code&gt;,
        and &lt;code&gt;JavaScriptAudioNode&lt;/code&gt;.\n&lt;p/&gt;\nThis time,
        I&#39;m going to go take things a little further and build a realtime spectrum
        analyzer with Web Audio and HTML5 Canvas. The final product plays a remote
        music file, and displays the frequency spectrum overlaid with a time domain
        graph.\n&lt;p/&gt;\n\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgpX14OzEMC3DnQ74e2TZUz2RSTwgECiV182MM7scAFYjkJTdyT5xMNYngRGYwOy-FaaGIcnO-geVMsVzpfgcG0smJChWAWouNtkZMxUCWIT7LJdIq7JojMIpsAmfMOD5MMIx0lAg/s1600/Screen+shot+2011-08-20+at+11.47.10+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;234&quot; width=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgpX14OzEMC3DnQ74e2TZUz2RSTwgECiV182MM7scAFYjkJTdyT5xMNYngRGYwOy-FaaGIcnO-geVMsVzpfgcG0smJChWAWouNtkZMxUCWIT7LJdIq7JojMIpsAmfMOD5MMIx0lAg/s400/Screen+shot+2011-08-20+at+11.47.10+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\nThe demo is here: &lt;a href=&quot;http://0xfe.muthanna.com/wavebox&quot;&gt;JavaScript
        Spectrum Analyzer&lt;/a&gt;. The code for the demo is in my &lt;a href=&quot;https://github.com/0xfe/experiments/tree/master/www/wavebox&quot;&gt;GitHub&lt;/a&gt;
        repository.\n&lt;p/&gt;\n&lt;h3&gt;The New Classes&lt;/h3&gt;\n&lt;p/&gt;\nIn
        this post we introduce three new Web Audio classes: &lt;code&gt;AudioBuffer&lt;/code&gt;,
        &lt;code&gt;AudioBufferSourceNode&lt;/code&gt;, and &lt;code&gt;RealtimeAnalyzerNode&lt;/code&gt;.\n&lt;p/&gt;\nAn
        &lt;code&gt;AudioBuffer&lt;/code&gt; represents an in-memory audio asset.
        It is usually used to store short audio clips and can contain multiple channels.\n&lt;p/&gt;\nAn
        &lt;code&gt;AudioBufferSourceNode&lt;/code&gt; is a specialization of &lt;code&gt;AudioNode&lt;/code&gt;
        that serves audio from &lt;code&gt;AudioBuffer&lt;/code&gt;s.\n&lt;p/&gt;\nA
        &lt;code&gt;RealtimeAnalyzerNode&lt;/code&gt; is an &lt;code&gt;AudioNode&lt;/code&gt;
        that returns time- and frequency-domain analysis information in real time.\n\n&lt;p/&gt;\n&lt;h3&gt;The
        Plumbing&lt;/h3&gt;\n&lt;p/&gt;\n\nTo begin, we need to acquire some audio.
        The API supports a number of different formats, including MP3 and raw PCM-encoded
        audio. In our demo, we retrieve a remote audio asset (an MP3 file) using AJAX,
        and use it to populate a new &lt;code&gt;AudioBuffer&lt;/code&gt;. This is
        implemented in the &lt;code&gt;RemoteAudioPlayer&lt;/code&gt; class (&lt;a
        href=&quot;https://github.com/0xfe/experiments/blob/master/www/wavebox/js/remoteaudioplayer.js&quot;&gt;js/remoteaudioplayer.js&lt;/a&gt;)
        like so:\n\n&lt;pre class=&quot;prettyprint&quot;&gt;\nRemoteAudioPlayer.prototype.load
        = function(callback) {\n  var request = new XMLHttpRequest();\n  var that
        = this;\n  request.open(&quot;GET&quot;, this.url, true);\n  request.responseType
        = &quot;arraybuffer&quot;;\n  request.onload = function() {\n    that.buffer
        = that.context.createBuffer(request.response, true);\n    that.reload();\n
        \   callback(request.response);\n  }\n\n  request.send();\n}\n&lt;/pre&gt;\n\nNotice
        that the &lt;i&gt;jQuery&lt;/i&gt;&#39;s AJAX calls aren&#39;t used here.
        This is because jQuery does not support the &lt;i&gt;arraybuffer&lt;/i&gt;
        response type, which is required for loading binary data from the server.
        The &lt;code&gt;AudioBuffer&lt;/code&gt; is created with the &lt;code&gt;AudioContext&lt;/code&gt;&#39;s
        &lt;code&gt;createBuffer&lt;/code&gt; function. The second parameter, &lt;code&gt;true&lt;/code&gt;,
        tells it to mix down all the channels to a single mono channel.\n\n&lt;p/&gt;\nThe
        &lt;code&gt;AudioBuffer&lt;/code&gt; is then provided to an &lt;code&gt;AudioBufferSourceNode&lt;/code&gt;,
        which will be the context&#39;s audio source. This source node is then connected
        to a &lt;code&gt;RealTimeAnalyzerNode&lt;/code&gt;, which in turn is connected
        to the context&#39;s destination, i.e, the computer&#39;s output device.\n\n&lt;pre
        class=&quot;prettyprint&quot;&gt;\nvar source_node = context.createBufferSource();\nsource_node.buffer
        = audio_buffer;\n\nvar analyzer = context.createAnalyser();\nanalyzer.fftSize
        = 2048; // 2048-point FFT\nsource_node.connect(analyzer);\nanalyzer.connect(context.destination);\n&lt;/pre&gt;\n\nTo
        start playing the music, call the &lt;code&gt;noteOn&lt;/code&gt; method of
        the source node. &lt;code&gt;noteOn&lt;/code&gt; takes one parameter: a timestamp
        indicating when to start playing. If set to &lt;code&gt;0&lt;/code&gt;, it
        plays immediately. To start playing the music 0.5 seconds from now, you can
        use &lt;code&gt;context.currentTime&lt;/code&gt; to get the reference point.\n\n&lt;pre
        class=&quot;prettyprint&quot;&gt;\n// Play music 0.5 seconds from now\nsource_node.noteOn(context.currentTime
        + 0.5);\n&lt;/pre&gt;\n\nIt&#39;s also worth noting that we specified the
        granularity of the FFT to 2048 by setting the &lt;code&gt;analyzer.fftSize&lt;/code&gt;
        variable. For those unfamiliar with DSP theory, this breaks the frequency
        spectrum of the audio into 2048 points, each point representing the magnitude
        of the &lt;i&gt;n/2048th&lt;/i&gt; frequency bin.\n\n&lt;p/&gt;\n\n&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;\n&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_sZlkl6rt9eyhJSC6_Veh4Q5eYipuxoAac_7G56fMnENz4dVXrfYXwQsjKX6ewUoj5GEvnE5JIpAh9iMuhFyR2OJw3AoQAe7vkd7XclMC7Mo0NO_QwSIDaQVmYa2QEnhrjLv5_A/s1600/Screen+shot+2011-08-20+at+11.38.45+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;150&quot; width=&quot;400&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_sZlkl6rt9eyhJSC6_Veh4Q5eYipuxoAac_7G56fMnENz4dVXrfYXwQsjKX6ewUoj5GEvnE5JIpAh9iMuhFyR2OJw3AoQAe7vkd7XclMC7Mo0NO_QwSIDaQVmYa2QEnhrjLv5_A/s400/Screen+shot+2011-08-20+at+11.38.45+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n\n&lt;p/&gt;\n&lt;h3&gt;The Pretty Graphs&lt;/h3&gt;\n&lt;p/&gt;\n\nOkay,
        it&#39;s now all wired up -- how do I get the pretty graphs? The general strategy
        is to poll the analyzer every few milliseconds (e.g., with &lt;code&gt;window.setInterval&lt;/code&gt;),
        request the time- or frequency-domain data, and then render it onto a HTML5
        Canvas element. The analyzer exports a few different methods to access the
        analysis data: &lt;code&gt;getFloatFrequencyData&lt;/code&gt;, &lt;code&gt;getByteFrequencyData&lt;/code&gt;,
        &lt;code&gt;getByteTimeDomainData&lt;/code&gt;. Each of these methods populate
        a given &lt;code&gt;ArrayBuffer&lt;/code&gt; with the appropriate analysis
        data.\n\n&lt;p/&gt;\nIn the below snippet, we schedule an &lt;code&gt;update()&lt;/code&gt;
        function every 50ms, which breaks the frequency-domain data points into 30
        bins, and renders a bar representing the average magnitude of the points in
        each bin.\n\n&lt;pre class=&quot;prettyprint&quot;&gt;\ncanvas = document.getElementById(canvas_id);\ncanvas_context
        = canvas.getContext(&quot;2d&quot;);\n\nfunction update() {\n  // This graph
        has 30 bars.\n  var num_bars = 30;\n\n  // Get the frequency-domain data\n
        \ var data = new Uint8Array(2048);\n  analyzer.getByteFrequencyData(data);\n\n
        \ // Clear the canvas\n  canvas_context.clearRect(0, 0, this.width, this.height);\n\n
        \ // Break the samples up into bins\n  var bin_size = Math.floor(length /
        num_bars);\n  for (var i=0; i &lt; num_bars; ++i) {\n    var sum = 0;\n    for
        (var j=0; j &lt; bin_size; ++j) {\n      sum += data[(i * bin_size) + j];\n
        \   }\n\n    // Calculate the average frequency of the samples in the bin\n
        \   var average = sum / bin_size;\n\n    // Draw the bars on the canvas\n
        \   var bar_width = canvas.width / num_bars;\n    var scaled_average = (average
        / 256) * canvas.height;\n\n    canvas_context.fillRect(i * bar_width, canvas.height,
        bar_width - 2,\n                         -scaled_average);\n}\n\n// Render
        every 50ms\nwindow.setInterval(update, 50);\n\n// Start the music\nsource_node.noteOn(0);\n&lt;/pre&gt;\n\nA
        similar strategy can be employed for time-domain data, except for a few minor
        differences: Time-domain data is usually rendered as waves, so you might want
        to use lot more bins and plot pixels instead of drawing bars. The code that
        renders the time and frequency domain graphs in the demo is encapsulated in
        the &lt;code&gt;SpectrumBox&lt;/code&gt; class in &lt;a href=&quot;https://github.com/0xfe/experiments/blob/master/www/wavebox/js/spectrum.js&quot;&gt;js/spectrum.js&lt;/a&gt;.\n\n&lt;p/&gt;\n&lt;h3&gt;The
        Minutiae&lt;/h3&gt;\n&lt;p/&gt;\nI glossed over a number of things in this
        post, mostly with respect to the details of the demo. You can learn it all
        from the source code, but here&#39;s a summary for the impatient: \n&lt;p/&gt;\nThe
        graphs are actually two HTML5 Canvas elements overlaid using CSS absolute
        positioning. Each element is used by its own &lt;code&gt;SpectrumBox&lt;/code&gt;
        class, one which displays the frequency spectrum, the other which displays
        the time-domain wave. \n&lt;p/&gt;\nThe routing of the nodes is done in the
        &lt;code&gt;onclick&lt;/code&gt; handler to the &lt;code&gt;#play&lt;/code&gt;
        button -- it takes the &lt;code&gt;AudioSourceNode&lt;/code&gt; from the &lt;code&gt;RemoteAudioPlayer&lt;/code&gt;,
        routes it to node of the frequency analyzer, routes &lt;i&gt;that&lt;/i&gt;
        to the node of the time-domain analyzer, and then finally to the destination.\n&lt;p/&gt;\n&lt;h3&gt;Bonus:
        Another Demo&lt;/h3&gt;\n&lt;p/&gt;\n\nThat&#39;s all folks! You now have
        the knowhow to build yourself a fancy new graphical spectrum analyzer. If
        all you want to do is play with the waves and stare at the graphs, check out
        my other demo: The &lt;a href=&quot;http://0xfe.muthanna.com/analyzer&quot;&gt;Web
        Audio Tone Analyzer&lt;/code&gt; (&lt;a href=&quot;https://github.com/0xfe/experiments/tree/master/www/analyzer&quot;&gt;source&lt;/a&gt;).
        This is really just the same spectrum analyzer from the first demo, connected
        to the tone generator from the &lt;a href=&quot;https://github.com/0xfe/experiments/tree/master/www/wavebox&quot;&gt;last
        post&lt;/a&gt;.\n\n&lt;p/&gt;\n&lt;div class=&quot;separator&quot; style=&quot;clear:
        both; text-align: center;&quot;&gt;\n&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBgJGcbHueNFzV57A0hNmHy5pgk8CujXroKhFGrDgfpHQhVqkpcJbA3n11VSR-BJw6voEuyJubfEoUQXhyeisdk4h9Mwgap66UU4ivhRiJY_mKPESde1aquV7NsQt1gcbsY5ALdg/s1600/Screen+shot+2011-08-20+at+10.13.15+AM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left:1em; margin-right:1em&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;127&quot; width=&quot;320&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBgJGcbHueNFzV57A0hNmHy5pgk8CujXroKhFGrDgfpHQhVqkpcJbA3n11VSR-BJw6voEuyJubfEoUQXhyeisdk4h9Mwgap66UU4ivhRiJY_mKPESde1aquV7NsQt1gcbsY5ALdg/s320/Screen+shot+2011-08-20+at+10.13.15+AM.png&quot;
        /&gt;&lt;/a&gt;&lt;/div&gt;\n\n&lt;p/&gt;\n\n&lt;h3&gt;References&lt;/h3&gt;\n&lt;/p&gt;\n\nAs
        a reminder, all the code for my posts is available at my GitHub repository:
        &lt;a href=&quot;http://github.com/0xfe&quot;&gt;github.com/0xfe&lt;/a&gt;.\n\n&lt;p/&gt;\nThe
        audio track used in the demo is a discarded take of  &lt;a href=&quot;http://captainstarr.bandcamp.com/track/who-da-man&quot;&gt;Who-Da-Man&lt;/a&gt;,
        which I recorded with my previous band &lt;a href=&quot;http://captainstarr.bandcamp.com/album/ep&quot;&gt;Captain
        Starr&lt;/a&gt; many many years ago.\n&lt;p/&gt;\nFinally, don&#39;t forget
        to read the &lt;a href=&quot;https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html&quot;&gt;Web
        Audio API&lt;/a&gt; draft specification for more information.\n&lt;p/&gt;\nEnjoy!</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/7852661428465635210/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2011/08/web-audio-spectrum-analyzer.html#comment-form'
        title='9 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/7852661428465635210'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/7852661428465635210'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2011/08/web-audio-spectrum-analyzer.html'
        title='A Web Audio Spectrum Analyzer'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgpX14OzEMC3DnQ74e2TZUz2RSTwgECiV182MM7scAFYjkJTdyT5xMNYngRGYwOy-FaaGIcnO-geVMsVzpfgcG0smJChWAWouNtkZMxUCWIT7LJdIq7JojMIpsAmfMOD5MMIx0lAg/s72-c/Screen+shot+2011-08-20+at+11.47.10+AM.png\"
        height=\"72\" width=\"72\"/><thr:total>9</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-6394151762251429282</id><published>2011-08-13T20:58:00.005-04:00</published><updated>2011-08-22T07:12:12.828-04:00</updated><title
        type='text'>Generating Tones with the Web Audio API</title><content type='html'>The
        Web Audio API is a W3C draft standard interface for building in-browser audio
        applications. Although the draft is well specified, it is almost impossible
        to find useful documentation on building applications with it. &lt;p/&gt;In
        my quest to deeper understand HTML5 audio, I spent some time figuring out
        how the API works, and decided to write up this quick tutorial on doing useful
        things with it. &lt;p/&gt;We will build a sine wave tone-generator entirely
        in JavaScript. The final product looks like this: &lt;a href=&quot;http://0xfe.muthanna.com/tone&quot;&gt;Web
        Audio Tone Generator&lt;/a&gt;. &lt;p/&gt;The full code is available in my
        GitHub repository: &lt;a href=&quot;https://github.com/0xfe/experiments/tree/master/www/tone&quot;&gt;https://github.com/0xfe/experiments/tree/master/www/tone&lt;/a&gt;
        &lt;p/&gt;&lt;h3&gt;\nCaveats&lt;/h3&gt;\n&lt;p/&gt;The Web Audio API is draft,
        is likely to change, and does not work on all browsers. Right now, only the
        latest versions of Chrome and Safari support it. &lt;p/&gt;&lt;h3&gt;\nOnwards
        We Go&lt;/h3&gt;\n&lt;p/&gt;Getting started making sounds with the Web Audio
        API is straightforward so long as you take the time to study the plumbing,
        most of which exists to allow for real-time audio processing and synthesis.
        The complete specification is available on the &lt;a href=&quot;https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html&quot;&gt;W3C
        Web Audio API&lt;/a&gt; page, and I&#39;d strongly recommend that you read
        it thoroughly if you&#39;re interested in building advanced applications with
        the API. &lt;p/&gt;To produce any form of sound, you need an &lt;code&gt;AudioContext&lt;/code&gt;
        and a few &lt;code&gt;AudioNode&lt;/code&gt;s. The &lt;code&gt;AudioContext&lt;/code&gt;
        is sort of like an environment for audio processing -- it&#39;s where various
        attributes such as the sample rate, the clock status, and other environment-global
        state reside. Most applications will need no more than a single instance of
        &lt;code&gt;AudioContext&lt;/code&gt;. &lt;p/&gt;The &lt;code&gt;AudioNode&lt;/code&gt;
        is probably the most important component in the API, and is responsible for
        synthesizing or processing audio. An &lt;code&gt;AudioNode&lt;/code&gt; instance
        can be an input source, an output destination, or a mid-stream processor.
        These nodes can be linked together to form processing pipelines to render
        a complete audio stream. &lt;p/&gt;One kind of &lt;code&gt;AudioNode&lt;/code&gt;
        is &lt;code&gt;JavaScriptAudioNode&lt;/code&gt;, which is used to generate
        sounds in JavaScript. This is what what we will use in this tutorial to build
        a tone generator. &lt;p/&gt;Let us begin by instantiating an &lt;code&gt;AudioContext&lt;/code&gt;
        and creating a &lt;code&gt;JavaScriptAudioNode&lt;/code&gt;.  &lt;pre class=&quot;prettyprint&quot;&gt;var
        context = new webkitAudioContext();\nvar node = context.createJavaScriptNode(1024,
        1, 1);\n&lt;/pre&gt;\nThe parameters to &lt;code&gt;createJavaScriptNode&lt;/code&gt;
        refer to the buffer size, the number of input channels, and the number of
        output channels. The buffer size must be in units of sample frames, i.e.,
        one of: 256, 512, 1024, 2048, 4096, 8192, or 16384. It controls the frequency
        of callbacks asking for a buffer refill. Smaller sizes allow for lower latency
        and higher for better overall quality. &lt;p/&gt;We&#39;re going to use the
        &lt;code&gt;JavaScriptNode&lt;/code&gt; as the source node along with a bit
        of code to create sine waves. To actually &lt;i&gt;hear&lt;/i&gt;&amp;nbsp;anything,
        it must be connected to an output node. It turns out that &lt;code&gt;context.destination&lt;/code&gt;
        gives us just that -- a node that maps to the speaker on your machine. &lt;p/&gt;&lt;h3&gt;\nThe
        SineWave Class&lt;/h3&gt;\n&lt;p/&gt;To start off our tone generator, we create
        a &lt;code&gt;SineWave&lt;/code&gt; class, which wraps the &lt;code&gt;AudioNode&lt;/code&gt;
        and wave generation logic into one cohesive package. This class will be responsible
        for creating the &lt;code&gt;JavaScriptNode&lt;/code&gt; instances, generating
        the sine waves, and managing the connection to the destination node. &lt;pre
        class=&quot;prettyprint&quot;&gt;SineWave = function(context) {\n  var that
        = this;\n  this.x = 0; // Initial sample number\n  this.context = context;\n
        \ this.node = context.createJavaScriptNode(1024, 1, 1);\n  this.node.onaudioprocess
        = function(e) { that.process(e) };\n}\n\nSineWave.prototype.process = function(e)
        {\n  var data = e.outputBuffer.getChannelData(0);\n  for (var i = 0; i &amp;lt;
        data.length; ++i) {\n    data[i] = Math.sin(this.x++);\n  }\n}\n\nSineWave.prototype.play
        = function() {\n  this.node.connect(this.context.destination);\n}\n\nSineWave.prototype.pause
        = function() {\n  this.node.disconnect();\n}\n&lt;/pre&gt;\nUpon instantiation,
        this class creates a &lt;code&gt;JavaScriptAudioNode&lt;/code&gt; and attaches
        an event handler to &lt;code&gt;onaudioprocess&lt;/code&gt; for buffer refills.
        The event handler requests a reference to the output buffer for the first
        channel, and fills it with a sine wave. Notice that the handler does not know
        the buffer size in advance, and gets it from &lt;code&gt;data.length&lt;/code&gt;.
        &lt;p/&gt;The buffer is of type &lt;code&gt;ArrayBuffer&lt;/code&gt; which
        is a JavaScript Typed Array. These arrays allow for high throughput processing
        of raw binary data. To learn more about Typed Arrays, check out the &lt;a
        href=&quot;https://developer.mozilla.org/en/javascript_typed_arrays&quot;&gt;Mozilla
        Developer Documentation on Typed Arrays&lt;/a&gt;. &lt;p/&gt;To try out a
        quick demo of the &lt;code&gt;SineWave&lt;/code&gt; class, add the following
        code to the &lt;code&gt;onload&lt;/code&gt; handler for your page: &lt;pre
        class=&quot;prettyprint&quot;&gt;var context = new webkitAudioContext();\nvar
        sinewave = new SineWave(context);\nsinewave.play();\n&lt;/pre&gt;\n&lt;div&gt;\nNotice
        that &lt;code&gt;sinewave.play()&lt;/code&gt; works by wiring up the node
        to the &lt;code&gt;AudioContext&lt;/code&gt;&#39;s destination (the speakers).
        To stop the tone, call &lt;code&gt;sinewave.pause()&lt;/code&gt;, which unplugs
        this connection.&lt;/div&gt;\n&lt;p/&gt;&lt;div&gt;\n&lt;h3&gt;\nGenerating
        Specific Tones&lt;/h3&gt;\n&lt;/div&gt;\n&lt;p/&gt; &lt;div&gt;\nSo, now you
        have yourself a tone. Are we done yet?&lt;/div&gt;\n\n&lt;p/&gt;\n&lt;div&gt;\nNot
        quite. How does one know what the frequency of the generated wave is? How
        does one generate tones of arbitrary frequencies?&lt;/div&gt;\n&lt;p/&gt;\n&lt;div&gt;\nTo
        answer these questions, we must find out the sample rate of the audio. Each
        data value we stuff into the buffer in out handler is a sample, and the sample
        rate is the number of samples processed per second. We can calculate the frequency
        of the tone by dividing the sample rate by the length of a full wave cycle.&lt;/div&gt;\n&lt;p/&gt;\n&lt;div&gt;\nHow
        do we get the sample rate? Via the &lt;code&gt;getSampleRate()&lt;/code&gt;
        method of &lt;code&gt;AudioContext&lt;/code&gt;. On my machine, the default
        sample rate is 44KHz, i.e., 44100 samples per second. This means that the
        frequency of the generated tone in our above code is:&lt;/div&gt;\n&lt;pre
        class=&quot;prettyprint&quot;&gt;freq = context.getSampleRate() / 2 * Math.PI\n&lt;/pre&gt;\n&lt;div&gt;\nThat&#39;s
        about 7KHz. Ouch! Lets use our newfound knowledge to generate less spine-curdling
        tones. To generate a tone of a specific frequency, you can change &lt;code&gt;SineWave.process&lt;/code&gt;
        to:&lt;/div&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;SineWave.prototype.process
        = function(e) {\n  var data = e.outputBuffer.getChannelData(0);\n  for (var
        i = 0; i &amp;lt; data.length; ++i) {\n    data[i] = Math.sin(this.x++ / (this.sample_rate
        / 2 * Math.PI * this.frequency));\n  }\n}\n&lt;/pre&gt;\nAlso make sure you
        add the following two lines to &lt;code&gt;SineWave&lt;/code&gt;&#39;s constructor:
        \ &lt;pre class=&quot;prettyprint&quot;&gt;this.sample_rate = this.context.getSampleRate();\nthis.frequency
        = 440;\n&lt;/pre&gt;\nThis initializes the frequency to &lt;i&gt;pitch standard
        A440&lt;/i&gt;, i.e., the A above &lt;i&gt;middle C.&lt;/i&gt; &lt;p/&gt;&lt;h3&gt;\nThe
        Theremin Effect&lt;/h3&gt;\n&lt;p/&gt;Now that we can generate tones of arbitrary
        frequencies, it&#39;s only natural that we connect our class to some sort
        of slider widget so we can experience the entire spectrum right in our browsers.
        Turns out that &lt;a href=&quot;http://jqueryui.com/&quot;&gt;JQueryUI&lt;/a&gt;
        already has such a &lt;a href=&quot;http://jqueryui.com/demos/slider/&quot;&gt;slider&lt;/a&gt;,
        leaving us only a little plumbing to do. &lt;p/&gt;We add a setter function
        to our &lt;code&gt;SineWave&lt;/code&gt; class, and call it from our slider
        widget&#39;s change handler. &lt;pre class=&quot;prettyprint&quot;&gt;SineWave.prototype.setFrequency
        = function(freq) {\n  this.next_frequency = freq;\n}\n&lt;/pre&gt;\nA JQueryUI
        snippet would look like this: &lt;pre class=&quot;prettyprint&quot;&gt;$(&quot;#slider&quot;).slider({\n
        \   value: 440,\n    min: 1,\n    max: 2048,\n    slide: function(event, ui)
        { sinewave.setFrequency(ui.value); }\n});\n&lt;/pre&gt;\n&lt;h3&gt;\nGoing
        up to Eleven&lt;/h3&gt;\n&lt;p/&gt;Adding support for volume is straightforward.
        Add an amplitude member to the &lt;code&gt;SineWave&lt;/code&gt; constructor
        along with a setter method, just like we did for frequency, and change &lt;code&gt;SineWave.process&lt;/code&gt;
        to:  &lt;pre class=&quot;prettyprint&quot;&gt;SineWave.prototype.process =
        function(e) {\n  var data = e.outputBuffer.getChannelData(0);\n  for (var
        i = 0; i &amp;lt; data.length; ++i) {\n    data[i] = this.amplitude * Math.sin(this.x++
        / (this.sample_rate / 2 * Math.PI * this.frequency));\n  }\n}\n&lt;/pre&gt;\nFolks,
        we now have a full fledged sine wave generator! &lt;p/&gt;&lt;h3&gt;\nBoo
        Hiss Crackle&lt;/h3&gt;\n&lt;p/&gt;But, we&#39;re not done yet. You&#39;ve
        probably noticed that changing the frequency causes mildly annoying crackling
        sounds. This happens because when the frequency changes, discontinuity occurs
        in the wave, causing a high-frequency &lt;i&gt;pop&lt;/i&gt;&amp;nbsp;in the
        audio stream. &lt;p/&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot;
        cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left:
        auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhalpMImRBOQHBmOscmOwmDAlyeLBL3bJ-unGATwmWuxUWy1OggewBKAyp4ckF67vY4RODDhgK1J0inVUaE0gcE4SG9s-bbQE7kOm5sdtIcTjvHi7jl99iV4XPXhnv-QqqehGBKPQ/s1600/Screen+shot+2011-08-13+at+8.45.06+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;137&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhalpMImRBOQHBmOscmOwmDAlyeLBL3bJ-unGATwmWuxUWy1OggewBKAyp4ckF67vY4RODDhgK1J0inVUaE0gcE4SG9s-bbQE7kOm5sdtIcTjvHi7jl99iV4XPXhnv-QqqehGBKPQ/s320/Screen+shot+2011-08-13+at+8.45.06+PM.png&quot;
        width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Discontinuity
        when Changing Frequencies&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;p/&gt;We
        try to eliminate the discontinuity by only shifting frequencies when the cycle
        of the previous frequency completes, i.e., the sample value is (approximately)
        zero. (There are better ways to do this, e.g., windowing, LPFs, etc., but
        these techniques are out of the scope of this tutorial.) &lt;p/&gt;Although
        this complicates the code a little bit, waiting for the cycle to end significantly
        reduces the noise upon frequency shifts.  &lt;pre class=&quot;prettyprint&quot;&gt;SineWave.prototype.setFrequency
        = function(freq) {\n  this.next_frequency = freq;\n}\n\nSineWave.prototype.process
        = function(e) {\n  // Get a reference to the output buffer and fill it up.\n
        \ var data = e.outputBuffer.getChannelData(0);\n\n  // We need to be careful
        about filling up the entire buffer and not\n  // overflowing.\n  for (var
        i = 0; i &amp;lt; data.length; ++i) {\n    data[i] = this.amplitude * Math.sin(\n
        \       this.x++ / (this.sampleRate / (this.frequency * 2 * Math.PI)));\n\n
        \   // This reduces high-frequency blips while switching frequencies. It works\n
        \   // by waiting for the sine wave to hit 0 (on it&#39;s way to positive
        territory)\n    // before switching frequencies.\n    if (this.next_frequency
        != this.frequency) {\n      // Figure out what the next point is.\n      next_data
        = this.amplitude * Math.sin(\n        this.x / (this.sampleRate / (this.frequency
        * 2 * Math.PI)));\n\n      // If the current point approximates 0, and the
        direction is positive,\n      // switch frequencies.\n      if (data[i] &amp;lt;
        0.001 &amp;amp;&amp;amp; data[i] &amp;gt; -0.001 &amp;amp;&amp;amp; data[i]
        &amp;lt; next_data) {\n        this.frequency = this.next_frequency;\n        this.x
        = 0;\n      }\n    }\n  }\n}\n&lt;/pre&gt;\n&lt;p/&gt;&lt;div&gt;\n&lt;h3&gt;\nThe
        End&lt;/h3&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;p/&gt;&lt;/div&gt;\n&lt;div&gt;\nAs
        mentioned in the beginning of this tutorial, a demo of the full code is available
        at&amp;nbsp;&lt;a href=&quot;http://0xfe.muthanna.com/tone/&quot;&gt;http://0xfe.muthanna.com/tone/&lt;/a&gt;&amp;nbsp;and
        the entire source code is available at&amp;nbsp;&lt;a href=&quot;https://github.com/0xfe/experiments/tree/master/www/tone&quot;&gt;https://github.com/0xfe/experiments/tree/master/www/tone&lt;/a&gt;.&lt;/div&gt;\n&lt;p/&gt;
        &lt;div&gt;\nDo check out the &lt;a href=&quot;https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html&quot;&gt;W3C
        Web Audio API&lt;/a&gt; specification. Do check out the &lt;a href=&quot;https://developer.mozilla.org/en/javascript_typed_arrays&quot;&gt;Mozilla
        document on JavaScript Typed Arrays&lt;/a&gt;.&lt;/div&gt;\n&lt;p/&gt; &lt;div&gt;\nComments,
        criticism, and error reports welcome. Enjoy!&lt;/div&gt;\n</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/6394151762251429282/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2011/08/generating-tones-with-web-audio-api.html#comment-form'
        title='11 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6394151762251429282'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6394151762251429282'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2011/08/generating-tones-with-web-audio-api.html'
        title='Generating Tones with the Web Audio API'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhalpMImRBOQHBmOscmOwmDAlyeLBL3bJ-unGATwmWuxUWy1OggewBKAyp4ckF67vY4RODDhgK1J0inVUaE0gcE4SG9s-bbQE7kOm5sdtIcTjvHi7jl99iV4XPXhnv-QqqehGBKPQ/s72-c/Screen+shot+2011-08-13+at+8.45.06+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>11</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-1841038669655438377</id><published>2011-03-31T13:50:00.000-04:00</published><updated>2011-03-31T13:50:44.471-04:00</updated><title
        type='text'>A Music Theory API</title><content type='html'>Most of my work
        last week consisted of writing music theory code. &lt;a href=&quot;http://vexflow.com/&quot;&gt;VexFlow&lt;/a&gt;
        now has a neat little music theory API, that gives you answers to questions
        like the following:&lt;br /&gt;\n&lt;br /&gt;\n&lt;ul&gt;&lt;li&gt;What note
        is a minor 3rd above a B?&lt;/li&gt;\n&lt;li&gt;What are the scale tones of
        a Gb Harmonic Minor?&lt;/li&gt;\n&lt;li&gt;What relation is the C# note to
        an A Major scale? (Major 3rd)&lt;/li&gt;\n&lt;li&gt;What accidentals should
        be displayed for the perfect 4th note of a G Major scale?&lt;/li&gt;\n&lt;li&gt;etc.&lt;/li&gt;\n&lt;/ul&gt;&lt;br
        /&gt;\nThe API is part of VexFlow, and can be used independently of the rendering
        API. Take a look at &lt;a href=&quot;https://github.com/0xfe/vexflow/blob/master/src/music.js&quot;&gt;music.js&lt;/a&gt;
        in the &lt;a href=&quot;http://github.com/0xfe/vexflow&quot;&gt;VexFlow GitHub
        repository&lt;/a&gt; for the complete reference. There&#39;s also a handy
        key management library for building scores in &lt;a href=&quot;https://github.com/0xfe/vexflow/blob/master/src/keymanager.js&quot;&gt;keymanager.js&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\nI&#39;m currently working on updating the&amp;nbsp;&lt;a
        href=&quot;http://vexflow.com/docs/tutorial.html&quot;&gt;VexFlow Tutorial&lt;/a&gt;&amp;nbsp;with
        a quickstart on the music theory API, but meanwhile, here are some teasers
        (pulled straight out of the&amp;nbsp;&lt;a href=&quot;https://github.com/0xfe/vexflow/blob/master/tests/music_tests.js&quot;&gt;tests&lt;/a&gt;).&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;// What does
        C note consist of?\nvar parts = music.getNoteParts(&quot;c&quot;);\nequals(parts.root,
        &quot;c&quot;);\nequals(parts.accidental, null);\n\n// What does C# note consist
        of?\nvar parts = music.getNoteParts(&quot;c#&quot;);\nequals(parts.root, &quot;c&quot;);\nequals(parts.accidental,
        &quot;#&quot;);\n\n// What is a flat-5th above C?\nvar value = music.getRelativeNoteValue(music.getNoteValue(&quot;c&quot;),\n
        \                                      music.getIntervalValue(&quot;b5&quot;));\nequals(value,
        music.getNoteValue(&quot;gb&quot;);\nequals(value, music.getNoteValue(&quot;f#&quot;);\n\n//
        What is the C quality of a Db?\nequals(music.getRelativeNoteName(&quot;c&quot;,
        music.getNoteValue(&quot;db&quot;)), &quot;c#&quot;);\n\n// What are the tones
        of a C major scale?\nvar c_major = music.getScaleTones(\n      music.getNoteValue(&quot;c&quot;),
        Vex.Flow.Music.scales.major);\n// result: [&quot;c&quot;, &quot;d&quot;, &quot;e&quot;,
        &quot;f&quot;, &quot;g&quot;, &quot;a&quot;, &quot;b&quot;]\n\n// What is
        the interval between a C and a D?\nequals(music.getCanonicalIntervalName(music.getIntervalBetween(\n
        \    music.getNoteValue(&quot;c&quot;), music.getNoteValue(&quot;d&quot;))),
        &quot;M2&quot;);\n&lt;/pre&gt;&lt;br /&gt;\n&lt;div&gt;&lt;span class=&quot;Apple-style-span&quot;
        style=&quot;line-height: 16px;&quot;&gt;&lt;br /&gt;\n&lt;/span&gt;&lt;/div&gt;Thanks
        to the theory support, we now have smarter Accidentals in the standard notation
        stave that VexTab generates.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjN1ilwcTQy81IgS1-R_nl7tp4oG0agi_Q3jvBZvwvFH3qq3Ktm7ikP87TY-S_YqrZx8cfd6-I21BeYfkqe2cidfztdCK1YLOC4Kb_z0OX2oKsVgdOlDsobtYqiSvBEc-9_lGAp4A/s1600/Screen+shot+2011-03-31+at+1.03.07+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjN1ilwcTQy81IgS1-R_nl7tp4oG0agi_Q3jvBZvwvFH3qq3Ktm7ikP87TY-S_YqrZx8cfd6-I21BeYfkqe2cidfztdCK1YLOC4Kb_z0OX2oKsVgdOlDsobtYqiSvBEc-9_lGAp4A/s1600/Screen+shot+2011-03-31+at+1.03.07+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;
        style=&quot;text-align: center;&quot;&gt;Smarter Accidentals&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\nNotice how the accidentals are correctly picked according to the rules
        of standard notation? Yep, so do I.&lt;br /&gt;\n&lt;br /&gt;\nWe also have
        lots more tests -- over 750 of them! &lt;a href=&quot;http://vexflow.com/tests&quot;&gt;Try
        running them on your browser&lt;/a&gt; and tell me how long it takes.&lt;br
        /&gt;\n&lt;br /&gt;\nThat&#39;s all folks!</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/1841038669655438377/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2011/03/music-theory-api.html#comment-form'
        title='19 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1841038669655438377'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1841038669655438377'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2011/03/music-theory-api.html'
        title='A Music Theory API'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjN1ilwcTQy81IgS1-R_nl7tp4oG0agi_Q3jvBZvwvFH3qq3Ktm7ikP87TY-S_YqrZx8cfd6-I21BeYfkqe2cidfztdCK1YLOC4Kb_z0OX2oKsVgdOlDsobtYqiSvBEc-9_lGAp4A/s72-c/Screen+shot+2011-03-31+at+1.03.07+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>19</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-6538091093974991528</id><published>2011-03-27T14:48:00.000-04:00</published><updated>2011-03-27T14:48:07.944-04:00</updated><title
        type='text'>Prettier Tablature</title><content type='html'>Spot the difference:&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot;
        cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left:
        auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvDxctz41t8lkakd87vv6buAIPudM5HtxgjG12vGWh6yZ3Qe3keTOSaVtvJHYwxOHmqpm911ybd8t4jW-A4SFn6MzBOdCOaK1ZsOA29iPPif-UudHxuIpN5WJFLUfb_b9WIILBtA/s1600/Screen+shot+2011-03-27+at+2.34.14+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvDxctz41t8lkakd87vv6buAIPudM5HtxgjG12vGWh6yZ3Qe3keTOSaVtvJHYwxOHmqpm911ybd8t4jW-A4SFn6MzBOdCOaK1ZsOA29iPPif-UudHxuIpN5WJFLUfb_b9WIILBtA/s1600/Screen+shot+2011-03-27+at+2.34.14+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;
        style=&quot;text-align: center;&quot;&gt;Before&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3EiDHCEJfygzSLmLpnBqYC8yjLl4LMjkrlNFDhqQi5HO6TOpSUrOsOi2I3u1BRrNfVeGg8cz-NMIsdednVAHu-lxEA5yRwunWuoE06EbEyeNXYy_VBRqrw3gvJ2GOT7PHvn8rkA/s1600/Screen+shot+2011-03-27+at+2.32.23+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3EiDHCEJfygzSLmLpnBqYC8yjLl4LMjkrlNFDhqQi5HO6TOpSUrOsOi2I3u1BRrNfVeGg8cz-NMIsdednVAHu-lxEA5yRwunWuoE06EbEyeNXYy_VBRqrw3gvJ2GOT7PHvn8rkA/s1600/Screen+shot+2011-03-27+at+2.32.23+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;
        style=&quot;text-align: center;&quot;&gt;After&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;div&gt;Still
        can&#39;t tell? Let me help you out. We have:&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;Slightly
        greater spacing between the tablature stave lines. This makes it more consistent
        in appearance with printed tablature.&lt;/li&gt;\n&lt;li&gt;Stave lines are
        cleared before fret numbers are rendered, vastly improving readability.&lt;/li&gt;\n&lt;li&gt;Font
        sizes for fret numbers and annotations are bigger.&lt;/li&gt;\n&lt;li&gt;Associated
        notation and tablature staves are connected with a vertical bar on the left.&lt;/li&gt;\n&lt;li&gt;Micro-changes
        in spacing between fret numbers, effects, annotations, etc.&lt;/li&gt;\n&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;All
        these changes have been incorporated into &lt;a href=&quot;http://vexflow.com/tabdiv&quot;&gt;TabDiv&lt;/a&gt;,
        and pushed to &lt;a href=&quot;http://github.com/0xfe/vexflow&quot;&gt;GitHub&lt;/a&gt;.
        See more on the &lt;a href=&quot;http://vexflow.com/vextab/tutorial.html&quot;&gt;VexTab
        Tutorial&lt;/a&gt; page. Enjoy!&lt;/div&gt;</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/6538091093974991528/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2011/03/prettier-tablature.html#comment-form'
        title='1 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6538091093974991528'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6538091093974991528'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2011/03/prettier-tablature.html'
        title='Prettier Tablature'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvDxctz41t8lkakd87vv6buAIPudM5HtxgjG12vGWh6yZ3Qe3keTOSaVtvJHYwxOHmqpm911ybd8t4jW-A4SFn6MzBOdCOaK1ZsOA29iPPif-UudHxuIpN5WJFLUfb_b9WIILBtA/s72-c/Screen+shot+2011-03-27+at+2.34.14+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-1929109118059060998</id><published>2011-03-24T16:44:00.000-04:00</published><updated>2011-03-24T16:44:47.737-04:00</updated><category
        scheme=\"http://www.blogger.com/atom/ns#\" term=\"vexflow\"/><title type='text'>The
        VexFlow Tutorial (...and other goodies)</title><content type='html'>Finally...
        finally... finally... we have the humble beginnings of what could be considered
        &quot;documentation&quot;.&lt;br /&gt;\n&lt;br /&gt;\nI present to you &lt;a
        href=&quot;http://vexflow.com/docs/tutorial.html&quot;&gt;The VexFlow Tutorial&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\nAlthough still in its infancy, the tutorial covers everything
        you need to &lt;i&gt;start&lt;/i&gt; using VexFlow in your own code. My plan
        for the next few weeks is to make this document as comprehensive as possible,
        and write up a separate API reference.&lt;br /&gt;\n&lt;br /&gt;\nI hope that
        this tutorial will help developers understand VexFlow better, and enable them
        to build new and interesting libraries, parsers, and applications.&lt;br /&gt;\n&lt;br
        /&gt;\nThe entire tutorial is stored in the &lt;a href=&quot;https://github.com/0xfe/vexflow/blob/master/docs/tutorial.html&quot;&gt;Git
        repo&lt;/a&gt;; feel free to send me your corrections or other updates.&lt;br
        /&gt;\n&lt;br /&gt;\nAbout time, I know.&lt;br /&gt;\n&lt;br /&gt;\nIn other
        news, we have had a few contributions to both VexFlow and VexTab. A big thanks
        to &lt;a href=&quot;https://github.com/airfrog&quot;&gt;airfrog&lt;/a&gt;,
        &lt;a href=&quot;https://github.com/wiseleyb&quot;&gt;wiseleyb&lt;/a&gt;,
        and &lt;a href=&quot;https://github.com/adamf&quot;&gt;adamf&lt;/a&gt; for
        getting these done.&lt;br /&gt;\n&lt;br /&gt;\nFirst, we have the ability
        to render dotted notes.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTJvi0zGz6LnMaUlGrYTQQCtHK5qDwop451cOBsWGXLwSaSUGrHs6UpuBK95zj-fRdph9w6ez4pzLuQIMze2owizc3Ly9Ja8Br3Va3KV-8J9Do0w6e0gb5W3La87_5sBro9mmEmA/s1600/Screen+shot+2011-03-24+at+4.29.01+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTJvi0zGz6LnMaUlGrYTQQCtHK5qDwop451cOBsWGXLwSaSUGrHs6UpuBK95zj-fRdph9w6ez4pzLuQIMze2owizc3Ly9Ja8Br3Va3KV-8J9Do0w6e0gb5W3La87_5sBro9mmEmA/s1600/Screen+shot+2011-03-24+at+4.29.01+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;
        style=&quot;text-align: center;&quot;&gt;Dotted Notes&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\nThen we have key signatures.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheUE2y0VoCdcCgZCE32Gwj4JCEFDx8hh7b2TjjwV42XamUDvNNhQX5Xq6RypmUawFxFo0zf9zBoQATGJXO_g3JPbYpzG5dDEzhm7zibHJ9eZnlWc0hKzmAFFi164GazKoULiI8Eg/s1600/Screen+shot+2011-03-24+at+4.30.42+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;131&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheUE2y0VoCdcCgZCE32Gwj4JCEFDx8hh7b2TjjwV42XamUDvNNhQX5Xq6RypmUawFxFo0zf9zBoQATGJXO_g3JPbYpzG5dDEzhm7zibHJ9eZnlWc0hKzmAFFi164GazKoULiI8Eg/s320/Screen+shot+2011-03-24+at+4.30.42+PM.png&quot;
        width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Key
        Signatures&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;\nWe
        also have time signatures.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg27y5Z87WaSWtfaCNXHl9HVU0W9gH9Aso7krjOZS4QF0qaNfqJSiftWZcPNvnGmTe19-LS4rbPPyBaOnJCKE7s5vQEnA85ZnGC8RDbP8oqxOIraHn835bZ9lUe-0CmyElU8tAAXQ/s1600/Screen+shot+2011-03-24+at+4.30.53+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg27y5Z87WaSWtfaCNXHl9HVU0W9gH9Aso7krjOZS4QF0qaNfqJSiftWZcPNvnGmTe19-LS4rbPPyBaOnJCKE7s5vQEnA85ZnGC8RDbP8oqxOIraHn835bZ9lUe-0CmyElU8tAAXQ/s1600/Screen+shot+2011-03-24+at+4.30.53+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;
        style=&quot;text-align: center;&quot;&gt;Time Signatures&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\nThis includes the really crazy time signatures too.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6onDHjQYycBooCK4HNjeECNfDU6s5UcPQai7Ab8ybP-vmVd2iZijJkoOb0H3-RZdS8-IdHCNQbPlyhsa6_s61YWGa0M6UkvTuy1zGGdaNkf_xYRJEiFKK92fb1v1-SQKXjBK0_w/s1600/Screen+shot+2011-03-24+at+4.31.03+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6onDHjQYycBooCK4HNjeECNfDU6s5UcPQai7Ab8ybP-vmVd2iZijJkoOb0H3-RZdS8-IdHCNQbPlyhsa6_s61YWGa0M6UkvTuy1zGGdaNkf_xYRJEiFKK92fb1v1-SQKXjBK0_w/s1600/Screen+shot+2011-03-24+at+4.31.03+PM.png&quot;
        /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;
        style=&quot;text-align: center;&quot;&gt;Whacky Time Signatures&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\nFinally, we have support for different types of clefs.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUXGZKV-uwG5IG2PIILUssE5giARboG92nDQDdlC3CJt-zu3QicRDirgKZxx_1geAMV_YHG-8QdEFP1hE6ek9_jTXdPUVNlQn0QOUsTh_81yimLMQ0mazZCGL0_p-YYRkfG3vWPg/s1600/Screen+shot+2011-03-24+at+4.31.40+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;92&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUXGZKV-uwG5IG2PIILUssE5giARboG92nDQDdlC3CJt-zu3QicRDirgKZxx_1geAMV_YHG-8QdEFP1hE6ek9_jTXdPUVNlQn0QOUsTh_81yimLMQ0mazZCGL0_p-YYRkfG3vWPg/s320/Screen+shot+2011-03-24+at+4.31.40+PM.png&quot;
        width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Alternate
        Clefs&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;\nBut
        wait... there&#39;s more.&amp;nbsp;All of this is supported in &lt;a href=&quot;http://vexflow.com/vextab/tutorial.html&quot;&gt;VexTab&lt;/a&gt;
        by way of new &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;tabstave&lt;/span&gt;
        parameters. Take a look at the updated &lt;a href=&quot;http://vexflow.com/vextab/tutorial.html&quot;&gt;VexTab
        Tutorial&lt;/a&gt; for the details.</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/1929109118059060998/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2011/03/vexflow-tutorial-and-other-goodies.html#comment-form'
        title='5 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1929109118059060998'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/1929109118059060998'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2011/03/vexflow-tutorial-and-other-goodies.html'
        title='The VexFlow Tutorial (...and other goodies)'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjTJvi0zGz6LnMaUlGrYTQQCtHK5qDwop451cOBsWGXLwSaSUGrHs6UpuBK95zj-fRdph9w6ez4pzLuQIMze2owizc3Ly9Ja8Br3Va3KV-8J9Do0w6e0gb5W3La87_5sBro9mmEmA/s72-c/Screen+shot+2011-03-24+at+4.29.01+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>5</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-6639885962680967449</id><published>2011-03-23T13:26:00.000-04:00</published><updated>2011-09-10T11:05:46.322-04:00</updated><category
        scheme=\"http://www.blogger.com/atom/ns#\" term=\"vim\"/><title type='text'>Editing
        XML and HTML in Vim</title><content type='html'>I just discovered the Vim
        &lt;a href=&quot;https://github.com/sukima/xmledit/&quot;&gt;xmledit&lt;/a&gt;
        plugin.&lt;br /&gt;\n&lt;br /&gt;\nWith features like tag-completion, auto-wrapping
        and unwrapping, quick navigation, etc., it has, in a matter of minutes, measurably
        decreased my level of frustration while editing markup in Vim.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;h3&gt;Installation&lt;/h3&gt;\n&lt;p/&gt;\n&lt;div&gt;The quickest
        way to install the plugin is by downloading the latest .&lt;code&gt;vba&lt;/code&gt;
        from the &lt;a href=&quot;http://vim.sourceforge.net/scripts/script.php?script_id=301&quot;&gt;plugin
        site&lt;/a&gt;, and run the following commands:&lt;/div&gt;&lt;br /&gt;\n&lt;pre
        class=&quot;prettyprint&quot;&gt;$ vim xmledit.vba\n:so %\n&lt;/pre&gt;&lt;br
        /&gt;\nYou also need to edit your&amp;nbsp;&lt;code&gt;.vimrc&lt;/code&gt;
        and add the following:&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;filetype
        plugin on\n&lt;/pre&gt;&lt;br /&gt;\n&lt;div&gt;This installs the plugin into
        your &lt;code&gt;.vim/ftplugin&lt;/code&gt; directory, and enables it for
        &lt;code&gt;.xml&lt;/code&gt; files. To enable it for other file types, create
        a link to the file with the new extension name in the same directory. (Copying
        the file also works.)&lt;/div&gt;&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$
        cd ~/.vim/ftplugin\n$ ln -s xml.vim html.vim\n$ ln -s xml.vim xhtml.vim\n&lt;/pre&gt;&lt;br
        /&gt;\n&lt;h3&gt;Usage&lt;/h3&gt;&lt;br /&gt;\nThe plugin supports the various
        Vim modes in interesting ways.&lt;br /&gt;\n&lt;br /&gt;\nIn insert mode,
        when you finish a tag (with the &lt;code&gt;&lt;span class=&quot;Apple-style-span&quot;
        style=&quot;font-family: &#39;Courier New&#39;, Courier, monospace;&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&amp;nbsp;character),
        it will be autocompleted and the cursor placed in-between the tags.&lt;br
        /&gt;\n&lt;br /&gt;\nIf you immediately type another &lt;code&gt;&lt;span
        class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier New&#39;,
        Courier, monospace;&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;, it will close
        the tag on its own line, and place the cursor on a new line right in between.&lt;br
        /&gt;\n&lt;br /&gt;\nThe &lt;code&gt;%&lt;/code&gt; key jumps between the
        start and end of a tag.&lt;br /&gt;\n&lt;br /&gt;\nThe &lt;code&gt;\\%&lt;/code&gt;
        combination jumps between opening and closing tags. (Note that backslash is
        the default key-prefix for scripts and plugins to use. You can change this
        prefix with the &lt;code&gt;mapleader&lt;/code&gt; setting.)&lt;br /&gt;\n&lt;br
        /&gt;\nIf you select text (for example with &lt;code&gt;v&lt;/code&gt;), and
        type &lt;code&gt;\\x&lt;/code&gt;, it will prompt you to wrap the text with
        a custom tag.&lt;br /&gt;\n&lt;br /&gt;\nTyping in &lt;code&gt;\\d&lt;/code&gt;
        unwraps surrounding tags from the cursor.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3&gt;Learning
        More&lt;/h3&gt;&lt;br /&gt;\nType &lt;code&gt;:help xml-plugin&lt;/code&gt;
        for help and more information.&lt;br /&gt;\n&lt;br /&gt;\nYay for another
        awesome Vim plugin. You can see my entire Vim profile in my &lt;a href=&quot;https://github.com/0xfe/evil/tree/master/dotfiles/vim_local&quot;&gt;Evil
        Tomato GitHub Repository&lt;/a&gt;.</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/6639885962680967449/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2011/03/editing-xml-and-html-in-vim.html#comment-form'
        title='3 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6639885962680967449'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6639885962680967449'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2011/03/editing-xml-and-html-in-vim.html'
        title='Editing XML and HTML in Vim'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-4947829838430309691</id><published>2011-03-20T08:43:00.000-04:00</published><updated>2011-03-20T08:43:13.268-04:00</updated><title
        type='text'>On Twitter</title><content type='html'>It turns out I&#39;m on
        twitter. I have absolutely no idea what I&#39;m going to do with it.&lt;br
        /&gt;\n&lt;br /&gt;\nMaybe I&#39;ll tweet every time time the compiler yells
        at me... or when my kernel panics... or when my browser &lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiAOC6OcErm77z3wo9yVSCI1strQm99Ap5KQOXC7JYi1P1YdC0CMaaUWfpUh-0pZzGyodL1WA7AcdRp0WLDJ-kCTFmHDtGtAkKc5HmY6ohmqYVV0ZCFZ1-NYxKBB5FG1iuj1mZ/s400/aw,+snap.png&quot;&gt;frowns&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\nWhatever it is, I&#39;m on twitter: &lt;a href=&quot;http://twitter.com/11111110b&quot;&gt;twitter.com/11111110b&lt;/a&gt;&lt;br
        /&gt;\n&lt;br /&gt;\nThat&#39;s seven ones and a zero, followed by a bee.</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/4947829838430309691/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2011/03/on-twitter.html#comment-form'
        title='0 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/4947829838430309691'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/4947829838430309691'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2011/03/on-twitter.html'
        title='On Twitter'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-5987592118110172726</id><published>2010-09-13T11:03:00.000-04:00</published><updated>2010-09-13T11:03:44.098-04:00</updated><category
        scheme=\"http://www.blogger.com/atom/ns#\" term=\"haskell\"/><title type='text'>Regex
        Substitution in Haskell</title><content type='html'>I&#39;m shocked and appalled
        at the fact that there is no generic regex substitution function in the GHC
        libraries. All I&#39;m looking for is a simple function equivalent to perl&#39;s
        &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier
        New&#39;, Courier, monospace;&quot;&gt;s/.../.../&lt;/span&gt; expression.&lt;br
        /&gt;\n&lt;br /&gt;\nAfter digging around a bit, I found &lt;span class=&quot;Apple-style-span&quot;
        style=&quot;font-family: &#39;Courier New&#39;, Courier, monospace;&quot;&gt;subRegex&lt;/span&gt;
        in &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier
        New&#39;, Courier, monospace;&quot;&gt;regex-compat&lt;/span&gt;. While this
        works well, it does not use PCRE, and as far as I can tell, there&#39;s no
        support for &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;ByteString&lt;/span&gt;s.&lt;br
        /&gt;\n&lt;br /&gt;\nGrrr.&lt;br /&gt;\n&lt;br /&gt;\nAnyhow, I took the &lt;span
        class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier New&#39;,
        Courier, monospace;&quot;&gt;subRegex&lt;/span&gt; implementation from &lt;span
        class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier New&#39;,
        Courier, monospace;&quot;&gt;regex-compat&lt;/span&gt; and mangled it slightly
        to work with &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;Text.Regex.PCRE&lt;/span&gt;.
        I also added the &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;(=~$)&lt;/span&gt; function
        which feels a bit more familiar to perl users. For example:&lt;br /&gt;\n&lt;pre
        class=&quot;prettyprint&quot;&gt;Prelude PCRESub&amp;gt; &quot;me boo&quot;
        =~$ (&quot;(me) boo&quot;, &quot;he \\\\1&quot;)\n&quot;he me&quot;&lt;/pre&gt;The
        above is equivalent to perl&#39;s:&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$text
        = &quot;me boo&quot;;\n$text =~ s/(me) boo/he $1/;&lt;/pre&gt;&lt;span class=&quot;Apple-style-span&quot;
        style=&quot;font-family: &#39;Courier New&#39;, Courier, monospace;&quot;&gt;(~=$)&lt;/span&gt;
        is implemented with &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;reSub&lt;/span&gt; (which
        is also exported by &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;PCRESub&lt;/span&gt;).
        &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier
        New&#39;, Courier, monospace;&quot;&gt;reSub&lt;/span&gt; allows you to provide
        your own &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;CompOption&lt;/span&gt;
        and &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier
        New&#39;, Courier, monospace;&quot;&gt;ExecOption&lt;/span&gt; options.&lt;br
        /&gt;\n&lt;br /&gt;\nHere&#39;s the &lt;span class=&quot;Apple-style-span&quot;
        style=&quot;font-family: &#39;Courier New&#39;, Courier, monospace;&quot;&gt;PCRESub&lt;/span&gt;
        module:&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;-- PCRE-based
        Regex Substitution\n-- Mohit Muthanna Cheppudira\n--\n-- Based off code by
        Chris Kuklewicz from regex-compat library.\n--\n-- Requires Text.Regex.PCRE
        from regex-pcre.\n\nmodule PCRESub(\n  (=~$),\n  reSub\n) where\n\nimport
        Data.Array((!))\nimport Text.Regex.PCRE\n\nsubRegex :: Regex                          --
        ^ Search pattern\n         -&gt; String                         -- ^ Input
        string\n         -&gt; String                         -- ^ Replacement text\n
        \        -&gt; String                         -- ^ Output string\nsubRegex
        _ &quot;&quot; _ = &quot;&quot;\nsubRegex regexp inp repl =\n  let compile
        _i str [] = \\ _m -&gt;  (str++)\n      compile i str ((&quot;\\\\&quot;,(off,len)):rest)
        =\n        let i&#39; = off+len\n            pre = take (off-i) str\n            str&#39;
        = drop (i&#39;-i) str\n        in if null str&#39; then \\ _m -&gt; (pre ++)
        . (&#39;\\\\&#39;:)\n             else \\  m -&gt; (pre ++) . (&#39;\\\\&#39;
        :) . compile i&#39; str&#39; rest m\n      compile i str ((xstr,(off,len)):rest)
        =\n        let i&#39; = off+len\n            pre = take (off-i) str\n            str&#39;
        = drop (i&#39;-i) str\n            x = read xstr\n        in if null str&#39;
        then \\ m -&gt; (pre++) . ((fst (m!x))++)\n             else \\ m -&gt; (pre++)
        . ((fst (m!x))++) . compile i&#39; str&#39; rest m\n      compiled :: MatchText
        String -&gt; String -&gt; String\n      compiled = compile 0 repl findrefs
        where\n        bre = makeRegexOpts defaultCompOpt execBlank &quot;\\\\\\\\(\\\\\\\\|[0-9]+)&quot;\n
        \       findrefs = map (\\m -&gt; (fst (m!1),snd (m!0))) (matchAllText bre
        repl)\n      go _i str [] = str\n      go i str (m:ms) =\n        let (_,(off,len))
        = m!0\n            i&#39; = off+len\n            pre = take (off-i) str\n
        \           str&#39; = drop (i&#39;-i) str\n        in if null str&#39; then
        pre ++ (compiled m &quot;&quot;)\n             else pre ++ (compiled m (go
        i&#39; str&#39; ms))\n  in go 0 inp (matchAllText regexp inp)\n\n-- Substitue
        re with sub in str using options copts and eopts.\nreSub :: String -&gt; String
        -&gt; String -&gt; CompOption -&gt; ExecOption -&gt; String\nreSub str re
        sub copts eopts = subRegex (makeRegexOpts copts eopts re) str sub\n\n-- Substitute
        re with sub in str, e.g.,\n--\n-- The perl expression:\n--\n--   $text = &quot;me
        boo&quot;;\n--   $text =~ s/(me) boo/he $1/;\n--\n-- can be written as:\n--\n--
        \  text = &quot;me boo&quot; =~$ (&quot;(me) boo&quot;, &quot;he \\\\1&quot;)\n--\n(=~$)
        :: String -&gt; (String, String) -&gt; String\n(=~$) str (re, sub) = reSub
        str re sub defaultCompOpt defaultExecOpt&lt;/pre&gt;Example usage:&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;import PCRESub\n\nmain = do\n
        \ let text = &quot;me boo&quot; =~$ (&quot;(me) boo&quot;, &quot;he \\\\1&quot;)\n
        \ print text&lt;/pre&gt;Paste this code in, or browse the source at my GitHub
        repo: &lt;a href=&quot;http://github.com/0xfe/experiments/blob/master/haskell/PCRESub.hs&quot;&gt;PCRESub.hs&lt;/a&gt;&lt;br
        /&gt;\n&lt;br /&gt;\nSomeone please make this work across all the regex backends
        (and add support for &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;ByteString&lt;/span&gt;s)!</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/5987592118110172726/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/09/regex-substitution-in-haskell.html#comment-form'
        title='3 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/5987592118110172726'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/5987592118110172726'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/09/regex-substitution-in-haskell.html'
        title='Regex Substitution in Haskell'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-5809791720055478982</id><published>2010-09-12T12:24:00.000-04:00</published><updated>2010-09-12T12:24:22.308-04:00</updated><category
        scheme=\"http://www.blogger.com/atom/ns#\" term=\"vexflow\"/><title type='text'>VexFlow
        Google Group</title><content type='html'>I&#39;ve been out of touch for a
        while, and it took me way too long to set this up; but hey - better late than
        never. :-)&lt;br /&gt;\n&lt;br /&gt;\nAfter looking into various options for
        the VexFlow mailing list, I eventually decided to use Google Groups. It&#39;s
        super easy to setup and manage, and has all the features I&#39;ll ever need.&lt;br
        /&gt;\n&lt;br /&gt;\nIf you&#39;re interested in hacking, discussing, or simply
        keeping up with VexFlow, sign up here:&lt;br /&gt;\n&lt;br /&gt;\n&lt;div
        style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://groups.google.com/group/vexflow&quot;&gt;http://groups.google.com/group/vexflow&lt;/a&gt;&lt;/div&gt;&lt;br
        /&gt;\nUnfortunately, I haven&#39;t had the time lately to hack on VexFlow,
        but I assure you that it&#39;s only temporary. I have a bunch of partial changes
        in the works, along with some interesting ideas floating around.&amp;nbsp;More
        later.</content><link rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/5809791720055478982/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/09/vexflow-google-group.html#comment-form'
        title='1 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/5809791720055478982'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/5809791720055478982'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/09/vexflow-google-group.html'
        title='VexFlow Google Group'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-3059590296733853422</id><published>2010-08-03T18:04:00.000-04:00</published><updated>2010-08-03T18:04:26.454-04:00</updated><title
        type='text'>VexFlow is Open Source</title><content type='html'>&lt;div style=&quot;margin-bottom:
        0px; margin-left: 0px; margin-right: 0px; margin-top: 0px;&quot;&gt;That&#39;s
        right folks! All the &lt;a href=&quot;http://www.vexflow.com/&quot;&gt;VexFlow&lt;/a&gt;
        code is now available in the &lt;a href=&quot;http://github.com/0xfe/vexflow&quot;&gt;VexFlow
        GitHub Repository&lt;/a&gt;.&lt;/div&gt;&lt;div style=&quot;margin-bottom:
        0px; margin-left: 0px; margin-right: 0px; margin-top: 0px;&quot;&gt;&lt;br
        /&gt;\n&lt;/div&gt;&lt;div style=&quot;margin-bottom: 0px; margin-left: 0px;
        margin-right: 0px; margin-top: 0px;&quot;&gt;It&#39;s distributed under the
        OSI approved MIT License, so feel free to tinker, tweak, hack, fix, fork,
        and redistribute it.&lt;/div&gt;&lt;div style=&quot;margin-bottom: 0px; margin-left:
        0px; margin-right: 0px; margin-top: 0px;&quot;&gt;&lt;br /&gt;\n&lt;/div&gt;&lt;div
        class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a
        href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiCCX_uGvdpHI6QDxV6euNvnnKUFw7lBIkbPcBqlyD75_J7RsVW5qbWjSK9qCbeQNe9i_UwEPvWSCOSNnpEunNPcA4TyAO2-FPX77mdDwUhFYe6JSYmFEVHAedxT0oOF5_iVGqooQ/s1600/Screen+shot+2010-08-03+at+5.36.09+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;187&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiCCX_uGvdpHI6QDxV6euNvnnKUFw7lBIkbPcBqlyD75_J7RsVW5qbWjSK9qCbeQNe9i_UwEPvWSCOSNnpEunNPcA4TyAO2-FPX77mdDwUhFYe6JSYmFEVHAedxT0oOF5_iVGqooQ/s320/Screen+shot+2010-08-03+at+5.36.09+PM.png&quot;
        width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;margin-bottom:
        0px; margin-left: 0px; margin-right: 0px; margin-top: 0px;&quot;&gt;&lt;br
        /&gt;\n&lt;/div&gt;&lt;div style=&quot;margin-bottom: 0px; margin-left: 0px;
        margin-right: 0px; margin-top: 0px;&quot;&gt;&lt;br /&gt;\n&lt;/div&gt;&lt;div
        style=&quot;margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top:
        0px;&quot;&gt;A lot of the core infrastructure (e.g., contexts, formatting,
        etc.) is ready and stable, and most of the work that needs to be done is adding
        support for various types of modifiers, effects, and annotations. I&#39;ve
        worked on some of the trickier ones, like accidentals and beams, and have
        left the easier ones out so interested coders can learn by contributing.&lt;/div&gt;&lt;div
        style=&quot;margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top:
        0px;&quot;&gt;&lt;br /&gt;\n&lt;/div&gt;&lt;div style=&quot;margin-bottom:
        0px; margin-left: 0px; margin-right: 0px; margin-top: 0px;&quot;&gt;This said,
        algorithms-enthusiasts need not feel left out - there are some hard problems
        to solve as well :-)&lt;/div&gt;&lt;div style=&quot;margin-bottom: 0px; margin-left:
        0px; margin-right: 0px; margin-top: 0px;&quot;&gt;&lt;br /&gt;\n&lt;/div&gt;&lt;div
        style=&quot;margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top:
        0px;&quot;&gt;Here&#39;s where I would like help from the community:&lt;/div&gt;&lt;div
        style=&quot;margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top:
        0px;&quot;&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Dots (Easy)&lt;/li&gt;\n&lt;li&gt;Trills
        (Easy)&lt;/li&gt;\n&lt;li&gt;Grace Notes (Moderate)&lt;/li&gt;\n&lt;li&gt;Slurs
        (Easy)&lt;/li&gt;\n&lt;li&gt;Glyphs for time signatures (Easy)&lt;/li&gt;\n&lt;li&gt;Key
        signature (Easy if you reuse the accidental placement code from accidentals.js)&lt;/li&gt;\n&lt;li&gt;Guitar
        effects: Palm Muting, Scratches, Whammy, Harmonics, etc. (Easy)&lt;/li&gt;\n&lt;li&gt;Chord
        Stave with Rhythm Slashes (Moderate to Hard)&lt;/li&gt;\n&lt;li&gt;Lyrics
        (Easy)&lt;/li&gt;\n&lt;/ul&gt;&lt;br /&gt;\n&lt;div style=&quot;margin-bottom:
        0px; margin-left: 0px; margin-right: 0px; margin-top: 0px;&quot;&gt;Here&#39;s
        what I&#39;m working on right now (and also wouldn&#39;t mind some help with):&lt;/div&gt;&lt;div
        style=&quot;margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top:
        0px;&quot;&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Tuplets / Triplets&lt;/li&gt;\n&lt;li&gt;VexTab
        parser support for rests, alternate keys, and multiple voices.&lt;/li&gt;\n&lt;li&gt;Alternate
        tunings and support for arbitrary-string instruments.&lt;/li&gt;\n&lt;/ul&gt;&lt;div&gt;There
        isn&#39;t much developer documentation right now, but a good place to start
        is by going through the &lt;a href=&quot;http://github.com/0xfe/vexflow/tree/master/tests/&quot;&gt;code&lt;/a&gt;
        for &lt;a href=&quot;http://vexflow.com/tests/&quot;&gt;the tests&lt;/a&gt;.
        You may notice that some files are commented better than others - a great
        way to help is by adding better comments along with more thorough tests.&lt;/div&gt;&lt;div&gt;&lt;br
        /&gt;\n&lt;/div&gt;&lt;div&gt;If you&#39;re not a coder and would like to
        help, you can do so by testing and &lt;a href=&quot;http://github.com/0xfe/vexflow/issues&quot;&gt;reporting
        bugs&lt;/a&gt;, helping with documentation, spending $7 on a &lt;a href=&quot;http://vexflow.com/tabdiv/&quot;&gt;TabDiv
        license&lt;/a&gt;, or simply spreading the word.&lt;/div&gt;&lt;div&gt;&lt;br
        /&gt;\n&lt;/div&gt;&lt;div&gt;Thanks for all the support and help over the
        past few months. &lt;a href=&quot;http://github.com/0xfe/vexflow&quot;&gt;Dive
        in&lt;/a&gt; and enjoy!&lt;/div&gt;</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/3059590296733853422/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/08/vexflow-is-open-source.html#comment-form'
        title='15 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/3059590296733853422'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/3059590296733853422'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/08/vexflow-is-open-source.html'
        title='VexFlow is Open Source'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiCCX_uGvdpHI6QDxV6euNvnnKUFw7lBIkbPcBqlyD75_J7RsVW5qbWjSK9qCbeQNe9i_UwEPvWSCOSNnpEunNPcA4TyAO2-FPX77mdDwUhFYe6JSYmFEVHAedxT0oOF5_iVGqooQ/s72-c/Screen+shot+2010-08-03+at+5.36.09+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>15</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-7961142667231282175</id><published>2010-07-20T21:54:00.000-04:00</published><updated>2010-07-20T21:54:23.905-04:00</updated><title
        type='text'>More Durations and Better Beaming</title><content type='html'>I
        finally got most of the duration and beaming support worked out last weekend,
        and I gotta say that the generated scores by &lt;a href=&quot;http://vexflow.com/&quot;&gt;VexFlow&lt;/a&gt;
        (and &lt;a href=&quot;http://vexflow.com/vextab&quot;&gt;VexTab&lt;/a&gt;)
        are starting to look pretty good.&lt;br /&gt;\n&lt;br /&gt;\nIn VexTab notation,
        you can now set the duration of the subsequent notes using the colon (&lt;span
        class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier New&#39;,
        Courier, monospace;&quot;&gt;:&lt;/span&gt;) character. By default, note durations
        are set to eighth notes.&lt;br /&gt;\n&lt;br /&gt;\nHere&#39;s an example
        of a line that generates a half-note followed by two quarter-notes.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot;
        cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left:
        auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4SokXKqQO6IN0lEH3D2PlyQERmbOVipuHNHDG4r-kmDdSPdJDz8hH38O8SKUyg1Xafi9Sp0jljjnPayVNJ1ta8Ez8H_c1PJwrLdqq5WtE7UXf7RgWWQXDmXmMlpSbf0llA1537Q/s1600/Screen+shot+2010-07-20+at+9.17.44+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;328&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4SokXKqQO6IN0lEH3D2PlyQERmbOVipuHNHDG4r-kmDdSPdJDz8hH38O8SKUyg1Xafi9Sp0jljjnPayVNJ1ta8Ez8H_c1PJwrLdqq5WtE7UXf7RgWWQXDmXmMlpSbf0llA1537Q/s400/Screen+shot+2010-07-20+at+9.17.44+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Basic
        Duration Support&lt;br /&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\nValid duration values (currently) are: &lt;span class=&quot;Apple-style-span&quot;
        style=&quot;font-family: &#39;Courier New&#39;, Courier, monospace;&quot;&gt;w&lt;/span&gt;,
        &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier
        New&#39;, Courier, monospace;&quot;&gt;h&lt;/span&gt;, &lt;span class=&quot;Apple-style-span&quot;
        style=&quot;font-family: &#39;Courier New&#39;, Courier, monospace;&quot;&gt;q&lt;/span&gt;,
        &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier
        New&#39;, Courier, monospace;&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;Apple-style-span&quot;
        style=&quot;font-family: &#39;Courier New&#39;, Courier, monospace;&quot;&gt;16&lt;/span&gt;,
        and &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier
        New&#39;, Courier, monospace;&quot;&gt;32&lt;/span&gt;. Support for dots and
        tuplets/triplets is not yet implemented.&lt;br /&gt;\n&lt;br /&gt;\nDurations
        can be specified inside slides, bends, and other types of ties by prefixing
        the fret with the duration value enclosed within colon characters.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKIJDWT5dvihx_d6pAC88xRKSznZvATNRSTXth6Kc3-UZgerT7Mg5t3F8z__X8uZGQ8dfHAAbkGSf1vXEvnEdG9J3CKzDuZvo5FLcCoiJyWDEasHpooW296n-xj1X8YNoCwTS1Vg/s1600/Screen+shot+2010-07-20+at+9.18.50+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;330&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKIJDWT5dvihx_d6pAC88xRKSznZvATNRSTXth6Kc3-UZgerT7Mg5t3F8z__X8uZGQ8dfHAAbkGSf1vXEvnEdG9J3CKzDuZvo5FLcCoiJyWDEasHpooW296n-xj1X8YNoCwTS1Vg/s400/Screen+shot+2010-07-20+at+9.18.50+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Durations
        within Ties&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;\nAlso,
        I spent time working on some of the tricker beam configurations, where notes
        with varying durations are beamed.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCpz_M1ppQZsOebHxPliRfXzxugqHBkSBmNjXQlEZg4HUFaAL3JI6G2WsM7aUnqn-lp0mi7r0Z14frYzVcyn5SB2YuJ08zOVyuSVA-d5JbFqx3qV_7v493PTGFmgeflHrKHLgAkA/s1600/Screen+shot+2010-07-20+at+9.20.49+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;127&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCpz_M1ppQZsOebHxPliRfXzxugqHBkSBmNjXQlEZg4HUFaAL3JI6G2WsM7aUnqn-lp0mi7r0Z14frYzVcyn5SB2YuJ08zOVyuSVA-d5JbFqx3qV_7v493PTGFmgeflHrKHLgAkA/s200/Screen+shot+2010-07-20+at+9.20.49+PM.png&quot;
        width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Crazy
        Beaming&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;\nIn
        VexTab, you can create beams by enclosing your notes within brackets (separated
        by spaces).&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiY52epYKi4fdr_f1eQQRr2uzjG0H6qW1oKc-ND8x9U9129pIzxGd0bmW5RonRIfGnZ279nUOcOJ37X_iZiO7HaZSL3ESQKwnqHPpM1GroFHSzO7ByHIzfdkEdTBun3rBEBGxnbHw/s1600/Screen+shot+2010-07-20+at+9.25.47+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;332&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiY52epYKi4fdr_f1eQQRr2uzjG0H6qW1oKc-ND8x9U9129pIzxGd0bmW5RonRIfGnZ279nUOcOJ37X_iZiO7HaZSL3ESQKwnqHPpM1GroFHSzO7ByHIzfdkEdTBun3rBEBGxnbHw/s400/Screen+shot+2010-07-20+at+9.25.47+PM.png&quot;
        width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Beaming
        in VexTab&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;\nAnyhow,
        I&#39;ve pushed out the latest revision, with support for standard notation,
        durations, and beaming to the&amp;nbsp;&lt;a href=&quot;http://vexflow.com/tabdiv&quot;&gt;TabDiv
        website&lt;/a&gt;. Feel free to &lt;a href=&quot;http://vexflow.com/vextab/tutorial.html&quot;&gt;toy
        with it&lt;/a&gt; and report any issues you come across.&lt;br /&gt;\n&lt;br
        /&gt;\nHere&#39;s a screenshot of a bluesy guitar lick written in VexTab.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot;
        cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left:
        auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiR7GuMPHx-SaGfRCOiB-3FL9pkFaDKuocLuIiJigPH6MP91HqMsTHMpFXhg5jx5XhNa2yo7QuBvLQ3nbI3z2-mYHwtqSEfJQp5TvfqwtxqmRV0Hmv-OUtIM0-rkqYkYlf4omfg0A/s1600/Screen+shot+2010-07-20+at+9.50.07+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;640&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiR7GuMPHx-SaGfRCOiB-3FL9pkFaDKuocLuIiJigPH6MP91HqMsTHMpFXhg5jx5XhNa2yo7QuBvLQ3nbI3z2-mYHwtqSEfJQp5TvfqwtxqmRV0Hmv-OUtIM0-rkqYkYlf4omfg0A/s640/Screen+shot+2010-07-20+at+9.50.07+PM.png&quot;
        width=&quot;408&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;A Blues
        Lick in VexTab&lt;br /&gt;\n&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\nThat&#39;s all for this week, folks! There are a lot more interesting
        things coming up. Check out the &lt;a href=&quot;http://vexflow.com/vextab/tutorial.html&quot;&gt;VexTab
        tutorial&lt;/a&gt; to play around in the sandboxes, and stay in touch.</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/7961142667231282175/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/07/more-durations-and-better-beaming.html#comment-form'
        title='10 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/7961142667231282175'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/7961142667231282175'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/07/more-durations-and-better-beaming.html'
        title='More Durations and Better Beaming'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4SokXKqQO6IN0lEH3D2PlyQERmbOVipuHNHDG4r-kmDdSPdJDz8hH38O8SKUyg1Xafi9Sp0jljjnPayVNJ1ta8Ez8H_c1PJwrLdqq5WtE7UXf7RgWWQXDmXmMlpSbf0llA1537Q/s72-c/Screen+shot+2010-07-20+at+9.17.44+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>10</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-7789963467582961010</id><published>2010-07-14T11:51:00.000-04:00</published><updated>2010-07-14T11:51:00.426-04:00</updated><title
        type='text'>Migrating VexFlow to SCons</title><content type='html'>I love
        tools. Tools keep my projects predictable and smooth. Tools help me code fast
        and release fast.&lt;br /&gt;\n&lt;br /&gt;\n&lt;a href=&quot;http://www.vexflow.com/&quot;&gt;VexFlow&lt;/a&gt;
        has gone through many iterations of design, implementation, and deployment,
        and I couldn&#39;t have brought it this far so quickly without my tools. (Well,
        automated testing had a lot to do with it too, but that&#39;s for another
        post.)&lt;br /&gt;\n&lt;br /&gt;\nYesterday, I added a new tool to my toolbox
        - &lt;a href=&quot;http://www.scons.org/&quot;&gt;SCons&lt;/a&gt;. I migrated
        all my building, packaging, test driving, and deployment code to SCons. Compared
        to the ugly shell scripts I previously used, SCons is a lot cleaner, a lot
        faster, and significantly easier to manage.&lt;br /&gt;\n&lt;br /&gt;\nI chose
        SCons for two reasons:&lt;br /&gt;\n&lt;ol&gt;&lt;li&gt;Simplicity. It&#39;s
        Python-based and super-easy to work with.&lt;/li&gt;\n&lt;li&gt;Familiarity.
        I&#39;ve used it before, so already know my way around it.&lt;/li&gt;\n&lt;/ol&gt;&lt;div&gt;Since
        I use the &lt;a href=&quot;http://code.google.com/closure/compiler/&quot;&gt;Google
        Closure Compiler&lt;/a&gt; to build and minimize my JavaScript code, I had
        to write a new builder for SCons. That turned out to be pretty straightforward
        to implement.&lt;/div&gt;&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;def
        js_builder(target, source, env):\n  &quot;&quot;&quot; A JavaScript builder
        using Google Closure Compiler. &quot;&quot;&quot;\n\n  cmd = env.subst(\n
        \     &quot;$JAVA -jar $JS_COMPILER --compilation_level $JS_COMPILATION_LEVEL&quot;);\n\n
        \ # Add defines to the command\n  for define in env[&#39;JS_DEFINES&#39;].keys():\n
        \   cmd += &quot; --define=\\&quot;%s=%s\\&quot;&quot; % (define, env[&#39;JS_DEFINES&#39;][define])\n\n
        \ # Add the source files\n  for file in source:\n    cmd += &quot; --js &quot;
        + str(file)\n\n  # Add the output file\n  cmd += &quot; --js_output_file &quot;
        + str(target[0])\n\n  # Log the command and run\n  print env.subst(cmd)\n
        \ os.system(env.subst(cmd))\n&lt;/pre&gt;&lt;br /&gt;\nI also needed a new
        builder to stamp my output with the relevant build information. So, I created
        a &lt;i&gt;Stamper, &lt;/i&gt;which is just a builder that runs some string
        substitution on files with &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;sed&lt;/span&gt;. The
        stamper looks like this:&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;def
        vexflow_stamper(target, source, env):\n  &quot;&quot;&quot; A Build Stamper
        for VexFlow &quot;&quot;&quot;\n\n  cmd =  &quot;sed &quot;\n  cmd += &quot;
        -e s/__VEX_BUILD_PREFIX__/$VEX_BUILD_PREFIX/&quot;\n  cmd += &quot; -e s/__VEX_VERSION__/$VEX_VERSION/&quot;\n
        \ cmd += &#39; -e &quot;s/__VEX_BUILD_DATE__/${VEX_BUILD_DATE}/&quot;&#39;\n
        \ cmd += &quot; -e s/__VEX_GIT_SHA1__/`git rev-list --max-count=1 HEAD`/ &quot;\n
        \ cmd += (&quot;%s &amp;gt; %s&quot; % (source[0], target[0]))\n\n  print
        env.subst(cmd)\n  os.system(env.subst(cmd))\n&lt;/pre&gt;&lt;br /&gt;\nBefore
        you can use these builders, you need to add them to your environment:&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;env.Append(BUILDERS
        = {&#39;JavaScript&#39;: Builder(action = js_builder),\n                       &#39;VexFlowStamp&#39;:
        Builder(action = vexflow_stamper)})\n&lt;/pre&gt;&lt;br /&gt;\nOnce this is
        done, you can add build JavaScript targets with the &lt;i&gt;JavaScript&lt;/i&gt;
        command.&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;env[&#39;JAVA&#39;]
        = &quot;/usr/bin/java&quot;\nenv[&#39;JS_COMPILER&#39;] = &quot;support/compiler.jar&quot;\nenv[&#39;JS_DEFINES&#39;
        ] = {\n  &quot;Vex.Debug&quot;: &quot;true&quot;,\n  &quot;Vex.LogLevel&quot;:
        &quot;4&quot;\n}\n\nsources = [&quot;src1.js&quot;, &quot;src2.js&quot;, &quot;src3.js&quot;]\n\nenv.JavaScript(&quot;src.min.js&quot;,
        sources)\n&lt;/pre&gt;&lt;br /&gt;\nThis really is just scratching the surface.
        There&#39;s a lot more you can do with SCons to automate and streamline your
        builds. To learn more, take a look at the &lt;a href=&quot;http://www.scons.org/doc/2.0.0.final.0/HTML/scons-user/index.html&quot;&gt;user
        guide&lt;/a&gt;.&lt;br /&gt;\n&lt;br /&gt;\nI added support for testing, packaging,
        and deployment (of the web pages and demos) to my SCons scripts in a matter
        of hours, and finally purged all my nasty shell scripts from the VexFlow codebase.&lt;br
        /&gt;\n&lt;br /&gt;\nGive it a try. I guarantee you&#39;ll be happier.</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/7789963467582961010/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/07/migrating-vexflow-to-scons.html#comment-form'
        title='3 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/7789963467582961010'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/7789963467582961010'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/07/migrating-vexflow-to-scons.html'
        title='Migrating VexFlow to SCons'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-6514910752490146447</id><published>2010-07-12T14:50:00.000-04:00</published><updated>2010-07-12T14:50:31.885-04:00</updated><title
        type='text'>Durations, Code, and Posters</title><content type='html'>The last
        few weeks have been relatively quiet on the VexFlow side. I&#39;ve been vacationing
        in Cape Cod with my wife and 3-month-old.&lt;br /&gt;\n&lt;br /&gt;\nObviously,
        vacation is never fun without a few good coding sprints. I started work on
        incorporating standard notation into &lt;a href=&quot;http://www.vexflow.com/vextab&quot;&gt;VexTab&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\nThe first thing I needed to do was create a class to
        convert fret-string pairs to notes. In order to support alternate tunings,
        I created a &lt;i&gt;Tuning&lt;/i&gt;&amp;nbsp;class, whose sole responsibility
        is to return the correct note for a given fret-string pair, based on the instrument
        type and tuning.&lt;br /&gt;\n&lt;br /&gt;\nSo, to convert the fret-string
        pair &quot;5/2&quot; on a 5-string bass to standard notation, all I need to
        do is:&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;var
        tuning = new Vex.Flow.Tuning(&quot;G/4,D/4,A/3,E/3,B/2&quot;);\nvar note =
        tuning.getNoteForFret(5, 2);\n&lt;/pre&gt;&lt;br /&gt;\nThe next part was
        augmenting the language to render standard notation when requested. I modified
        &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family: &#39;Courier
        New&#39;, Courier, monospace;&quot;&gt;tabstave&lt;/span&gt; to accept &lt;span
        class=&quot;Apple-style-span&quot; style=&quot;font-family: inherit;&quot;&gt;&lt;i&gt;key=value&lt;/i&gt;&lt;/span&gt;
        parameters, and added a parameter called &lt;span class=&quot;Apple-style-span&quot;
        style=&quot;font-family: &#39;Courier New&#39;, Courier, monospace;&quot;&gt;notation&lt;/span&gt;.
        When set to &lt;span class=&quot;Apple-style-span&quot; style=&quot;font-family:
        &#39;Courier New&#39;, Courier, monospace;&quot;&gt;true&lt;/span&gt;, it
        renders standard notation above the guitar tab.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table
        align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;
        class=&quot;tr-caption-container&quot; style=&quot;margin-left: auto; margin-right:
        auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td style=&quot;text-align:
        center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjOfzb0VTihrFnDXvA642NRGLuWU45tUoukDnqlFYI5bF-J_CBAWHriN3qroiWKRqWYDoOPFNKfgDoZp5jmRwRqYjla4YEQ2Chd0yL_O6bJAFow9mG6-kUlCNHTbrFvHpupX02O3g/s1600/Screen+shot+2010-07-12+at+2.20.47+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;276&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjOfzb0VTihrFnDXvA642NRGLuWU45tUoukDnqlFYI5bF-J_CBAWHriN3qroiWKRqWYDoOPFNKfgDoZp5jmRwRqYjla4YEQ2Chd0yL_O6bJAFow9mG6-kUlCNHTbrFvHpupX02O3g/s320/Screen+shot+2010-07-12+at+2.20.47+PM.png&quot;
        width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;VexTab
        with Standard Notation&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\nI also started work on basic duration support and auto-beaming. I don&#39;t
        have much to show for this yet, because they&#39;re currently a bit intertwined,
        and automatic beaming is harder than I anticipated (yet again!)&lt;br /&gt;\n&lt;br
        /&gt;\nIn other news, I &lt;a href=&quot;http://github.com/0xfe/vex/blob/master/vextab/vextab.js&quot;&gt;open
        sourced&lt;/a&gt; the VexTab parser, so you can learn more about the language
        or use it in your own rendering engines. It is currently slightly coupled
        to VexFlow, but pretty trivial to decouple. (I&#39;m going to fully decouple
        it as this project progresses.)&lt;br /&gt;\n&lt;br /&gt;\nThe parser is licensed
        under the &lt;a href=&quot;http://www.opensource.org/licenses/mit-license.php&quot;&gt;MIT
        license&lt;/a&gt;, and is available on GitHub at: &lt;a href=&quot;http://github.com/0xfe/vex/tree/master/vextab/&quot;&gt;http://github.com/0xfe/vex/tree/master/vextab/&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\nFinally, some readers who liked my previous &lt;a href=&quot;http://0xfe.blogspot.com/2009/12/google-chrome-poster-from-source-code.html&quot;&gt;Chrome
        Poster from Source Code&lt;/a&gt; post requested posters for other open-source
        projects. I generated posters for Firefox, Linux, and FreeBSD, and made them
        available on my other side project: &lt;a href=&quot;http://wickedmeanposters.com/&quot;&gt;Wicked
        Mean Posters&lt;/a&gt;.&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot;
        cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;
        style=&quot;margin-left: auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAD0NHLeE4x2HoXGDzW6pydG0jqBIb_bI1AzrlDohHGM14iu928BTzOftpGh0cHv4uKD47sphwVDgO1sbkX61XXvgeIU1F0He8VGp0Na_QoGFUtXfOXd-ItH6nITciSpGfCm-fHA/s1600/Screen+shot+2010-07-12+at+2.43.14+PM.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;198&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAD0NHLeE4x2HoXGDzW6pydG0jqBIb_bI1AzrlDohHGM14iu928BTzOftpGh0cHv4uKD47sphwVDgO1sbkX61XXvgeIU1F0He8VGp0Na_QoGFUtXfOXd-ItH6nITciSpGfCm-fHA/s320/Screen+shot+2010-07-12+at+2.43.14+PM.png&quot;
        width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Firefox
        Poster from Source Code&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br
        /&gt;\nMore next time!</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/6514910752490146447/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/07/durations-code-and-posters.html#comment-form'
        title='5 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6514910752490146447'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/6514910752490146447'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/07/durations-code-and-posters.html'
        title='Durations, Code, and Posters'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjOfzb0VTihrFnDXvA642NRGLuWU45tUoukDnqlFYI5bF-J_CBAWHriN3qroiWKRqWYDoOPFNKfgDoZp5jmRwRqYjla4YEQ2Chd0yL_O6bJAFow9mG6-kUlCNHTbrFvHpupX02O3g/s72-c/Screen+shot+2010-07-12+at+2.20.47+PM.png\"
        height=\"72\" width=\"72\"/><thr:total>5</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-8369373862453509821</id><published>2010-06-25T17:25:00.000-04:00</published><updated>2011-09-10T11:20:07.098-04:00</updated><title
        type='text'>Encrypted Incremental Backups to S3</title><content type='html'>I
        spent some time this week trying to get secure online backups working for
        all my machines.&lt;br /&gt;\n&lt;br /&gt;\nSo far, I&#39;ve been managing
        most of my data and workspaces with replicated Git repositories. I have scripts
        that allow me to maintain roaming profiles across my machines (almost) seamlessly,
        and these scripts try to ensure that these profiles are consistently replicated.
        My profiles include things like dot files (&lt;code&gt;.vimrc&lt;/code&gt;,
        &lt;code&gt;.screenrc&lt;/code&gt;, etc.), startup scripts, tools, workspaces,
        repositories, and other odds and ends.&lt;br /&gt;\n&lt;br /&gt;\nBecause
        I tend to be ultra-paranoid about security and reliability, the replicas are
        encrypted and distributed across different machines in different locations.
        For encryption, I use &lt;a href=&quot;https://launchpad.net/ecryptfs&quot;&gt;ecryptfs&lt;/a&gt;
        on Linux machines, and FileVault on the Mac.&lt;br /&gt;\n&lt;br /&gt;\nAnyhow,
        this week I lost my Mac to a hardware failure, and my co-located Linux machine
        to a service-provider &lt;i&gt;dismantling&lt;/i&gt;. That left me with one
        replica... just waiting to fail.&lt;br /&gt;\n&lt;br /&gt;\nI decided that
        I needed another replica, but didn&#39;t want to pay for, or have to setup
        another co-located server. After spending some time researching various online-backup
        providers, I decided to go with &lt;a href=&quot;http://aws.amazon.com/s3/&quot;&gt;Amazon&#39;s
        S3 service&lt;/a&gt;.&lt;br /&gt;\n&lt;br /&gt;\nI chose S3 because - it&#39;s
        cheap, it&#39;s tried and tested, it&#39;s built on an internal distributed
        and replicated database, and there are some great tools that work with it.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;h3&gt;Brackup&lt;/h3&gt;&lt;br /&gt;\n&lt;a href=&quot;http://code.google.com/p/brackup/&quot;&gt;Brackup&lt;/a&gt;,
        by Brad Fitzpatrick, is one of those tools. It allows you to make encrypted
        incremental backups to S3, without a lot of hair-pulling or teeth-gnashing.&lt;br
        /&gt;\n&lt;br /&gt;\nTo get Brackup running on your machine, you need to have
        GPG, Perl 5, and the Net::Amazon::S3 Perl module installed. On the Mac, you
        also need to get MacPorts.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3&gt;Installation&lt;/h3&gt;&lt;br
        /&gt;\nMost modern distributions come with Perl 5 pre-installed, but not with
        GPG. The package name you want on both MacPorts and Ubuntu, is &lt;code&gt;gnupg&lt;/code&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\nThe first thing you need to do, if you don&#39;t already
        have a GPG key, is to generate one.&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$
        gpg --gen-keys&lt;/pre&gt;&lt;br /&gt;\nIf you need to backup multiple machines,
        export your public key to a text file, and import it on the other machines.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;hostA$ gpg --export
        -a &quot;User Name&quot; &amp;gt; public.key\nhostA$ scp public.key hostB:/tmp\nhostB$
        gpg --import /tmp/public.key\n&lt;/pre&gt;&lt;br /&gt;\nRemember that all
        your backups will be encrypted with your public key, so if you lose your private
        key, the only thing you can do with your backups is generate white noise.
        Export your private key and save it in a safe place. (I suggest &lt;a href=&quot;http://vexcrypto.appspot.com/&quot;&gt;VexCrypto&lt;/a&gt;.)&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$ gpg --export-secret-key
        -a &quot;User Name&quot; &amp;gt; private.key\n&lt;/pre&gt;&lt;br /&gt;\nNow
        that you have your keys setup, download and install Brackup. The easiest way
        to do this is by using the &lt;code&gt;cpan&lt;/code&gt; tool.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$ sudo cpan Net::Amazon::S3\n$
        sudo cpan Brackup\n&lt;/pre&gt;&lt;br /&gt;\nNote that it&#39;s better (and
        way faster) to use your distribution&#39;s package for Net::Amazon::S3. On
        Ubuntu the package is &lt;code&gt;libnet-amazon-s3-perl&lt;/code&gt;, and
        on MacPorts, the package is &lt;code&gt;p5-amazon-s3&lt;/code&gt;.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;h3&gt;Configuration&lt;/h3&gt;\n&lt;br /&gt;\nOnce this is done,
        you can generate a template configuration file by typing in &lt;code&gt;brackup&lt;/code&gt;
        on the command line. This file is stored in &lt;code&gt;$HOME/.brackup&lt;/code&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$ &lt;b&gt;brackup&lt;/b&gt;\nError:
        Your config file needs tweaking.  I put a commented-out template at: /home/muthanna/.brackup.conf\n\nbrackup
        --from=[source_name] --to=[target_name] [--output=&lt;backup_metafile.brackup&gt;]\nbrackup
        --help\n&lt;/backup_metafile.brackup&gt;&lt;/pre&gt;&lt;br /&gt;\nEdit the
        configuration file and create your sources and targets. You will likely have
        multiple sources, and one target. Here&#39;s a snip of my configuration:&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;[TARGET:amazon]\ntype
        = Amazon\naws_access_key_id  = XXXXXXXXXXX\naws_secret_access_key = XXXXXXXXXXXXXX\nkeep_backups
        = 10\n\n[SOURCE:mac_repos]\npath = /Users/0xfe/Local\nchunk_size = 5m\ngpg_recipient
        = 79E44165\nignore = ^.*\\.(swp|swo|hi|o|a|pyc|svn|class|DS_Store|Trash|Trashes)$/\n\n[SOURCE:mac_desktop_books]\npath
        = /Users/0xfe/Desktop/Books\ngpg_recipient = 79E44165\nignore = ^.*\\.(swp|swo|hi|o|a|pyc|svn|class|DS_Store|Trash|Trashes)$/\n\n[SOURCE:mac_desktop_workspace]\npath
        = /Users/0xfe/Desktop/Workspace\ngpg_recipient = 79E44165\nignore = ^.*\\.(swp|swo|hi|o|a|pyc|svn|class|DS_Store|Trash|Trashes)$/\n&lt;/pre&gt;&lt;br
        /&gt;\nThe configuration keys are pretty self explanatory. I should point
        out that &lt;code&gt;gpg_recipient&lt;/code&gt; is your public key ID, as
        shown by &lt;code&gt;gpg --list-keys&lt;/code&gt;.&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre
        class=&quot;prettyprint&quot;&gt;$ gpg --list-keys\n/Users/0xfe/.gnupg/pubring.gpg\n-----------------------------------\npub
        \  2048R/79E44165 2010-06-24\nuid                  My Username &amp;lt;snip@snip.com&amp;gt;\nsub
        \  2048R/43AD4B72 2010-06-24\n&lt;/pre&gt;&lt;br /&gt;\nFor more details on
        the various parameters, see &lt;a href=&quot;http://search.cpan.org/~bradfitz/Brackup/lib/Brackup/Manual/Overview.pod&quot;&gt;The
        Brackup Manual&lt;/a&gt;.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3&gt;Start a Backup&lt;/h3&gt;\n&lt;br
        /&gt;\nTo backup one of your sources, use the &lt;code&gt;brackup&lt;/code&gt;
        command, as so:&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$
        brackup -v --from=mac_repos --to=amazon\n&lt;/pre&gt;&lt;br /&gt;\nIf you
        now take a look at your &lt;a href=&quot;http://aws.amazon.com/&quot;&gt;AWS
        Dashboard&lt;/a&gt;, you should see the buckets and chunks created for your
        backup data.&lt;br /&gt;\n&lt;br /&gt;\nNotice that &lt;code&gt;brackup&lt;/code&gt;
        creates an output file (with the extension &lt;code&gt;.brackup&lt;/code&gt;)
        in the current directory. This file serves as an index, and maintains pointers
        to the S3 chunks for each backed-up file. You will need this file to locate
        and restore your data, and a copy of it is maintained on S3.&lt;br /&gt;\n&lt;br
        /&gt;\n&lt;h3&gt;Restoring&lt;/h3&gt;\n&lt;br /&gt;\n&quot;&lt;i&gt;Test restores
        regularly.&lt;/i&gt;&quot; -- a wise man.&lt;br /&gt;\n&lt;br /&gt;\nTo restore
        your Brackup backups, you will need to have your private key handy on the
        machine that you&#39;re restoring to. Brackup accesses your private key via
        &lt;code&gt;gpg-agent&lt;/code&gt;.&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$
        sudo port install gpg-agent\n$ eval $(gpg-agent --daemon)\n&lt;/pre&gt;&lt;br
        /&gt;\nThe &lt;code&gt;brackup-restore&lt;/code&gt; command restores a source
        tree to a path specified on the command line. It makes use of the output file
        that brackup generated during the initial backup to locate and restore your
        data. If you don&#39;t have a local copy of the output file, you can use &lt;code&gt;brackup-target&lt;/code&gt;
        to retrieve a copy from S3.&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$
        brackup-restore -v --from=mac_repos-20100624.brackup \\\n  --to=/Users/0xfe/temp/mac_repos
        --all\n&lt;/pre&gt;&lt;br /&gt;\nYou will be prompted for you AWS key, your
        AWS secret key, and your GPG private key passphrase. Make sure that that the
        restore completed successfully and correctly. Comparing the SHA1 hashes of
        the restored data with those of the original data is a good way to validate
        correctness.&lt;br /&gt;\n&lt;br /&gt;\n&lt;h3&gt;Garbage Collection&lt;/h3&gt;\n&lt;br
        /&gt;\nYou will need to prune and garbage collect your data regularly to keep
        backups from piling up and using up space in S3. The following commands delete
        old backed up chunks based on the &lt;i&gt;keep_files &lt;/i&gt;configuration
        value of the target.&lt;br /&gt;\n&lt;br /&gt;\n&lt;pre class=&quot;prettyprint&quot;&gt;$
        brackup-target amazon prune\n$ brackup-target amazon gc\n&lt;/pre&gt;&lt;br
        /&gt;\nThat&#39;s all folks! Secure, on-line, off-site, incremental, buzz-word-ridden
        backups. Code safely!</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/8369373862453509821/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/06/encrypted-incremental-backups-to-s3.html#comment-form'
        title='4 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/8369373862453509821'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/8369373862453509821'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/06/encrypted-incremental-backups-to-s3.html'
        title='Encrypted Incremental Backups to S3'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><thr:total>4</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-3313904850292755497</id><published>2010-06-21T14:12:00.000-04:00</published><updated>2010-06-21T14:12:11.700-04:00</updated><title
        type='text'>On Parsing and Licenses</title><content type='html'>So I spent
        this weekend rewriting the &lt;a href=&quot;http://vexflow.com/tabdiv/tutorial.html&quot;&gt;VexTab&lt;/a&gt;
        parser. The original version, though it served its purpose as a quick prototype
        for the language, was severely limited due to it being built primarily out
        of regular expressions.&lt;br /&gt;\n&lt;br /&gt;\nThe new parser uses a recursive-descent
        algorithm, and fully supports the original grammar. Adding new syntactic elements
        to the language is now simple, as is adding support for more complex grammars.&lt;br
        /&gt;\n&lt;br /&gt;\nSome new features I added to the language are support
        for slides, hammer-ons, pull-offs, and tapping. Here&#39;s a blues lick written
        in VexTab:&lt;br /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot;
        cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left:
        auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjOTpU652I2h8heK-MA-5nu0w1I70rvYWZDuPrcr2ufE663YB3DK-yexfnHSJz3BnbRSGvk8N3OpPwmu_ZIgDX0zHQkialvKR014n87LzrgUHY0vDCVutWBuAABvtU8yR3BFYY60g/s1600/Picture+11.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;262&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjOTpU652I2h8heK-MA-5nu0w1I70rvYWZDuPrcr2ufE663YB3DK-yexfnHSJz3BnbRSGvk8N3OpPwmu_ZIgDX0zHQkialvKR014n87LzrgUHY0vDCVutWBuAABvtU8yR3BFYY60g/s320/Picture+11.png&quot;
        width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Blues
        Lick in VexTab&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;\nSome
        readers have asked me about durations and how to specify rhythms in VexTab.
        Although the VexFlow core has full support for durations and timing, I still
        need a good way to represent them in the language. I&#39;m open to ideas here
        if you have any.&lt;br /&gt;\n&lt;br /&gt;\n&lt;b&gt;Enter TabDiv&lt;/b&gt;&lt;br
        /&gt;\n&lt;br /&gt;\nI also spent this weekend working on the release of the
        first VexFlow-based product:&amp;nbsp;&lt;a href=&quot;http://vexflow.com/tabdiv/index.html&quot;&gt;TabDiv&lt;/a&gt;.
        TabDiv lets you easily embed guitar tablature into your website or blog.&lt;br
        /&gt;\n&lt;br /&gt;\nAfter you&#39;ve included the TabDiv &lt;code&gt;.js&lt;/code&gt;
        and &lt;code&gt;.css&lt;/code&gt; files in your HTML document (or blog template),
        you can add tabs by simply creating DIV elements and setting the class to
        vex-tabdiv.&lt;br /&gt;\n&lt;br /&gt;\nYou can get TabDiv here:&amp;nbsp;&lt;a
        href=&quot;http://vexflow.com/tabdiv/index.html&quot;&gt;http://vexflow.com/tabdiv/index.html&lt;/a&gt;.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;b&gt;Why not Open-Source?&lt;/b&gt;&lt;br /&gt;\n&lt;br
        /&gt;\nI&#39;m no stranger to open-source. I&#39;ve been writing, maintaining,
        and contributing to open-source software for over a decade.&lt;br /&gt;\n&lt;br
        /&gt;\nAlthough I hope to eventually open-source all the VexFlow source code,
        I&#39;m going to hold off on it until I figure out where I want to take this
        product. I&#39;ve invested a lot of time and effort into making VexFlow a
        fast high-quality renderer, and I&#39;d like to find a way to cater to both
        a commercial-audience, and the open-source community.&lt;br /&gt;\n&lt;br
        /&gt;\nSo, how does one find and maintain this delicate balance? Do I completely
        open-source it? Should I keep it closed and charge for it? Dual-license maybe?</content><link
        rel='replies' type='application/atom+xml' href='https://0xfe.blogspot.com/feeds/3313904850292755497/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/06/on-parsing-and-licenses.html#comment-form'
        title='16 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/3313904850292755497'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/3313904850292755497'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/06/on-parsing-and-licenses.html'
        title='On Parsing and Licenses'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjOTpU652I2h8heK-MA-5nu0w1I70rvYWZDuPrcr2ufE663YB3DK-yexfnHSJz3BnbRSGvk8N3OpPwmu_ZIgDX0zHQkialvKR014n87LzrgUHY0vDCVutWBuAABvtU8yR3BFYY60g/s72-c/Picture+11.png\"
        height=\"72\" width=\"72\"/><thr:total>16</thr:total></entry><entry><id>tag:blogger.com,1999:blog-19544619.post-7599469828136185502</id><published>2010-06-17T15:01:00.000-04:00</published><updated>2010-06-17T15:01:57.156-04:00</updated><title
        type='text'>Benchmarking VexFlow</title><content type='html'>I have about
        340 tests now for VexFlow, and one of the things I find really impressive
        is the speed at which browsers currently load, execute, and render web-pages.&lt;br
        /&gt;\n&lt;br /&gt;\nSince the code exercises the browser on a few different
        dimensions (heavy JavaScript, lots of DOM manipulation, a few new HTML5 features),
        I decided to pit the major browsers against each other and run a few benchmarks.&lt;br
        /&gt;\n&lt;br /&gt;\n&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot;
        cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot; style=&quot;margin-left:
        auto; margin-right: auto; text-align: center;&quot;&gt;&lt;tbody&gt;\n&lt;tr&gt;&lt;td
        style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiYbJtGgfxWbAZNnhARDNSNFhsLELRdCUQC9AJgQVTSxMrw0AcWkLlOZYuhzbxW5wUGHjptKYm1Ul758647rbb2p2hdn8ItTxlQN4qJe8CzrLH01dzwV248vhoP27vsIFWikAo0nA/s1600/Picture+9.png&quot;
        imageanchor=&quot;1&quot; style=&quot;margin-left: auto; margin-right: auto;&quot;&gt;&lt;img
        border=&quot;0&quot; height=&quot;127&quot; src=&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiYbJtGgfxWbAZNnhARDNSNFhsLELRdCUQC9AJgQVTSxMrw0AcWkLlOZYuhzbxW5wUGHjptKYm1Ul758647rbb2p2hdn8ItTxlQN4qJe8CzrLH01dzwV248vhoP27vsIFWikAo0nA/s320/Picture+9.png&quot;
        width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td
        class=&quot;tr-caption&quot; style=&quot;text-align: center;&quot;&gt;Test
        Suite on Chrome 5.0.375&lt;/td&gt;&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;I
        ran the 340 tests in a loop a 1000 times on each browser, and calculated the
        mean runtime in milliseconds. Here are the results:&lt;br /&gt;\n&lt;br /&gt;\n&lt;ul&gt;&lt;li&gt;Chrome
        5.0.375: &lt;b&gt;754ms&lt;/b&gt;&lt;/li&gt;\n&lt;li&gt;Safari 4.0.4: &lt;b&gt;1118ms&lt;/b&gt;&lt;/li&gt;\n&lt;li&gt;Opera
        10.53: &lt;b&gt;1511ms&lt;/b&gt;&lt;/li&gt;\n&lt;li&gt;Firefox 3.6.3: &lt;b&gt;3209ms&lt;/b&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;div&gt;&lt;br
        /&gt;\nThe difference between the Chrome and Firefox numbers is quite surprising.&lt;/div&gt;&lt;br
        /&gt;\nI also ran some SVG vs. Canvas benchmarks and found that SVG was about
        3 times slower than Canvas. This factor increased significantly as the number
        of elements in the SVG image grew. That said, SVG rendered much more consistently
        across the different browsers.&lt;br /&gt;\n&lt;br /&gt;\nThe test machine
        used was a dual-core MacBook Pro with a 2.53 GHz Intel Core 2 Duo processor
        and 4GB of DDR3 RAM.</content><link rel='replies' type='application/atom+xml'
        href='https://0xfe.blogspot.com/feeds/7599469828136185502/comments/default'
        title='Post Comments'/><link rel='replies' type='text/html' href='https://0xfe.blogspot.com/2010/06/benchmarking-vexflow.html#comment-form'
        title='3 Comments'/><link rel='edit' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/7599469828136185502'/><link
        rel='self' type='application/atom+xml' href='https://www.blogger.com/feeds/19544619/posts/default/7599469828136185502'/><link
        rel='alternate' type='text/html' href='https://0xfe.blogspot.com/2010/06/benchmarking-vexflow.html'
        title='Benchmarking VexFlow'/><author><name>0xfe</name><uri>http://www.blogger.com/profile/11179501091623983192</uri><email>noreply@blogger.com</email><gd:image
        rel='http://schemas.google.com/g/2005#thumbnail' width='16' height='16' src='https://img1.blogblog.com/img/b16-rounded.gif'/></author><media:thumbnail
        xmlns:media=\"http://search.yahoo.com/mrss/\" url=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiYbJtGgfxWbAZNnhARDNSNFhsLELRdCUQC9AJgQVTSxMrw0AcWkLlOZYuhzbxW5wUGHjptKYm1Ul758647rbb2p2hdn8ItTxlQN4qJe8CzrLH01dzwV248vhoP27vsIFWikAo0nA/s72-c/Picture+9.png\"
        height=\"72\" width=\"72\"/><thr:total>3</thr:total></entry></feed>"
  recorded_at: Tue, 29 Jul 2025 09:55:38 GMT
recorded_with: VCR 6.3.1
